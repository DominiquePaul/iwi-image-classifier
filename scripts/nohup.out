  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    Layer (type)                 Output Shape              Param #   
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    =================================================================
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d (Conv2D)              (None, 299, 299, 36)      1008      
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_1 (Conv2D)            (None, 299, 299, 36)      11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    max_pooling2d (MaxPooling2D) (None, 149, 149, 36)      0         
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    batch_normalization (BatchNo (None, 149, 149, 36)      144       
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_2 (Conv2D)            (None, 149, 149, 36)      11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_3 (Conv2D)            (None, 149, 149, 36)      11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    max_pooling2d_1 (MaxPooling2 (None, 74, 74, 36)        0         
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    batch_normalization_1 (Batch (None, 74, 74, 36)        144       
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_4 (Conv2D)            (None, 74, 74, 36)        11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_5 (Conv2D)            (None, 74, 74, 36)        11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    max_pooling2d_2 (MaxPooling2 (None, 37, 37, 36)        0         
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    batch_normalization_2 (Batch (None, 37, 37, 36)        144       
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_6 (Conv2D)            (None, 37, 37, 36)        11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_7 (Conv2D)            (None, 37, 37, 36)        11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    max_pooling2d_3 (MaxPooling2 (None, 18, 18, 36)        0         
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    batch_normalization_3 (Batch (None, 18, 18, 36)        144       
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_8 (Conv2D)            (None, 18, 18, 36)        11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_9 (Conv2D)            (None, 18, 18, 36)        11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    max_pooling2d_4 (MaxPooling2 (None, 9, 9, 36)          0         
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    batch_normalization_4 (Batch (None, 9, 9, 36)          144       
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_10 (Conv2D)           (None, 9, 9, 36)          11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    conv2d_11 (Conv2D)           (None, 9, 9, 36)          11700     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    max_pooling2d_5 (MaxPooling2 (None, 4, 4, 36)          0         
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    batch_normalization_5 (Batch (None, 4, 4, 36)          144       
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    flatten (Flatten)            (None, 576)               0         
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    dense (Dense)                (None, 39)                22503     
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    dropout (Dropout)            (None, 39)                0         
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    dense_1 (Dense)              (None, 39)                1560      
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    dropout_1 (Dropout)          (None, 39)                0         
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    dense_2 (Dense)              (None, 2)                 80        
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    =================================================================
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    Total params: 154,715
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    Trainable params: 154,283
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    Non-trainable params: 432
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]                                                    None
  0%|          | 0/10 [00:08<?, ?it/s, best loss: ?]2019-03-30 13:11:33.758680: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.
  FutureWarning)

WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                    Epoch 1/2
  0%|          | 0/10 [00:23<?, ?it/s, best loss: ?]                                                     1/10 [==>...........................]
  0%|          | 0/10 [02:09<?, ?it/s, best loss: ?]                                                     - ETA: 15:48 - loss: 1.8072 - sparse_categorical_accuracy: 0.2383 - f1_score: 0.8622
  0%|          | 0/10 [02:09<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [02:11<?, ?it/s, best loss: ?]                                                     2/10 [=====>........................]
  0%|          | 0/10 [02:11<?, ?it/s, best loss: ?]                                                     - ETA: 7:09 - loss: 1.3984 - sparse_categorical_accuracy: 0.3047 - f1_score: 0.8571 
  0%|          | 0/10 [02:11<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [02:12<?, ?it/s, best loss: ?]                                                     3/10 [========>.....................]
  0%|          | 0/10 [02:12<?, ?it/s, best loss: ?]                                                     - ETA: 4:14 - loss: 1.1998 - sparse_categorical_accuracy: 0.3672 - f1_score: 0.8613
  0%|          | 0/10 [02:12<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [02:14<?, ?it/s, best loss: ?]                                                     4/10 [===========>..................]
  0%|          | 0/10 [02:14<?, ?it/s, best loss: ?]                                                     - ETA: 2:46 - loss: 1.0744 - sparse_categorical_accuracy: 0.4287 - f1_score: 0.8603
  0%|          | 0/10 [02:14<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [02:16<?, ?it/s, best loss: ?]                                                     5/10 [==============>...............]
  0%|          | 0/10 [02:16<?, ?it/s, best loss: ?]                                                     - ETA: 1:53 - loss: 0.9798 - sparse_categorical_accuracy: 0.4719 - f1_score: 0.8581
  0%|          | 0/10 [02:16<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [02:18<?, ?it/s, best loss: ?]                                                     6/10 [=================>............]
  0%|          | 0/10 [02:18<?, ?it/s, best loss: ?]                                                     - ETA: 1:16 - loss: 0.9252 - sparse_categorical_accuracy: 0.5072 - f1_score: 0.8592
  0%|          | 0/10 [02:18<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [02:20<?, ?it/s, best loss: ?]                                                     7/10 [====================>.........]
  0%|          | 0/10 [02:20<?, ?it/s, best loss: ?]                                                     - ETA: 50s - loss: 0.8838 - sparse_categorical_accuracy: 0.5379 - f1_score: 0.8571 
  0%|          | 0/10 [02:20<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [02:22<?, ?it/s, best loss: ?]                                                     8/10 [=======================>......]
  0%|          | 0/10 [02:22<?, ?it/s, best loss: ?]                                                     - ETA: 29s - loss: 0.8444 - sparse_categorical_accuracy: 0.5645 - f1_score: 0.8571
  0%|          | 0/10 [02:22<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [02:24<?, ?it/s, best loss: ?]                                                     9/10 [==========================>...]
  0%|          | 0/10 [02:24<?, ?it/s, best loss: ?]                                                     - ETA: 13s - loss: 0.8077 - sparse_categorical_accuracy: 0.5859 - f1_score: 0.8585
  0%|          | 0/10 [02:24<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:27<?, ?it/s, best loss: ?]                                                    10/10 [==============================]
  0%|          | 0/10 [03:27<?, ?it/s, best loss: ?]                                                     - 184s 18s/step - loss: 0.7771 - sparse_categorical_accuracy: 0.6012 - f1_score: 0.8578 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

  0%|          | 0/10 [03:27<?, ?it/s, best loss: ?]                                                    Epoch 2/2
  0%|          | 0/10 [03:27<?, ?it/s, best loss: ?]                                                     1/10 [==>...........................]
  0%|          | 0/10 [03:29<?, ?it/s, best loss: ?]                                                     - ETA: 18s - loss: 0.5523 - sparse_categorical_accuracy: 0.7617 - f1_score: 0.8622
  0%|          | 0/10 [03:29<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:31<?, ?it/s, best loss: ?]                                                     2/10 [=====>........................]
  0%|          | 0/10 [03:31<?, ?it/s, best loss: ?]                                                     - ETA: 16s - loss: 0.5340 - sparse_categorical_accuracy: 0.7598 - f1_score: 0.8635
  0%|          | 0/10 [03:31<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:33<?, ?it/s, best loss: ?]                                                     3/10 [========>.....................]
  0%|          | 0/10 [03:33<?, ?it/s, best loss: ?]                                                     - ETA: 14s - loss: 0.5195 - sparse_categorical_accuracy: 0.7539 - f1_score: 0.8597
  0%|          | 0/10 [03:33<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:35<?, ?it/s, best loss: ?]                                                     4/10 [===========>..................]
  0%|          | 0/10 [03:35<?, ?it/s, best loss: ?]                                                     - ETA: 11s - loss: 0.5137 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8578
  0%|          | 0/10 [03:35<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:37<?, ?it/s, best loss: ?]                                                     5/10 [==============>...............]
  0%|          | 0/10 [03:37<?, ?it/s, best loss: ?]                                                     - ETA: 9s - loss: 0.5039 - sparse_categorical_accuracy: 0.7555 - f1_score: 0.8561 
  0%|          | 0/10 [03:37<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:39<?, ?it/s, best loss: ?]                                                     6/10 [=================>............]
  0%|          | 0/10 [03:39<?, ?it/s, best loss: ?]                                                     - ETA: 7s - loss: 0.4949 - sparse_categorical_accuracy: 0.7617 - f1_score: 0.8592
  0%|          | 0/10 [03:39<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:41<?, ?it/s, best loss: ?]                                                     7/10 [====================>.........]
  0%|          | 0/10 [03:41<?, ?it/s, best loss: ?]                                                     - ETA: 5s - loss: 0.4872 - sparse_categorical_accuracy: 0.7673 - f1_score: 0.8585
  0%|          | 0/10 [03:41<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:43<?, ?it/s, best loss: ?]                                                     8/10 [=======================>......]
  0%|          | 0/10 [03:43<?, ?it/s, best loss: ?]                                                     - ETA: 3s - loss: 0.4758 - sparse_categorical_accuracy: 0.7734 - f1_score: 0.8577
  0%|          | 0/10 [03:43<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:45<?, ?it/s, best loss: ?]                                                     9/10 [==========================>...]
  0%|          | 0/10 [03:45<?, ?it/s, best loss: ?]                                                     - ETA: 1s - loss: 0.4677 - sparse_categorical_accuracy: 0.7769 - f1_score: 0.8582
  0%|          | 0/10 [03:45<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/10 [03:48<?, ?it/s, best loss: ?]                                                    10/10 [==============================]
  0%|          | 0/10 [03:48<?, ?it/s, best loss: ?]                                                     - 21s 2s/step - loss: 0.4592 - sparse_categorical_accuracy: 0.7812 - f1_score: 0.8571 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.7208 - val_f1_score: 0.8406

  0%|          | 0/10 [03:48<?, ?it/s, best loss: ?]                                                    0.5886848568916321
  0%|          | 0/10 [03:50<?, ?it/s, best loss: ?] 10%|█         | 1/10 [03:50<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              Layer (type)                 Output Shape              Param #   
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              conv2d_12 (Conv2D)           (None, 299, 299, 46)      1288      
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              conv2d_13 (Conv2D)           (None, 299, 299, 46)      19090     
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_6 (MaxPooling2 (None, 149, 149, 46)      0         
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_6 (Batch (None, 149, 149, 46)      184       
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              conv2d_14 (Conv2D)           (None, 149, 149, 46)      19090     
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              conv2d_15 (Conv2D)           (None, 149, 149, 46)      19090     
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_7 (MaxPooling2 (None, 74, 74, 46)        0         
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_7 (Batch (None, 74, 74, 46)        184       
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              conv2d_16 (Conv2D)           (None, 74, 74, 46)        19090     
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              conv2d_17 (Conv2D)           (None, 74, 74, 46)        19090     
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_8 (MaxPooling2 (None, 37, 37, 46)        0         
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_8 (Batch (None, 37, 37, 46)        184       
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              conv2d_18 (Conv2D)           (None, 37, 37, 46)        19090     
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              conv2d_19 (Conv2D)           (None, 37, 37, 46)        19090     
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_9 (MaxPooling2 (None, 18, 18, 46)        0         
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_9 (Batch (None, 18, 18, 46)        184       
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              flatten_1 (Flatten)          (None, 14904)             0         
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              dense_3 (Dense)              (None, 91)                1356355   
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              dropout_2 (Dropout)          (None, 91)                0         
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              dense_4 (Dense)              (None, 91)                8372      
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              dropout_3 (Dropout)          (None, 91)                0         
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              dense_5 (Dense)              (None, 91)                8372      
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              dropout_4 (Dropout)          (None, 91)                0         
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              dense_6 (Dense)              (None, 2)                 184       
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              Total params: 1,508,937
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              Trainable params: 1,508,569
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              Non-trainable params: 368
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              None
 10%|█         | 1/10 [03:56<34:37, 230.84s/it, best loss: 0.5886848568916321]2019-03-30 13:15:17.486666: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                              Epoch 1/2
 10%|█         | 1/10 [04:13<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 10%|█         | 1/10 [05:59<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16:01 - loss: 1.8058 - sparse_categorical_accuracy: 0.3281 - f1_score: 0.8571
 10%|█         | 1/10 [05:59<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [06:02<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 10%|█         | 1/10 [06:02<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 7:15 - loss: 1.4366 - sparse_categorical_accuracy: 0.4316 - f1_score: 0.8659 
 10%|█         | 1/10 [06:02<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [06:04<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 10%|█         | 1/10 [06:04<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4:18 - loss: 1.2855 - sparse_categorical_accuracy: 0.5000 - f1_score: 0.8596
 10%|█         | 1/10 [06:04<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [06:05<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 10%|█         | 1/10 [06:05<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:49 - loss: 1.2812 - sparse_categorical_accuracy: 0.5264 - f1_score: 0.8583
 10%|█         | 1/10 [06:05<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [06:08<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 10%|█         | 1/10 [06:08<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:54 - loss: 1.2436 - sparse_categorical_accuracy: 0.5531 - f1_score: 0.8565
 10%|█         | 1/10 [06:08<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [06:09<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 10%|█         | 1/10 [06:09<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:17 - loss: 1.1799 - sparse_categorical_accuracy: 0.5697 - f1_score: 0.8536
 10%|█         | 1/10 [06:09<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [06:11<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 10%|█         | 1/10 [06:11<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 50s - loss: 1.1383 - sparse_categorical_accuracy: 0.5809 - f1_score: 0.8552 
 10%|█         | 1/10 [06:11<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [06:14<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 10%|█         | 1/10 [06:14<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 30s - loss: 1.0986 - sparse_categorical_accuracy: 0.5923 - f1_score: 0.8545
 10%|█         | 1/10 [06:14<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [06:16<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 10%|█         | 1/10 [06:16<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 13s - loss: 1.0646 - sparse_categorical_accuracy: 0.5994 - f1_score: 0.8536
 10%|█         | 1/10 [06:16<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:19<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 10%|█         | 1/10 [07:19<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - 186s 19s/step - loss: 1.0307 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8519 - val_loss: 1.1836 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 10%|█         | 1/10 [07:19<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              Epoch 2/2
 10%|█         | 1/10 [07:19<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 10%|█         | 1/10 [07:21<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 18s - loss: 0.7559 - sparse_categorical_accuracy: 0.6641 - f1_score: 0.8364
 10%|█         | 1/10 [07:21<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:23<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 10%|█         | 1/10 [07:23<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16s - loss: 0.7299 - sparse_categorical_accuracy: 0.6953 - f1_score: 0.8455
 10%|█         | 1/10 [07:23<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:25<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 10%|█         | 1/10 [07:25<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 0.7741 - sparse_categorical_accuracy: 0.6992 - f1_score: 0.8494
 10%|█         | 1/10 [07:25<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:27<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 10%|█         | 1/10 [07:27<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 12s - loss: 0.7725 - sparse_categorical_accuracy: 0.7031 - f1_score: 0.8545
 10%|█         | 1/10 [07:27<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:29<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 10%|█         | 1/10 [07:29<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10s - loss: 0.7491 - sparse_categorical_accuracy: 0.6961 - f1_score: 0.8545
 10%|█         | 1/10 [07:29<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:31<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 10%|█         | 1/10 [07:31<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8s - loss: 0.7398 - sparse_categorical_accuracy: 0.7038 - f1_score: 0.8554 
 10%|█         | 1/10 [07:31<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:33<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 10%|█         | 1/10 [07:33<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6s - loss: 0.7254 - sparse_categorical_accuracy: 0.7081 - f1_score: 0.8552
 10%|█         | 1/10 [07:33<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:35<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 10%|█         | 1/10 [07:35<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4s - loss: 0.7091 - sparse_categorical_accuracy: 0.7095 - f1_score: 0.8539
 10%|█         | 1/10 [07:35<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:37<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 10%|█         | 1/10 [07:37<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2s - loss: 0.7051 - sparse_categorical_accuracy: 0.7075 - f1_score: 0.8542
 10%|█         | 1/10 [07:37<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              
 10%|█         | 1/10 [07:41<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 10%|█         | 1/10 [07:41<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                               - 22s 2s/step - loss: 0.6981 - sparse_categorical_accuracy: 0.7090 - f1_score: 0.8550 - val_loss: 0.7372 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 10%|█         | 1/10 [07:41<34:37, 230.84s/it, best loss: 0.5886848568916321]                                                                              0.7372474670410156
 10%|█         | 1/10 [07:45<34:37, 230.84s/it, best loss: 0.5886848568916321] 20%|██        | 2/10 [07:45<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              Layer (type)                 Output Shape              Param #   
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_20 (Conv2D)           (None, 299, 299, 65)      1820      
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_21 (Conv2D)           (None, 299, 299, 65)      38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_10 (MaxPooling (None, 149, 149, 65)      0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_10 (Batc (None, 149, 149, 65)      260       
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_22 (Conv2D)           (None, 149, 149, 65)      38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_23 (Conv2D)           (None, 149, 149, 65)      38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_11 (MaxPooling (None, 74, 74, 65)        0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_11 (Batc (None, 74, 74, 65)        260       
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_24 (Conv2D)           (None, 74, 74, 65)        38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_25 (Conv2D)           (None, 74, 74, 65)        38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_12 (MaxPooling (None, 37, 37, 65)        0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_12 (Batc (None, 37, 37, 65)        260       
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_26 (Conv2D)           (None, 37, 37, 65)        38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_27 (Conv2D)           (None, 37, 37, 65)        38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_13 (MaxPooling (None, 18, 18, 65)        0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_13 (Batc (None, 18, 18, 65)        260       
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_28 (Conv2D)           (None, 18, 18, 65)        38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_29 (Conv2D)           (None, 18, 18, 65)        38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_14 (MaxPooling (None, 9, 9, 65)          0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_14 (Batc (None, 9, 9, 65)          260       
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_30 (Conv2D)           (None, 9, 9, 65)          38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              conv2d_31 (Conv2D)           (None, 9, 9, 65)          38090     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_15 (MaxPooling (None, 4, 4, 65)          0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_15 (Batc (None, 4, 4, 65)          260       
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              flatten_2 (Flatten)          (None, 1040)              0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dense_7 (Dense)              (None, 56)                58296     
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dropout_5 (Dropout)          (None, 56)                0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dense_8 (Dense)              (None, 56)                3192      
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dropout_6 (Dropout)          (None, 56)                0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dense_9 (Dense)              (None, 56)                3192      
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dropout_7 (Dropout)          (None, 56)                0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dense_10 (Dense)             (None, 56)                3192      
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dropout_8 (Dropout)          (None, 56)                0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dense_11 (Dense)             (None, 56)                3192      
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dropout_9 (Dropout)          (None, 56)                0         
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              dense_12 (Dense)             (None, 2)                 114       
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              Total params: 493,548
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              Trainable params: 492,768
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              Non-trainable params: 780
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              None
 20%|██        | 2/10 [07:51<30:55, 231.89s/it, best loss: 0.5886848568916321]2019-03-30 13:19:12.304505: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                              Epoch 1/2
 20%|██        | 2/10 [08:13<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 20%|██        | 2/10 [10:11<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 17:43 - loss: 3.4926 - sparse_categorical_accuracy: 0.6562 - f1_score: 0.6761
 20%|██        | 2/10 [10:11<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [10:13<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 20%|██        | 2/10 [10:13<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8:01 - loss: 3.5459 - sparse_categorical_accuracy: 0.6250 - f1_score: 0.7615 
 20%|██        | 2/10 [10:13<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [10:15<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 20%|██        | 2/10 [10:15<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4:45 - loss: 3.5221 - sparse_categorical_accuracy: 0.6328 - f1_score: 0.7992
 20%|██        | 2/10 [10:15<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [10:17<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 20%|██        | 2/10 [10:17<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 3:06 - loss: 3.5122 - sparse_categorical_accuracy: 0.6348 - f1_score: 0.8137
 20%|██        | 2/10 [10:17<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [10:19<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 20%|██        | 2/10 [10:19<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:06 - loss: 3.5882 - sparse_categorical_accuracy: 0.6305 - f1_score: 0.8234
 20%|██        | 2/10 [10:19<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [10:21<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 20%|██        | 2/10 [10:21<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:25 - loss: 3.6513 - sparse_categorical_accuracy: 0.6335 - f1_score: 0.8315
 20%|██        | 2/10 [10:21<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [10:23<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 20%|██        | 2/10 [10:23<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 55s - loss: 3.6010 - sparse_categorical_accuracy: 0.6350 - f1_score: 0.8370 
 20%|██        | 2/10 [10:23<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [10:25<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 20%|██        | 2/10 [10:25<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 33s - loss: 3.5864 - sparse_categorical_accuracy: 0.6362 - f1_score: 0.8372
 20%|██        | 2/10 [10:25<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [10:28<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 20%|██        | 2/10 [10:28<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 3.6086 - sparse_categorical_accuracy: 0.6311 - f1_score: 0.8380
 20%|██        | 2/10 [10:28<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:35<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 20%|██        | 2/10 [11:35<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - 203s 20s/step - loss: 3.6364 - sparse_categorical_accuracy: 0.6289 - f1_score: 0.8386 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 20%|██        | 2/10 [11:35<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              Epoch 2/2
 20%|██        | 2/10 [11:35<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 20%|██        | 2/10 [11:37<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 18s - loss: 3.2228 - sparse_categorical_accuracy: 0.6094 - f1_score: 0.8468
 20%|██        | 2/10 [11:37<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:39<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 20%|██        | 2/10 [11:39<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16s - loss: 3.2750 - sparse_categorical_accuracy: 0.6309 - f1_score: 0.8545
 20%|██        | 2/10 [11:39<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:42<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 20%|██        | 2/10 [11:42<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 3.2425 - sparse_categorical_accuracy: 0.6367 - f1_score: 0.8511
 20%|██        | 2/10 [11:42<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:44<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 20%|██        | 2/10 [11:44<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 12s - loss: 3.3215 - sparse_categorical_accuracy: 0.6338 - f1_score: 0.8520
 20%|██        | 2/10 [11:44<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:46<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 20%|██        | 2/10 [11:46<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10s - loss: 3.3520 - sparse_categorical_accuracy: 0.6328 - f1_score: 0.8560
 20%|██        | 2/10 [11:46<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:48<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 20%|██        | 2/10 [11:48<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8s - loss: 3.3982 - sparse_categorical_accuracy: 0.6361 - f1_score: 0.8541 
 20%|██        | 2/10 [11:48<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:50<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 20%|██        | 2/10 [11:50<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6s - loss: 3.3063 - sparse_categorical_accuracy: 0.6429 - f1_score: 0.8545
 20%|██        | 2/10 [11:50<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:52<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 20%|██        | 2/10 [11:52<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4s - loss: 3.3369 - sparse_categorical_accuracy: 0.6421 - f1_score: 0.8561
 20%|██        | 2/10 [11:52<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:54<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 20%|██        | 2/10 [11:54<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2s - loss: 3.2876 - sparse_categorical_accuracy: 0.6432 - f1_score: 0.8554
 20%|██        | 2/10 [11:54<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              
 20%|██        | 2/10 [11:58<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 20%|██        | 2/10 [11:58<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                               - 22s 2s/step - loss: 3.2380 - sparse_categorical_accuracy: 0.6473 - f1_score: 0.8565 - val_loss: 1.8580 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 20%|██        | 2/10 [11:58<30:55, 231.89s/it, best loss: 0.5886848568916321]                                                                              1.8579769134521484
 20%|██        | 2/10 [12:05<30:55, 231.89s/it, best loss: 0.5886848568916321] 30%|███       | 3/10 [12:05<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              Layer (type)                 Output Shape              Param #   
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_32 (Conv2D)           (None, 299, 299, 80)      2240      
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_33 (Conv2D)           (None, 299, 299, 80)      57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_16 (MaxPooling (None, 149, 149, 80)      0         
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_16 (Batc (None, 149, 149, 80)      320       
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_34 (Conv2D)           (None, 149, 149, 80)      57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_35 (Conv2D)           (None, 149, 149, 80)      57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_17 (MaxPooling (None, 74, 74, 80)        0         
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_17 (Batc (None, 74, 74, 80)        320       
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_36 (Conv2D)           (None, 74, 74, 80)        57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_37 (Conv2D)           (None, 74, 74, 80)        57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_18 (MaxPooling (None, 37, 37, 80)        0         
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_18 (Batc (None, 37, 37, 80)        320       
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_38 (Conv2D)           (None, 37, 37, 80)        57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_39 (Conv2D)           (None, 37, 37, 80)        57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_19 (MaxPooling (None, 18, 18, 80)        0         
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_19 (Batc (None, 18, 18, 80)        320       
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_40 (Conv2D)           (None, 18, 18, 80)        57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_41 (Conv2D)           (None, 18, 18, 80)        57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_20 (MaxPooling (None, 9, 9, 80)          0         
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_20 (Batc (None, 9, 9, 80)          320       
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_42 (Conv2D)           (None, 9, 9, 80)          57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              conv2d_43 (Conv2D)           (None, 9, 9, 80)          57680     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_21 (MaxPooling (None, 4, 4, 80)          0         
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_21 (Batc (None, 4, 4, 80)          320       
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              flatten_3 (Flatten)          (None, 1280)              0         
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              dense_13 (Dense)             (None, 63)                80703     
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              dropout_10 (Dropout)         (None, 63)                0         
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              dense_14 (Dense)             (None, 2)                 128       
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              Total params: 719,471
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              Trainable params: 718,511
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              Non-trainable params: 960
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              None
 30%|███       | 3/10 [12:11<28:02, 240.30s/it, best loss: 0.5886848568916321]2019-03-30 13:23:32.006573: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                              Epoch 1/2
 30%|███       | 3/10 [12:42<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 30%|███       | 3/10 [14:39<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 17:38 - loss: 0.8175 - sparse_categorical_accuracy: 0.5820 - f1_score: 0.8520
 30%|███       | 3/10 [14:39<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [14:42<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 30%|███       | 3/10 [14:42<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8:00 - loss: 0.7805 - sparse_categorical_accuracy: 0.6582 - f1_score: 0.8533 
 30%|███       | 3/10 [14:42<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [14:44<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 30%|███       | 3/10 [14:44<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4:44 - loss: 0.7543 - sparse_categorical_accuracy: 0.6771 - f1_score: 0.8563
 30%|███       | 3/10 [14:44<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [14:46<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 30%|███       | 3/10 [14:46<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 3:06 - loss: 0.7329 - sparse_categorical_accuracy: 0.6904 - f1_score: 0.8565
 30%|███       | 3/10 [14:46<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [14:48<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 30%|███       | 3/10 [14:48<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:06 - loss: 0.6928 - sparse_categorical_accuracy: 0.7102 - f1_score: 0.8571
 30%|███       | 3/10 [14:48<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [14:50<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 30%|███       | 3/10 [14:50<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:25 - loss: 0.6342 - sparse_categorical_accuracy: 0.7344 - f1_score: 0.8571
 30%|███       | 3/10 [14:50<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [14:52<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 30%|███       | 3/10 [14:52<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 55s - loss: 0.6186 - sparse_categorical_accuracy: 0.7344 - f1_score: 0.8553 
 30%|███       | 3/10 [14:52<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [14:54<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 30%|███       | 3/10 [14:54<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 33s - loss: 0.6051 - sparse_categorical_accuracy: 0.7393 - f1_score: 0.8568
 30%|███       | 3/10 [14:54<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [14:56<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 30%|███       | 3/10 [14:56<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 0.5895 - sparse_categorical_accuracy: 0.7391 - f1_score: 0.8545
 30%|███       | 3/10 [14:56<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 30%|███       | 3/10 [16:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - 209s 21s/step - loss: 0.5725 - sparse_categorical_accuracy: 0.7445 - f1_score: 0.8548 - val_loss: 4.0449 - val_sparse_categorical_accuracy: 0.2750 - val_f1_score: 0.8406

 30%|███       | 3/10 [16:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              Epoch 2/2
 30%|███       | 3/10 [16:11<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 30%|███       | 3/10 [16:13<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 18s - loss: 0.4793 - sparse_categorical_accuracy: 0.7812 - f1_score: 0.8673
 30%|███       | 3/10 [16:13<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:15<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 30%|███       | 3/10 [16:15<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16s - loss: 0.4396 - sparse_categorical_accuracy: 0.8008 - f1_score: 0.8583
 30%|███       | 3/10 [16:15<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:17<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 30%|███       | 3/10 [16:17<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 0.4080 - sparse_categorical_accuracy: 0.8177 - f1_score: 0.8579
 30%|███       | 3/10 [16:17<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:19<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 30%|███       | 3/10 [16:19<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 12s - loss: 0.4045 - sparse_categorical_accuracy: 0.8145 - f1_score: 0.8571
 30%|███       | 3/10 [16:19<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:21<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 30%|███       | 3/10 [16:21<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10s - loss: 0.3835 - sparse_categorical_accuracy: 0.8219 - f1_score: 0.8556
 30%|███       | 3/10 [16:21<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:23<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 30%|███       | 3/10 [16:23<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8s - loss: 0.3799 - sparse_categorical_accuracy: 0.8255 - f1_score: 0.8579 
 30%|███       | 3/10 [16:23<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:25<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 30%|███       | 3/10 [16:25<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6s - loss: 0.3675 - sparse_categorical_accuracy: 0.8315 - f1_score: 0.8596
 30%|███       | 3/10 [16:25<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:27<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 30%|███       | 3/10 [16:27<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4s - loss: 0.3522 - sparse_categorical_accuracy: 0.8374 - f1_score: 0.8603
 30%|███       | 3/10 [16:27<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:29<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 30%|███       | 3/10 [16:29<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2s - loss: 0.3415 - sparse_categorical_accuracy: 0.8407 - f1_score: 0.8582
 30%|███       | 3/10 [16:29<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              
 30%|███       | 3/10 [16:33<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 30%|███       | 3/10 [16:33<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                               - 22s 2s/step - loss: 0.3437 - sparse_categorical_accuracy: 0.8410 - f1_score: 0.8571 - val_loss: 5.5054 - val_sparse_categorical_accuracy: 0.2750 - val_f1_score: 0.8406

 30%|███       | 3/10 [16:33<28:02, 240.30s/it, best loss: 0.5886848568916321]                                                                              5.505434513092041
 30%|███       | 3/10 [16:43<28:02, 240.30s/it, best loss: 0.5886848568916321] 40%|████      | 4/10 [16:43<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              Layer (type)                 Output Shape              Param #   
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              conv2d_44 (Conv2D)           (None, 299, 299, 24)      672       
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              conv2d_45 (Conv2D)           (None, 299, 299, 24)      5208      
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_22 (MaxPooling (None, 149, 149, 24)      0         
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_22 (Batc (None, 149, 149, 24)      96        
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              conv2d_46 (Conv2D)           (None, 149, 149, 24)      5208      
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              conv2d_47 (Conv2D)           (None, 149, 149, 24)      5208      
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_23 (MaxPooling (None, 74, 74, 24)        0         
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_23 (Batc (None, 74, 74, 24)        96        
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              conv2d_48 (Conv2D)           (None, 74, 74, 24)        5208      
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              conv2d_49 (Conv2D)           (None, 74, 74, 24)        5208      
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_24 (MaxPooling (None, 37, 37, 24)        0         
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_24 (Batc (None, 37, 37, 24)        96        
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              conv2d_50 (Conv2D)           (None, 37, 37, 24)        5208      
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              conv2d_51 (Conv2D)           (None, 37, 37, 24)        5208      
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_25 (MaxPooling (None, 18, 18, 24)        0         
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_25 (Batc (None, 18, 18, 24)        96        
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              flatten_4 (Flatten)          (None, 7776)              0         
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              dense_15 (Dense)             (None, 72)                559944    
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              dropout_11 (Dropout)         (None, 72)                0         
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              dense_16 (Dense)             (None, 72)                5256      
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              dropout_12 (Dropout)         (None, 72)                0         
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              dense_17 (Dense)             (None, 72)                5256      
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              dropout_13 (Dropout)         (None, 72)                0         
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              dense_18 (Dense)             (None, 2)                 146       
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              Total params: 608,114
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              Trainable params: 607,922
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              Non-trainable params: 192
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              None
 40%|████      | 4/10 [16:49<25:11, 251.86s/it, best loss: 0.5886848568916321]2019-03-30 13:28:09.891887: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                              Epoch 1/2
 40%|████      | 4/10 [17:28<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 40%|████      | 4/10 [19:25<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 17:40 - loss: 3.5019 - sparse_categorical_accuracy: 0.6328 - f1_score: 0.7093
 40%|████      | 4/10 [19:25<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [19:28<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 40%|████      | 4/10 [19:28<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8:00 - loss: 3.5337 - sparse_categorical_accuracy: 0.6309 - f1_score: 0.7920 
 40%|████      | 4/10 [19:28<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [19:30<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 40%|████      | 4/10 [19:30<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4:45 - loss: 3.7118 - sparse_categorical_accuracy: 0.6159 - f1_score: 0.8094
 40%|████      | 4/10 [19:30<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [19:32<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 40%|████      | 4/10 [19:32<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 3:06 - loss: 3.7659 - sparse_categorical_accuracy: 0.6221 - f1_score: 0.8233
 40%|████      | 4/10 [19:32<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [19:34<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 40%|████      | 4/10 [19:34<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:06 - loss: 3.6236 - sparse_categorical_accuracy: 0.6297 - f1_score: 0.8269
 40%|████      | 4/10 [19:34<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [19:36<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 40%|████      | 4/10 [19:36<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:25 - loss: 3.6131 - sparse_categorical_accuracy: 0.6263 - f1_score: 0.8328
 40%|████      | 4/10 [19:36<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [19:38<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 40%|████      | 4/10 [19:38<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 55s - loss: 3.6804 - sparse_categorical_accuracy: 0.6200 - f1_score: 0.8356 
 40%|████      | 4/10 [19:38<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [19:40<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 40%|████      | 4/10 [19:40<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 33s - loss: 3.6767 - sparse_categorical_accuracy: 0.6172 - f1_score: 0.8395
 40%|████      | 4/10 [19:40<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [19:42<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 40%|████      | 4/10 [19:42<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 3.7314 - sparse_categorical_accuracy: 0.6124 - f1_score: 0.8395
 40%|████      | 4/10 [19:42<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [20:54<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 40%|████      | 4/10 [20:54<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - 207s 21s/step - loss: 3.7186 - sparse_categorical_accuracy: 0.6145 - f1_score: 0.8407 - val_loss: 1.0500 - val_sparse_categorical_accuracy: 0.2625 - val_f1_score: 0.8406

 40%|████      | 4/10 [20:54<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              Epoch 2/2
 40%|████      | 4/10 [20:54<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 40%|████      | 4/10 [20:56<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 18s - loss: 3.5185 - sparse_categorical_accuracy: 0.6289 - f1_score: 0.8571
 40%|████      | 4/10 [20:56<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [20:58<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 40%|████      | 4/10 [20:58<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16s - loss: 3.2815 - sparse_categorical_accuracy: 0.6406 - f1_score: 0.8634
 40%|████      | 4/10 [20:58<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [21:00<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 40%|████      | 4/10 [21:00<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 3.3097 - sparse_categorical_accuracy: 0.6419 - f1_score: 0.8570
 40%|████      | 4/10 [21:00<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [21:02<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 40%|████      | 4/10 [21:02<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 12s - loss: 3.3698 - sparse_categorical_accuracy: 0.6396 - f1_score: 0.8558
 40%|████      | 4/10 [21:02<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [21:04<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 40%|████      | 4/10 [21:04<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10s - loss: 3.4492 - sparse_categorical_accuracy: 0.6328 - f1_score: 0.8555
 40%|████      | 4/10 [21:04<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [21:06<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 40%|████      | 4/10 [21:06<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8s - loss: 3.5655 - sparse_categorical_accuracy: 0.6257 - f1_score: 0.8537 
 40%|████      | 4/10 [21:06<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [21:08<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 40%|████      | 4/10 [21:08<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6s - loss: 3.5635 - sparse_categorical_accuracy: 0.6244 - f1_score: 0.8512
 40%|████      | 4/10 [21:08<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [21:10<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 40%|████      | 4/10 [21:10<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4s - loss: 3.6315 - sparse_categorical_accuracy: 0.6235 - f1_score: 0.8532
 40%|████      | 4/10 [21:10<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [21:12<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 40%|████      | 4/10 [21:12<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2s - loss: 3.6749 - sparse_categorical_accuracy: 0.6207 - f1_score: 0.8516
 40%|████      | 4/10 [21:12<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              
 40%|████      | 4/10 [21:16<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 40%|████      | 4/10 [21:16<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                               - 22s 2s/step - loss: 3.6954 - sparse_categorical_accuracy: 0.6207 - f1_score: 0.8517 - val_loss: 0.8282 - val_sparse_categorical_accuracy: 0.4625 - val_f1_score: 0.8406

 40%|████      | 4/10 [21:16<25:11, 251.86s/it, best loss: 0.5886848568916321]                                                                              0.8282008767127991
 40%|████      | 4/10 [21:30<25:11, 251.86s/it, best loss: 0.5886848568916321] 50%|█████     | 5/10 [21:30<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              Layer (type)                 Output Shape              Param #   
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_52 (Conv2D)           (None, 299, 299, 122)     3416      
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_53 (Conv2D)           (None, 299, 299, 122)     134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_26 (MaxPooling (None, 149, 149, 122)     0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_26 (Batc (None, 149, 149, 122)     488       
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_54 (Conv2D)           (None, 149, 149, 122)     134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_55 (Conv2D)           (None, 149, 149, 122)     134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_27 (MaxPooling (None, 74, 74, 122)       0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_27 (Batc (None, 74, 74, 122)       488       
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_56 (Conv2D)           (None, 74, 74, 122)       134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_57 (Conv2D)           (None, 74, 74, 122)       134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_28 (MaxPooling (None, 37, 37, 122)       0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_28 (Batc (None, 37, 37, 122)       488       
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_58 (Conv2D)           (None, 37, 37, 122)       134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_59 (Conv2D)           (None, 37, 37, 122)       134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_29 (MaxPooling (None, 18, 18, 122)       0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_29 (Batc (None, 18, 18, 122)       488       
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_60 (Conv2D)           (None, 18, 18, 122)       134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_61 (Conv2D)           (None, 18, 18, 122)       134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_30 (MaxPooling (None, 9, 9, 122)         0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_30 (Batc (None, 9, 9, 122)         488       
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_62 (Conv2D)           (None, 9, 9, 122)         134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_63 (Conv2D)           (None, 9, 9, 122)         134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_31 (MaxPooling (None, 4, 4, 122)         0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_31 (Batc (None, 4, 4, 122)         488       
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_64 (Conv2D)           (None, 4, 4, 122)         134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              conv2d_65 (Conv2D)           (None, 4, 4, 122)         134078    
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_32 (MaxPooling (None, 2, 2, 122)         0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_32 (Batc (None, 2, 2, 122)         488       
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              flatten_5 (Flatten)          (None, 488)               0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              dense_19 (Dense)             (None, 27)                13203     
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              dropout_14 (Dropout)         (None, 27)                0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              dense_20 (Dense)             (None, 27)                756       
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              dropout_15 (Dropout)         (None, 27)                0         
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              dense_21 (Dense)             (None, 2)                 56        
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              Total params: 1,763,861
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              Trainable params: 1,762,153
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              Non-trainable params: 1,708
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              None
 50%|█████     | 5/10 [21:36<21:50, 262.17s/it, best loss: 0.5886848568916321]2019-03-30 13:32:57.586010: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                              Epoch 1/2
 50%|█████     | 5/10 [22:26<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 50%|█████     | 5/10 [24:38<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 19:45 - loss: 1.1927 - sparse_categorical_accuracy: 0.5508 - f1_score: 0.8514
 50%|█████     | 5/10 [24:38<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [24:40<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 50%|█████     | 5/10 [24:40<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8:55 - loss: 1.0299 - sparse_categorical_accuracy: 0.5488 - f1_score: 0.8593 
 50%|█████     | 5/10 [24:40<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [24:42<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 50%|█████     | 5/10 [24:42<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 5:17 - loss: 0.9349 - sparse_categorical_accuracy: 0.5807 - f1_score: 0.8620
 50%|█████     | 5/10 [24:42<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [24:44<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 50%|█████     | 5/10 [24:44<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 3:26 - loss: 0.8767 - sparse_categorical_accuracy: 0.5977 - f1_score: 0.8569
 50%|█████     | 5/10 [24:44<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [24:46<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 50%|█████     | 5/10 [24:46<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:20 - loss: 0.8511 - sparse_categorical_accuracy: 0.6148 - f1_score: 0.8543
 50%|█████     | 5/10 [24:46<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [24:48<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 50%|█████     | 5/10 [24:48<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:34 - loss: 0.8224 - sparse_categorical_accuracy: 0.6230 - f1_score: 0.8561
 50%|█████     | 5/10 [24:48<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [24:51<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 50%|█████     | 5/10 [24:51<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:01 - loss: 0.8029 - sparse_categorical_accuracy: 0.6300 - f1_score: 0.8577
 50%|█████     | 5/10 [24:51<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [24:53<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 50%|█████     | 5/10 [24:53<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 36s - loss: 0.7806 - sparse_categorical_accuracy: 0.6338 - f1_score: 0.8576 
 50%|█████     | 5/10 [24:53<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [24:55<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 50%|█████     | 5/10 [24:55<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16s - loss: 0.7713 - sparse_categorical_accuracy: 0.6367 - f1_score: 0.8576
 50%|█████     | 5/10 [24:55<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:18<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 50%|█████     | 5/10 [26:18<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - 231s 23s/step - loss: 0.7510 - sparse_categorical_accuracy: 0.6461 - f1_score: 0.8593 - val_loss: 4.4325 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 50%|█████     | 5/10 [26:18<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              Epoch 2/2
 50%|█████     | 5/10 [26:18<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 50%|█████     | 5/10 [26:20<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 18s - loss: 0.6307 - sparse_categorical_accuracy: 0.7031 - f1_score: 0.8673
 50%|█████     | 5/10 [26:20<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:22<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 50%|█████     | 5/10 [26:22<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16s - loss: 0.6370 - sparse_categorical_accuracy: 0.7070 - f1_score: 0.8673
 50%|█████     | 5/10 [26:22<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:24<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 50%|█████     | 5/10 [26:24<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 0.6286 - sparse_categorical_accuracy: 0.7031 - f1_score: 0.8587
 50%|█████     | 5/10 [26:24<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:26<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 50%|█████     | 5/10 [26:26<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 12s - loss: 0.6338 - sparse_categorical_accuracy: 0.6895 - f1_score: 0.8608
 50%|█████     | 5/10 [26:26<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:28<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 50%|█████     | 5/10 [26:28<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10s - loss: 0.6499 - sparse_categorical_accuracy: 0.6906 - f1_score: 0.8621
 50%|█████     | 5/10 [26:28<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:30<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 50%|█████     | 5/10 [26:30<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8s - loss: 0.6428 - sparse_categorical_accuracy: 0.6992 - f1_score: 0.8613 
 50%|█████     | 5/10 [26:30<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:33<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 50%|█████     | 5/10 [26:33<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6s - loss: 0.6439 - sparse_categorical_accuracy: 0.6959 - f1_score: 0.8585
 50%|█████     | 5/10 [26:33<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:35<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 50%|█████     | 5/10 [26:35<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4s - loss: 0.6436 - sparse_categorical_accuracy: 0.6909 - f1_score: 0.8567
 50%|█████     | 5/10 [26:35<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:37<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 50%|█████     | 5/10 [26:37<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2s - loss: 0.6413 - sparse_categorical_accuracy: 0.6927 - f1_score: 0.8547
 50%|█████     | 5/10 [26:37<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              
 50%|█████     | 5/10 [26:41<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 50%|█████     | 5/10 [26:41<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                               - 23s 2s/step - loss: 0.6283 - sparse_categorical_accuracy: 0.7008 - f1_score: 0.8560 - val_loss: 8.8767 - val_sparse_categorical_accuracy: 0.3958 - val_f1_score: 0.8406

 50%|█████     | 5/10 [26:41<21:50, 262.17s/it, best loss: 0.5886848568916321]                                                                              8.876663208007812
 50%|█████     | 5/10 [26:59<21:50, 262.17s/it, best loss: 0.5886848568916321] 60%|██████    | 6/10 [26:59<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              Layer (type)                 Output Shape              Param #   
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_66 (Conv2D)           (None, 299, 299, 74)      2072      
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_67 (Conv2D)           (None, 299, 299, 74)      49358     
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_33 (MaxPooling (None, 149, 149, 74)      0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_33 (Batc (None, 149, 149, 74)      296       
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_68 (Conv2D)           (None, 149, 149, 74)      49358     
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_69 (Conv2D)           (None, 149, 149, 74)      49358     
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_34 (MaxPooling (None, 74, 74, 74)        0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_34 (Batc (None, 74, 74, 74)        296       
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_70 (Conv2D)           (None, 74, 74, 74)        49358     
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_71 (Conv2D)           (None, 74, 74, 74)        49358     
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_35 (MaxPooling (None, 37, 37, 74)        0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_35 (Batc (None, 37, 37, 74)        296       
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_72 (Conv2D)           (None, 37, 37, 74)        49358     
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_73 (Conv2D)           (None, 37, 37, 74)        49358     
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_36 (MaxPooling (None, 18, 18, 74)        0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_36 (Batc (None, 18, 18, 74)        296       
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_74 (Conv2D)           (None, 18, 18, 74)        49358     
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              conv2d_75 (Conv2D)           (None, 18, 18, 74)        49358     
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_37 (MaxPooling (None, 9, 9, 74)          0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_37 (Batc (None, 9, 9, 74)          296       
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              flatten_6 (Flatten)          (None, 5994)              0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              dense_22 (Dense)             (None, 21)                125895    
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              dropout_16 (Dropout)         (None, 21)                0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              dense_23 (Dense)             (None, 21)                462       
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              dropout_17 (Dropout)         (None, 21)                0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              dense_24 (Dense)             (None, 21)                462       
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              dropout_18 (Dropout)         (None, 21)                0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              dense_25 (Dense)             (None, 21)                462       
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              dropout_19 (Dropout)         (None, 21)                0         
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              dense_26 (Dense)             (None, 2)                 44        
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              Total params: 575,099
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              Trainable params: 574,359
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              Non-trainable params: 740
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              None
 60%|██████    | 6/10 [27:05<18:49, 282.38s/it, best loss: 0.5886848568916321]2019-03-30 13:38:26.427390: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                              Epoch 1/2
 60%|██████    | 6/10 [28:08<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 60%|██████    | 6/10 [30:31<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 21:26 - loss: 1.3063 - sparse_categorical_accuracy: 0.3047 - f1_score: 0.8494
 60%|██████    | 6/10 [30:31<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [30:33<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 60%|██████    | 6/10 [30:33<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 9:39 - loss: 1.0970 - sparse_categorical_accuracy: 0.3145 - f1_score: 0.8481 
 60%|██████    | 6/10 [30:33<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [30:35<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 60%|██████    | 6/10 [30:35<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 5:43 - loss: 1.0178 - sparse_categorical_accuracy: 0.3372 - f1_score: 0.8511
 60%|██████    | 6/10 [30:35<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [30:37<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 60%|██████    | 6/10 [30:37<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 3:43 - loss: 0.9558 - sparse_categorical_accuracy: 0.3496 - f1_score: 0.8501
 60%|██████    | 6/10 [30:37<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [30:39<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 60%|██████    | 6/10 [30:39<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:31 - loss: 0.9130 - sparse_categorical_accuracy: 0.3633 - f1_score: 0.8499
 60%|██████    | 6/10 [30:39<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [30:41<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 60%|██████    | 6/10 [30:41<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:42 - loss: 0.8819 - sparse_categorical_accuracy: 0.3757 - f1_score: 0.8481
 60%|██████    | 6/10 [30:41<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [30:43<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 60%|██████    | 6/10 [30:43<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:06 - loss: 0.8615 - sparse_categorical_accuracy: 0.3862 - f1_score: 0.8498
 60%|██████    | 6/10 [30:43<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [30:45<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 60%|██████    | 6/10 [30:45<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 39s - loss: 0.8445 - sparse_categorical_accuracy: 0.4058 - f1_score: 0.8532 
 60%|██████    | 6/10 [30:45<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [30:47<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 60%|██████    | 6/10 [30:47<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 17s - loss: 0.8310 - sparse_categorical_accuracy: 0.4180 - f1_score: 0.8539
 60%|██████    | 6/10 [30:47<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:13<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 60%|██████    | 6/10 [32:13<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - 245s 25s/step - loss: 0.8182 - sparse_categorical_accuracy: 0.4313 - f1_score: 0.8550 - val_loss: 0.7727 - val_sparse_categorical_accuracy: 0.3042 - val_f1_score: 0.8406

 60%|██████    | 6/10 [32:13<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              Epoch 2/2
 60%|██████    | 6/10 [32:13<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 60%|██████    | 6/10 [32:15<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 19s - loss: 0.6871 - sparse_categorical_accuracy: 0.6328 - f1_score: 0.8597
 60%|██████    | 6/10 [32:15<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:17<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 60%|██████    | 6/10 [32:17<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16s - loss: 0.6912 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8622
 60%|██████    | 6/10 [32:17<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:19<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 60%|██████    | 6/10 [32:19<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 0.6790 - sparse_categorical_accuracy: 0.6198 - f1_score: 0.8672
 60%|██████    | 6/10 [32:19<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:21<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 60%|██████    | 6/10 [32:21<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 12s - loss: 0.6806 - sparse_categorical_accuracy: 0.6182 - f1_score: 0.8641
 60%|██████    | 6/10 [32:21<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:23<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 60%|██████    | 6/10 [32:23<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10s - loss: 0.6853 - sparse_categorical_accuracy: 0.6172 - f1_score: 0.8622
 60%|██████    | 6/10 [32:23<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:25<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 60%|██████    | 6/10 [32:25<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8s - loss: 0.6837 - sparse_categorical_accuracy: 0.6270 - f1_score: 0.8587 
 60%|██████    | 6/10 [32:25<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:28<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 60%|██████    | 6/10 [32:28<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6s - loss: 0.6785 - sparse_categorical_accuracy: 0.6345 - f1_score: 0.8574
 60%|██████    | 6/10 [32:28<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:29<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 60%|██████    | 6/10 [32:29<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4s - loss: 0.6781 - sparse_categorical_accuracy: 0.6362 - f1_score: 0.8561
 60%|██████    | 6/10 [32:29<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:32<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 60%|██████    | 6/10 [32:32<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2s - loss: 0.6733 - sparse_categorical_accuracy: 0.6445 - f1_score: 0.8559
 60%|██████    | 6/10 [32:32<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              
 60%|██████    | 6/10 [32:36<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 60%|██████    | 6/10 [32:36<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                               - 23s 2s/step - loss: 0.6694 - sparse_categorical_accuracy: 0.6480 - f1_score: 0.8558 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.7292 - val_f1_score: 0.8406

 60%|██████    | 6/10 [32:36<18:49, 282.38s/it, best loss: 0.5886848568916321]                                                                              0.670020341873169
 60%|██████    | 6/10 [33:00<18:49, 282.38s/it, best loss: 0.5886848568916321] 70%|███████   | 7/10 [33:00<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              Layer (type)                 Output Shape              Param #   
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_76 (Conv2D)           (None, 299, 299, 110)     3080      
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_77 (Conv2D)           (None, 299, 299, 110)     109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_38 (MaxPooling (None, 149, 149, 110)     0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_38 (Batc (None, 149, 149, 110)     440       
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_78 (Conv2D)           (None, 149, 149, 110)     109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_79 (Conv2D)           (None, 149, 149, 110)     109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_39 (MaxPooling (None, 74, 74, 110)       0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_39 (Batc (None, 74, 74, 110)       440       
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_80 (Conv2D)           (None, 74, 74, 110)       109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_81 (Conv2D)           (None, 74, 74, 110)       109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_40 (MaxPooling (None, 37, 37, 110)       0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_40 (Batc (None, 37, 37, 110)       440       
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_82 (Conv2D)           (None, 37, 37, 110)       109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_83 (Conv2D)           (None, 37, 37, 110)       109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_41 (MaxPooling (None, 18, 18, 110)       0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_41 (Batc (None, 18, 18, 110)       440       
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_84 (Conv2D)           (None, 18, 18, 110)       109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_85 (Conv2D)           (None, 18, 18, 110)       109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_42 (MaxPooling (None, 9, 9, 110)         0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_42 (Batc (None, 9, 9, 110)         440       
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_86 (Conv2D)           (None, 9, 9, 110)         109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_87 (Conv2D)           (None, 9, 9, 110)         109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_43 (MaxPooling (None, 4, 4, 110)         0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_43 (Batc (None, 4, 4, 110)         440       
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_88 (Conv2D)           (None, 4, 4, 110)         109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              conv2d_89 (Conv2D)           (None, 4, 4, 110)         109010    
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_44 (MaxPooling (None, 2, 2, 110)         0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_44 (Batc (None, 2, 2, 110)         440       
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              flatten_7 (Flatten)          (None, 440)               0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              dense_27 (Dense)             (None, 60)                26460     
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              dropout_20 (Dropout)         (None, 60)                0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              dense_28 (Dense)             (None, 60)                3660      
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              dropout_21 (Dropout)         (None, 60)                0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              dense_29 (Dense)             (None, 60)                3660      
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              dropout_22 (Dropout)         (None, 60)                0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              dense_30 (Dense)             (None, 60)                3660      
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              dropout_23 (Dropout)         (None, 60)                0         
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              dense_31 (Dense)             (None, 2)                 122       
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              Total params: 1,460,852
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              Trainable params: 1,459,312
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              Non-trainable params: 1,540
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              None
 70%|███████   | 7/10 [33:05<15:17, 305.99s/it, best loss: 0.5886848568916321]2019-03-30 13:44:26.636393: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                              Epoch 1/2
 70%|███████   | 7/10 [34:24<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 70%|███████   | 7/10 [37:03<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 23:55 - loss: 0.6552 - sparse_categorical_accuracy: 0.6484 - f1_score: 0.8468
 70%|███████   | 7/10 [37:03<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [37:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 70%|███████   | 7/10 [37:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10:46 - loss: 0.6308 - sparse_categorical_accuracy: 0.6953 - f1_score: 0.8571
 70%|███████   | 7/10 [37:05<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [37:07<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 70%|███████   | 7/10 [37:07<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6:22 - loss: 0.6499 - sparse_categorical_accuracy: 0.6875 - f1_score: 0.8537 
 70%|███████   | 7/10 [37:07<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [37:09<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 70%|███████   | 7/10 [37:09<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4:08 - loss: 0.6566 - sparse_categorical_accuracy: 0.6885 - f1_score: 0.8493
 70%|███████   | 7/10 [37:09<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [37:12<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 70%|███████   | 7/10 [37:12<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:47 - loss: 0.6431 - sparse_categorical_accuracy: 0.6898 - f1_score: 0.8473
 70%|███████   | 7/10 [37:12<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [37:14<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 70%|███████   | 7/10 [37:14<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:53 - loss: 0.6351 - sparse_categorical_accuracy: 0.6921 - f1_score: 0.8459
 70%|███████   | 7/10 [37:14<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [37:16<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 70%|███████   | 7/10 [37:16<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:13 - loss: 0.6305 - sparse_categorical_accuracy: 0.6975 - f1_score: 0.8475
 70%|███████   | 7/10 [37:16<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [37:18<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 70%|███████   | 7/10 [37:18<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 43s - loss: 0.6235 - sparse_categorical_accuracy: 0.7061 - f1_score: 0.8497 
 70%|███████   | 7/10 [37:18<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [37:20<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 70%|███████   | 7/10 [37:20<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 19s - loss: 0.6159 - sparse_categorical_accuracy: 0.7114 - f1_score: 0.8502
 70%|███████   | 7/10 [37:20<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [38:53<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 70%|███████   | 7/10 [38:53<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - 270s 27s/step - loss: 0.6100 - sparse_categorical_accuracy: 0.7117 - f1_score: 0.8511 - val_loss: 1.0494 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 70%|███████   | 7/10 [38:53<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              Epoch 2/2
 70%|███████   | 7/10 [38:53<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 70%|███████   | 7/10 [38:55<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 18s - loss: 0.5279 - sparse_categorical_accuracy: 0.7422 - f1_score: 0.8673
 70%|███████   | 7/10 [38:55<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [38:57<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 70%|███████   | 7/10 [38:57<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16s - loss: 0.5560 - sparse_categorical_accuracy: 0.7285 - f1_score: 0.8558
 70%|███████   | 7/10 [38:57<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [38:59<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 70%|███████   | 7/10 [38:59<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 0.5536 - sparse_categorical_accuracy: 0.7279 - f1_score: 0.8519
 70%|███████   | 7/10 [38:59<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [39:02<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 70%|███████   | 7/10 [39:02<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 12s - loss: 0.5621 - sparse_categorical_accuracy: 0.7393 - f1_score: 0.8551
 70%|███████   | 7/10 [39:02<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [39:04<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 70%|███████   | 7/10 [39:04<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10s - loss: 0.5546 - sparse_categorical_accuracy: 0.7375 - f1_score: 0.8555
 70%|███████   | 7/10 [39:04<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [39:06<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 70%|███████   | 7/10 [39:06<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8s - loss: 0.5474 - sparse_categorical_accuracy: 0.7402 - f1_score: 0.8558 
 70%|███████   | 7/10 [39:06<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [39:08<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 70%|███████   | 7/10 [39:08<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6s - loss: 0.5514 - sparse_categorical_accuracy: 0.7366 - f1_score: 0.8538
 70%|███████   | 7/10 [39:08<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [39:10<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 70%|███████   | 7/10 [39:10<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4s - loss: 0.5464 - sparse_categorical_accuracy: 0.7378 - f1_score: 0.8539
 70%|███████   | 7/10 [39:10<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [39:13<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 70%|███████   | 7/10 [39:13<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2s - loss: 0.5423 - sparse_categorical_accuracy: 0.7400 - f1_score: 0.8556
 70%|███████   | 7/10 [39:13<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              
 70%|███████   | 7/10 [39:17<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 70%|███████   | 7/10 [39:17<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                               - 23s 2s/step - loss: 0.5346 - sparse_categorical_accuracy: 0.7387 - f1_score: 0.8542 - val_loss: 4.2705 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 70%|███████   | 7/10 [39:17<15:17, 305.99s/it, best loss: 0.5886848568916321]                                                                              4.270461559295654
 70%|███████   | 7/10 [39:48<15:17, 305.99s/it, best loss: 0.5886848568916321] 80%|████████  | 8/10 [39:48<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              Layer (type)                 Output Shape              Param #   
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_90 (Conv2D)           (None, 299, 299, 54)      1512      
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_91 (Conv2D)           (None, 299, 299, 54)      26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_45 (MaxPooling (None, 149, 149, 54)      0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_45 (Batc (None, 149, 149, 54)      216       
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_92 (Conv2D)           (None, 149, 149, 54)      26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_93 (Conv2D)           (None, 149, 149, 54)      26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_46 (MaxPooling (None, 74, 74, 54)        0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_46 (Batc (None, 74, 74, 54)        216       
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_94 (Conv2D)           (None, 74, 74, 54)        26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_95 (Conv2D)           (None, 74, 74, 54)        26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_47 (MaxPooling (None, 37, 37, 54)        0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_47 (Batc (None, 37, 37, 54)        216       
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_96 (Conv2D)           (None, 37, 37, 54)        26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_97 (Conv2D)           (None, 37, 37, 54)        26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_48 (MaxPooling (None, 18, 18, 54)        0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_48 (Batc (None, 18, 18, 54)        216       
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_98 (Conv2D)           (None, 18, 18, 54)        26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_99 (Conv2D)           (None, 18, 18, 54)        26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_49 (MaxPooling (None, 9, 9, 54)          0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_49 (Batc (None, 9, 9, 54)          216       
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_100 (Conv2D)          (None, 9, 9, 54)          26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_101 (Conv2D)          (None, 9, 9, 54)          26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_50 (MaxPooling (None, 4, 4, 54)          0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_50 (Batc (None, 4, 4, 54)          216       
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_102 (Conv2D)          (None, 4, 4, 54)          26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              conv2d_103 (Conv2D)          (None, 4, 4, 54)          26298     
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_51 (MaxPooling (None, 2, 2, 54)          0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_51 (Batc (None, 2, 2, 54)          216       
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              flatten_8 (Flatten)          (None, 216)               0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dense_32 (Dense)             (None, 45)                9765      
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dropout_24 (Dropout)         (None, 45)                0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dense_33 (Dense)             (None, 45)                2070      
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dropout_25 (Dropout)         (None, 45)                0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dense_34 (Dense)             (None, 45)                2070      
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dropout_26 (Dropout)         (None, 45)                0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dense_35 (Dense)             (None, 45)                2070      
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dropout_27 (Dropout)         (None, 45)                0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dense_36 (Dense)             (None, 45)                2070      
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dropout_28 (Dropout)         (None, 45)                0         
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              dense_37 (Dense)             (None, 2)                 92        
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              Total params: 363,035
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              Trainable params: 362,279
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              Non-trainable params: 756
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              None
 80%|████████  | 8/10 [39:53<11:13, 336.52s/it, best loss: 0.5886848568916321]2019-03-30 13:51:14.555080: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                              Epoch 1/2
 80%|████████  | 8/10 [41:33<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 80%|████████  | 8/10 [44:24<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 25:40 - loss: 0.7274 - sparse_categorical_accuracy: 0.4062 - f1_score: 0.8494
 80%|████████  | 8/10 [44:24<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [44:26<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 80%|████████  | 8/10 [44:26<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 11:32 - loss: 0.7066 - sparse_categorical_accuracy: 0.4785 - f1_score: 0.8583
 80%|████████  | 8/10 [44:26<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [44:28<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 80%|████████  | 8/10 [44:28<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6:48 - loss: 0.6912 - sparse_categorical_accuracy: 0.5443 - f1_score: 0.8571 
 80%|████████  | 8/10 [44:28<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [44:30<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 80%|████████  | 8/10 [44:30<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4:25 - loss: 0.6784 - sparse_categorical_accuracy: 0.5801 - f1_score: 0.8519
 80%|████████  | 8/10 [44:30<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [44:32<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 80%|████████  | 8/10 [44:32<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:59 - loss: 0.6699 - sparse_categorical_accuracy: 0.6125 - f1_score: 0.8540
 80%|████████  | 8/10 [44:32<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [44:34<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 80%|████████  | 8/10 [44:34<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:01 - loss: 0.6570 - sparse_categorical_accuracy: 0.6309 - f1_score: 0.8545
 80%|████████  | 8/10 [44:34<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [44:36<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 80%|████████  | 8/10 [44:36<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:18 - loss: 0.6427 - sparse_categorical_accuracy: 0.6456 - f1_score: 0.8549
 80%|████████  | 8/10 [44:36<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [44:38<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 80%|████████  | 8/10 [44:38<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 46s - loss: 0.6328 - sparse_categorical_accuracy: 0.6582 - f1_score: 0.8545 
 80%|████████  | 8/10 [44:38<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [44:40<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 80%|████████  | 8/10 [44:40<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 20s - loss: 0.6210 - sparse_categorical_accuracy: 0.6710 - f1_score: 0.8568
 80%|████████  | 8/10 [44:40<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:25<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 80%|████████  | 8/10 [46:25<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - 293s 29s/step - loss: 0.6105 - sparse_categorical_accuracy: 0.6801 - f1_score: 0.8576 - val_loss: 0.6104 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 80%|████████  | 8/10 [46:25<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              Epoch 2/2
 80%|████████  | 8/10 [46:25<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 80%|████████  | 8/10 [46:27<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 18s - loss: 0.5010 - sparse_categorical_accuracy: 0.7656 - f1_score: 0.8647
 80%|████████  | 8/10 [46:27<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:29<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 80%|████████  | 8/10 [46:29<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 16s - loss: 0.5386 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8558
 80%|████████  | 8/10 [46:29<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:31<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 80%|████████  | 8/10 [46:31<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 0.5209 - sparse_categorical_accuracy: 0.7539 - f1_score: 0.8588
 80%|████████  | 8/10 [46:31<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:33<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 80%|████████  | 8/10 [46:33<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 12s - loss: 0.5141 - sparse_categorical_accuracy: 0.7510 - f1_score: 0.8571
 80%|████████  | 8/10 [46:33<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:36<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 80%|████████  | 8/10 [46:36<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10s - loss: 0.4995 - sparse_categorical_accuracy: 0.7539 - f1_score: 0.8591
 80%|████████  | 8/10 [46:36<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:38<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 80%|████████  | 8/10 [46:38<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8s - loss: 0.5016 - sparse_categorical_accuracy: 0.7520 - f1_score: 0.8579 
 80%|████████  | 8/10 [46:38<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:40<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 80%|████████  | 8/10 [46:40<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6s - loss: 0.4933 - sparse_categorical_accuracy: 0.7539 - f1_score: 0.8593
 80%|████████  | 8/10 [46:40<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:42<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 80%|████████  | 8/10 [46:42<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4s - loss: 0.4911 - sparse_categorical_accuracy: 0.7539 - f1_score: 0.8593
 80%|████████  | 8/10 [46:42<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:44<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 80%|████████  | 8/10 [46:44<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2s - loss: 0.4852 - sparse_categorical_accuracy: 0.7535 - f1_score: 0.8591
 80%|████████  | 8/10 [46:44<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              
 80%|████████  | 8/10 [46:48<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 80%|████████  | 8/10 [46:48<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                               - 23s 2s/step - loss: 0.4816 - sparse_categorical_accuracy: 0.7531 - f1_score: 0.8589 - val_loss: 0.6146 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 80%|████████  | 8/10 [46:48<11:13, 336.52s/it, best loss: 0.5886848568916321]                                                                              0.6146151423454285
 80%|████████  | 8/10 [47:27<11:13, 336.52s/it, best loss: 0.5886848568916321] 90%|█████████ | 9/10 [47:27<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              Layer (type)                 Output Shape              Param #   
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_104 (Conv2D)          (None, 299, 299, 38)      1064      
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_105 (Conv2D)          (None, 299, 299, 38)      13034     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_52 (MaxPooling (None, 149, 149, 38)      0         
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_52 (Batc (None, 149, 149, 38)      152       
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_106 (Conv2D)          (None, 149, 149, 38)      13034     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_107 (Conv2D)          (None, 149, 149, 38)      13034     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_53 (MaxPooling (None, 74, 74, 38)        0         
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_53 (Batc (None, 74, 74, 38)        152       
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_108 (Conv2D)          (None, 74, 74, 38)        13034     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_109 (Conv2D)          (None, 74, 74, 38)        13034     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_54 (MaxPooling (None, 37, 37, 38)        0         
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_54 (Batc (None, 37, 37, 38)        152       
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_110 (Conv2D)          (None, 37, 37, 38)        13034     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_111 (Conv2D)          (None, 37, 37, 38)        13034     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_55 (MaxPooling (None, 18, 18, 38)        0         
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_55 (Batc (None, 18, 18, 38)        152       
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_112 (Conv2D)          (None, 18, 18, 38)        13034     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              conv2d_113 (Conv2D)          (None, 18, 18, 38)        13034     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              max_pooling2d_56 (MaxPooling (None, 9, 9, 38)          0         
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              batch_normalization_56 (Batc (None, 9, 9, 38)          152       
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              flatten_9 (Flatten)          (None, 3078)              0         
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              dense_38 (Dense)             (None, 30)                92370     
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              dropout_29 (Dropout)         (None, 30)                0         
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              dense_39 (Dense)             (None, 30)                930       
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              dropout_30 (Dropout)         (None, 30)                0         
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              dense_40 (Dense)             (None, 2)                 62        
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              =================================================================
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              Total params: 212,492
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              Trainable params: 212,112
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              Non-trainable params: 380
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              _________________________________________________________________
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              None
 90%|█████████ | 9/10 [47:32<06:13, 373.20s/it, best loss: 0.5886848568916321]2019-03-30 13:58:53.684815: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                              Epoch 1/2
 90%|█████████ | 9/10 [49:36<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 90%|█████████ | 9/10 [52:34<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 26:39 - loss: 1.1745 - sparse_categorical_accuracy: 0.4570 - f1_score: 0.8390
 90%|█████████ | 9/10 [52:34<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [52:36<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 90%|█████████ | 9/10 [52:36<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 11:59 - loss: 1.0008 - sparse_categorical_accuracy: 0.5117 - f1_score: 0.8519
 90%|█████████ | 9/10 [52:36<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [52:38<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 90%|█████████ | 9/10 [52:38<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 7:04 - loss: 0.8611 - sparse_categorical_accuracy: 0.5846 - f1_score: 0.8570 
 90%|█████████ | 9/10 [52:38<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [52:40<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 90%|█████████ | 9/10 [52:40<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4:36 - loss: 0.7866 - sparse_categorical_accuracy: 0.6240 - f1_score: 0.8545
 90%|█████████ | 9/10 [52:40<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [52:42<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 90%|█████████ | 9/10 [52:42<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 3:06 - loss: 0.7472 - sparse_categorical_accuracy: 0.6469 - f1_score: 0.8545
 90%|█████████ | 9/10 [52:42<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [52:44<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 90%|█████████ | 9/10 [52:44<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2:05 - loss: 0.7291 - sparse_categorical_accuracy: 0.6595 - f1_score: 0.8510
 90%|█████████ | 9/10 [52:44<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [52:46<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 90%|█████████ | 9/10 [52:46<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 1:21 - loss: 0.7161 - sparse_categorical_accuracy: 0.6669 - f1_score: 0.8515
 90%|█████████ | 9/10 [52:46<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [52:48<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 90%|█████████ | 9/10 [52:48<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 48s - loss: 0.6934 - sparse_categorical_accuracy: 0.6782 - f1_score: 0.8532 
 90%|█████████ | 9/10 [52:48<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [52:50<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 90%|█████████ | 9/10 [52:50<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 21s - loss: 0.6756 - sparse_categorical_accuracy: 0.6845 - f1_score: 0.8528
 90%|█████████ | 9/10 [52:50<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [54:43<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 90%|█████████ | 9/10 [54:43<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - 308s 31s/step - loss: 0.6619 - sparse_categorical_accuracy: 0.6895 - f1_score: 0.8545 - val_loss: 0.9000 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 90%|█████████ | 9/10 [54:43<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              Epoch 2/2
 90%|█████████ | 9/10 [54:43<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               1/10 [==>...........................]
 90%|█████████ | 9/10 [54:46<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 19s - loss: 0.5632 - sparse_categorical_accuracy: 0.7617 - f1_score: 0.8520
 90%|█████████ | 9/10 [54:46<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [54:48<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               2/10 [=====>........................]
 90%|█████████ | 9/10 [54:48<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 17s - loss: 0.5552 - sparse_categorical_accuracy: 0.7402 - f1_score: 0.8559
 90%|█████████ | 9/10 [54:48<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [54:50<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               3/10 [========>.....................]
 90%|█████████ | 9/10 [54:50<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 14s - loss: 0.6288 - sparse_categorical_accuracy: 0.7161 - f1_score: 0.8563
 90%|█████████ | 9/10 [54:50<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [54:52<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               4/10 [===========>..................]
 90%|█████████ | 9/10 [54:52<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 12s - loss: 0.6230 - sparse_categorical_accuracy: 0.7217 - f1_score: 0.8539
 90%|█████████ | 9/10 [54:52<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [54:54<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               5/10 [==============>...............]
 90%|█████████ | 9/10 [54:54<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 10s - loss: 0.6314 - sparse_categorical_accuracy: 0.7188 - f1_score: 0.8561
 90%|█████████ | 9/10 [54:54<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [54:56<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               6/10 [=================>............]
 90%|█████████ | 9/10 [54:56<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 8s - loss: 0.6095 - sparse_categorical_accuracy: 0.7207 - f1_score: 0.8537 
 90%|█████████ | 9/10 [54:56<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [54:58<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               7/10 [====================>.........]
 90%|█████████ | 9/10 [54:58<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 6s - loss: 0.5960 - sparse_categorical_accuracy: 0.7232 - f1_score: 0.8538
 90%|█████████ | 9/10 [54:58<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [55:00<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               8/10 [=======================>......]
 90%|█████████ | 9/10 [55:00<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 4s - loss: 0.5834 - sparse_categorical_accuracy: 0.7251 - f1_score: 0.8529
 90%|█████████ | 9/10 [55:00<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [55:02<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               9/10 [==========================>...]
 90%|█████████ | 9/10 [55:02<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - ETA: 2s - loss: 0.5708 - sparse_categorical_accuracy: 0.7261 - f1_score: 0.8531
 90%|█████████ | 9/10 [55:02<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              
 90%|█████████ | 9/10 [55:06<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              10/10 [==============================]
 90%|█████████ | 9/10 [55:06<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                               - 23s 2s/step - loss: 0.5630 - sparse_categorical_accuracy: 0.7293 - f1_score: 0.8522 - val_loss: 0.5914 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 90%|█████████ | 9/10 [55:06<06:13, 373.20s/it, best loss: 0.5886848568916321]                                                                              0.5914162993431091
 90%|█████████ | 9/10 [55:53<06:13, 373.20s/it, best loss: 0.5886848568916321]100%|██████████| 10/10 [55:53<00:00, 413.24s/it, best loss: 0.5886848568916321]
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7f6ecf6c7630>>
Traceback (most recent call last):
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
