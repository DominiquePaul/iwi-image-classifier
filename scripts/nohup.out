  0%|          | 0/30 [00:00<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    Layer (type)                 Output Shape              Param #   
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    =================================================================
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d (Conv2D)              (None, 299, 299, 52)      1456      
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_1 (Conv2D)            (None, 299, 299, 52)      24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    max_pooling2d (MaxPooling2D) (None, 149, 149, 52)      0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    batch_normalization (BatchNo (None, 149, 149, 52)      208       
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_2 (Conv2D)            (None, 149, 149, 52)      24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_3 (Conv2D)            (None, 149, 149, 52)      24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    max_pooling2d_1 (MaxPooling2 (None, 74, 74, 52)        0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    batch_normalization_1 (Batch (None, 74, 74, 52)        208       
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_4 (Conv2D)            (None, 74, 74, 52)        24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_5 (Conv2D)            (None, 74, 74, 52)        24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    max_pooling2d_2 (MaxPooling2 (None, 37, 37, 52)        0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    batch_normalization_2 (Batch (None, 37, 37, 52)        208       
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_6 (Conv2D)            (None, 37, 37, 52)        24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_7 (Conv2D)            (None, 37, 37, 52)        24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    max_pooling2d_3 (MaxPooling2 (None, 18, 18, 52)        0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    batch_normalization_3 (Batch (None, 18, 18, 52)        208       
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_8 (Conv2D)            (None, 18, 18, 52)        24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_9 (Conv2D)            (None, 18, 18, 52)        24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    max_pooling2d_4 (MaxPooling2 (None, 9, 9, 52)          0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    batch_normalization_4 (Batch (None, 9, 9, 52)          208       
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_10 (Conv2D)           (None, 9, 9, 52)          24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_11 (Conv2D)           (None, 9, 9, 52)          24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    max_pooling2d_5 (MaxPooling2 (None, 4, 4, 52)          0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    batch_normalization_5 (Batch (None, 4, 4, 52)          208       
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_12 (Conv2D)           (None, 4, 4, 52)          24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    conv2d_13 (Conv2D)           (None, 4, 4, 52)          24388     
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    max_pooling2d_6 (MaxPooling2 (None, 2, 2, 52)          0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    batch_normalization_6 (Batch (None, 2, 2, 52)          208       
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    flatten (Flatten)            (None, 208)               0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    dense (Dense)                (None, 19)                3971      
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    dropout (Dropout)            (None, 19)                0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    dense_1 (Dense)              (None, 19)                380       
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    dropout_1 (Dropout)          (None, 19)                0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    dense_2 (Dense)              (None, 19)                380       
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    dropout_2 (Dropout)          (None, 19)                0         
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    dense_3 (Dense)              (None, 2)                 40        
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    =================================================================
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    Total params: 324,727
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    Trainable params: 323,999
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    Non-trainable params: 728
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]                                                    None
  0%|          | 0/30 [00:06<?, ?it/s, best loss: ?]2019-04-13 07:36:22.260346: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.
  FutureWarning)

WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                    Epoch 1/2
  0%|          | 0/30 [00:25<?, ?it/s, best loss: ?]                                                     1/10 [==>...........................]
  0%|          | 0/30 [02:13<?, ?it/s, best loss: ?]                                                     - ETA: 16:16 - loss: 0.9512 - sparse_categorical_accuracy: 0.3672 - f1_score: 0.8698
  0%|          | 0/30 [02:13<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:15<?, ?it/s, best loss: ?]                                                     2/10 [=====>........................]
  0%|          | 0/30 [02:15<?, ?it/s, best loss: ?]                                                     - ETA: 7:20 - loss: 0.8544 - sparse_categorical_accuracy: 0.4258 - f1_score: 0.8531 
  0%|          | 0/30 [02:15<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:17<?, ?it/s, best loss: ?]                                                     3/10 [========>.....................]
  0%|          | 0/30 [02:17<?, ?it/s, best loss: ?]                                                     - ETA: 4:21 - loss: 0.8105 - sparse_categorical_accuracy: 0.4557 - f1_score: 0.8475
  0%|          | 0/30 [02:17<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:18<?, ?it/s, best loss: ?]                                                     4/10 [===========>..................]
  0%|          | 0/30 [02:18<?, ?it/s, best loss: ?]                                                     - ETA: 2:50 - loss: 0.7671 - sparse_categorical_accuracy: 0.4912 - f1_score: 0.8486
  0%|          | 0/30 [02:18<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:20<?, ?it/s, best loss: ?]                                                     5/10 [==============>...............]
  0%|          | 0/30 [02:20<?, ?it/s, best loss: ?]                                                     - ETA: 1:55 - loss: 0.7423 - sparse_categorical_accuracy: 0.5164 - f1_score: 0.8488
  0%|          | 0/30 [02:20<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:22<?, ?it/s, best loss: ?]                                                     6/10 [=================>............]
  0%|          | 0/30 [02:22<?, ?it/s, best loss: ?]                                                     - ETA: 1:18 - loss: 0.7244 - sparse_categorical_accuracy: 0.5345 - f1_score: 0.8510
  0%|          | 0/30 [02:22<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:24<?, ?it/s, best loss: ?]                                                     7/10 [====================>.........]
  0%|          | 0/30 [02:24<?, ?it/s, best loss: ?]                                                     - ETA: 50s - loss: 0.7175 - sparse_categorical_accuracy: 0.5502 - f1_score: 0.8508 
  0%|          | 0/30 [02:24<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:25<?, ?it/s, best loss: ?]                                                     8/10 [=======================>......]
  0%|          | 0/30 [02:25<?, ?it/s, best loss: ?]                                                     - ETA: 30s - loss: 0.7063 - sparse_categorical_accuracy: 0.5649 - f1_score: 0.8516
  0%|          | 0/30 [02:25<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:27<?, ?it/s, best loss: ?]                                                     9/10 [==========================>...]
  0%|          | 0/30 [02:27<?, ?it/s, best loss: ?]                                                     - ETA: 13s - loss: 0.6948 - sparse_categorical_accuracy: 0.5781 - f1_score: 0.8536
  0%|          | 0/30 [02:27<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:28<?, ?it/s, best loss: ?]                                                    10/10 [==============================]
  0%|          | 0/30 [03:28<?, ?it/s, best loss: ?]                                                     - 184s 18s/step - loss: 0.6835 - sparse_categorical_accuracy: 0.5855 - f1_score: 0.8519 - val_loss: 0.6210 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

  0%|          | 0/30 [03:28<?, ?it/s, best loss: ?]                                                    Epoch 2/2
  0%|          | 0/30 [03:28<?, ?it/s, best loss: ?]                                                     1/10 [==>...........................]
  0%|          | 0/30 [03:30<?, ?it/s, best loss: ?]                                                     - ETA: 14s - loss: 0.5879 - sparse_categorical_accuracy: 0.7031 - f1_score: 0.8546
  0%|          | 0/30 [03:30<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:32<?, ?it/s, best loss: ?]                                                     2/10 [=====>........................]
  0%|          | 0/30 [03:32<?, ?it/s, best loss: ?]                                                     - ETA: 13s - loss: 0.5797 - sparse_categorical_accuracy: 0.7207 - f1_score: 0.8609
  0%|          | 0/30 [03:32<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:33<?, ?it/s, best loss: ?]                                                     3/10 [========>.....................]
  0%|          | 0/30 [03:33<?, ?it/s, best loss: ?]                                                     - ETA: 11s - loss: 0.5576 - sparse_categorical_accuracy: 0.7279 - f1_score: 0.8588
  0%|          | 0/30 [03:33<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:35<?, ?it/s, best loss: ?]                                                     4/10 [===========>..................]
  0%|          | 0/30 [03:35<?, ?it/s, best loss: ?]                                                     - ETA: 9s - loss: 0.5585 - sparse_categorical_accuracy: 0.7168 - f1_score: 0.8565 
  0%|          | 0/30 [03:35<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:36<?, ?it/s, best loss: ?]                                                     5/10 [==============>...............]
  0%|          | 0/30 [03:36<?, ?it/s, best loss: ?]                                                     - ETA: 8s - loss: 0.5600 - sparse_categorical_accuracy: 0.7102 - f1_score: 0.8556
  0%|          | 0/30 [03:36<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:38<?, ?it/s, best loss: ?]                                                     6/10 [=================>............]
  0%|          | 0/30 [03:38<?, ?it/s, best loss: ?]                                                     - ETA: 6s - loss: 0.5593 - sparse_categorical_accuracy: 0.7148 - f1_score: 0.8579
  0%|          | 0/30 [03:38<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:40<?, ?it/s, best loss: ?]                                                     7/10 [====================>.........]
  0%|          | 0/30 [03:40<?, ?it/s, best loss: ?]                                                     - ETA: 5s - loss: 0.5547 - sparse_categorical_accuracy: 0.7193 - f1_score: 0.8600
  0%|          | 0/30 [03:40<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:42<?, ?it/s, best loss: ?]                                                     8/10 [=======================>......]
  0%|          | 0/30 [03:42<?, ?it/s, best loss: ?]                                                     - ETA: 3s - loss: 0.5535 - sparse_categorical_accuracy: 0.7227 - f1_score: 0.8609
  0%|          | 0/30 [03:42<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:43<?, ?it/s, best loss: ?]                                                     9/10 [==========================>...]
  0%|          | 0/30 [03:43<?, ?it/s, best loss: ?]                                                     - ETA: 1s - loss: 0.5537 - sparse_categorical_accuracy: 0.7253 - f1_score: 0.8608
  0%|          | 0/30 [03:43<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [03:46<?, ?it/s, best loss: ?]                                                    10/10 [==============================]
  0%|          | 0/30 [03:46<?, ?it/s, best loss: ?]                                                     - 18s 2s/step - loss: 0.5510 - sparse_categorical_accuracy: 0.7262 - f1_score: 0.8614 - val_loss: 0.6380 - val_sparse_categorical_accuracy: 0.7167 - val_f1_score: 0.8406

  0%|          | 0/30 [03:46<?, ?it/s, best loss: ?]                                                    0.6380364894866943
  0%|          | 0/30 [03:49<?, ?it/s, best loss: ?]  3%|▎         | 1/30 [03:49<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                Layer (type)                 Output Shape              Param #   
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                =================================================================
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_14 (Conv2D)           (None, 299, 299, 94)      2632      
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_15 (Conv2D)           (None, 299, 299, 94)      79618     
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_7 (MaxPooling2 (None, 149, 149, 94)      0         
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_7 (Batch (None, 149, 149, 94)      376       
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_16 (Conv2D)           (None, 149, 149, 94)      79618     
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_17 (Conv2D)           (None, 149, 149, 94)      79618     
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_8 (MaxPooling2 (None, 74, 74, 94)        0         
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_8 (Batch (None, 74, 74, 94)        376       
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_18 (Conv2D)           (None, 74, 74, 94)        79618     
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_19 (Conv2D)           (None, 74, 74, 94)        79618     
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_9 (MaxPooling2 (None, 37, 37, 94)        0         
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_9 (Batch (None, 37, 37, 94)        376       
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_20 (Conv2D)           (None, 37, 37, 94)        79618     
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_21 (Conv2D)           (None, 37, 37, 94)        79618     
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_10 (MaxPooling (None, 18, 18, 94)        0         
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_10 (Batc (None, 18, 18, 94)        376       
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_22 (Conv2D)           (None, 18, 18, 94)        79618     
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                conv2d_23 (Conv2D)           (None, 18, 18, 94)        79618     
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_11 (MaxPooling (None, 9, 9, 94)          0         
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_11 (Batc (None, 9, 9, 94)          376       
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                flatten_1 (Flatten)          (None, 7614)              0         
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                dense_4 (Dense)              (None, 32)                243680    
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                dropout_3 (Dropout)          (None, 32)                0         
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                dense_5 (Dense)              (None, 2)                 66        
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                =================================================================
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                Total params: 964,820
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                Trainable params: 963,880
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                Non-trainable params: 940
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                None
  3%|▎         | 1/30 [03:54<1:50:56, 229.54s/it, best loss: 0.6380364894866943]2019-04-13 07:39:59.280170: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
  3%|▎         | 1/30 [04:07<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
  3%|▎         | 1/30 [05:56<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 16:18 - loss: 1.8645 - sparse_categorical_accuracy: 0.4492 - f1_score: 0.8565
  3%|▎         | 1/30 [05:56<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [05:57<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
  3%|▎         | 1/30 [05:57<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 7:22 - loss: 1.4240 - sparse_categorical_accuracy: 0.5586 - f1_score: 0.8581 
  3%|▎         | 1/30 [05:57<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [05:59<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
  3%|▎         | 1/30 [05:59<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4:21 - loss: 1.2650 - sparse_categorical_accuracy: 0.6185 - f1_score: 0.8620
  3%|▎         | 1/30 [05:59<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [06:01<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
  3%|▎         | 1/30 [06:01<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 2:50 - loss: 1.1086 - sparse_categorical_accuracy: 0.6592 - f1_score: 0.8658
  3%|▎         | 1/30 [06:01<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [06:02<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
  3%|▎         | 1/30 [06:02<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:55 - loss: 1.0326 - sparse_categorical_accuracy: 0.6703 - f1_score: 0.8641
  3%|▎         | 1/30 [06:02<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [06:04<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
  3%|▎         | 1/30 [06:04<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:18 - loss: 0.9675 - sparse_categorical_accuracy: 0.6868 - f1_score: 0.8650
  3%|▎         | 1/30 [06:04<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [06:06<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
  3%|▎         | 1/30 [06:06<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 50s - loss: 0.9282 - sparse_categorical_accuracy: 0.6959 - f1_score: 0.8639 
  3%|▎         | 1/30 [06:06<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [06:07<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
  3%|▎         | 1/30 [06:07<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 30s - loss: 0.8832 - sparse_categorical_accuracy: 0.6992 - f1_score: 0.8621
  3%|▎         | 1/30 [06:07<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [06:09<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
  3%|▎         | 1/30 [06:09<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 13s - loss: 0.8508 - sparse_categorical_accuracy: 0.7070 - f1_score: 0.8627
  3%|▎         | 1/30 [06:09<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:15<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
  3%|▎         | 1/30 [07:15<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - 188s 19s/step - loss: 0.8277 - sparse_categorical_accuracy: 0.7109 - f1_score: 0.8608 - val_loss: 2.5428 - val_sparse_categorical_accuracy: 0.7208 - val_f1_score: 0.8406

  3%|▎         | 1/30 [07:15<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                Epoch 2/2
  3%|▎         | 1/30 [07:15<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
  3%|▎         | 1/30 [07:16<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 15s - loss: 0.5791 - sparse_categorical_accuracy: 0.7695 - f1_score: 0.8622
  3%|▎         | 1/30 [07:16<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:18<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
  3%|▎         | 1/30 [07:18<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 13s - loss: 0.5341 - sparse_categorical_accuracy: 0.7871 - f1_score: 0.8660
  3%|▎         | 1/30 [07:18<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:20<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
  3%|▎         | 1/30 [07:20<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 11s - loss: 0.5700 - sparse_categorical_accuracy: 0.7760 - f1_score: 0.8605
  3%|▎         | 1/30 [07:20<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:22<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
  3%|▎         | 1/30 [07:22<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 10s - loss: 0.5557 - sparse_categorical_accuracy: 0.7725 - f1_score: 0.8584
  3%|▎         | 1/30 [07:22<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:23<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
  3%|▎         | 1/30 [07:23<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8s - loss: 0.5409 - sparse_categorical_accuracy: 0.7734 - f1_score: 0.8601 
  3%|▎         | 1/30 [07:23<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:25<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
  3%|▎         | 1/30 [07:25<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6s - loss: 0.5420 - sparse_categorical_accuracy: 0.7721 - f1_score: 0.8601
  3%|▎         | 1/30 [07:25<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:27<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
  3%|▎         | 1/30 [07:27<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 5s - loss: 0.5440 - sparse_categorical_accuracy: 0.7701 - f1_score: 0.8589
  3%|▎         | 1/30 [07:27<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:28<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
  3%|▎         | 1/30 [07:28<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3s - loss: 0.5328 - sparse_categorical_accuracy: 0.7715 - f1_score: 0.8600
  3%|▎         | 1/30 [07:28<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:30<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
  3%|▎         | 1/30 [07:30<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1s - loss: 0.5317 - sparse_categorical_accuracy: 0.7717 - f1_score: 0.8610
  3%|▎         | 1/30 [07:30<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                
  3%|▎         | 1/30 [07:33<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
  3%|▎         | 1/30 [07:33<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                 - 18s 2s/step - loss: 0.5272 - sparse_categorical_accuracy: 0.7699 - f1_score: 0.8604 - val_loss: 6.9844 - val_sparse_categorical_accuracy: 0.3167 - val_f1_score: 0.8406

  3%|▎         | 1/30 [07:33<1:50:56, 229.54s/it, best loss: 0.6380364894866943]                                                                                6.984436511993408
  3%|▎         | 1/30 [07:38<1:50:56, 229.54s/it, best loss: 0.6380364894866943]  7%|▋         | 2/30 [07:38<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                Layer (type)                 Output Shape              Param #   
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                =================================================================
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_24 (Conv2D)           (None, 299, 299, 83)      2324      
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_25 (Conv2D)           (None, 299, 299, 83)      62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_12 (MaxPooling (None, 149, 149, 83)      0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_12 (Batc (None, 149, 149, 83)      332       
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_26 (Conv2D)           (None, 149, 149, 83)      62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_27 (Conv2D)           (None, 149, 149, 83)      62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_13 (MaxPooling (None, 74, 74, 83)        0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_13 (Batc (None, 74, 74, 83)        332       
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_28 (Conv2D)           (None, 74, 74, 83)        62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_29 (Conv2D)           (None, 74, 74, 83)        62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_14 (MaxPooling (None, 37, 37, 83)        0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_14 (Batc (None, 37, 37, 83)        332       
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_30 (Conv2D)           (None, 37, 37, 83)        62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_31 (Conv2D)           (None, 37, 37, 83)        62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_15 (MaxPooling (None, 18, 18, 83)        0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_15 (Batc (None, 18, 18, 83)        332       
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_32 (Conv2D)           (None, 18, 18, 83)        62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_33 (Conv2D)           (None, 18, 18, 83)        62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_16 (MaxPooling (None, 9, 9, 83)          0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_16 (Batc (None, 9, 9, 83)          332       
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_34 (Conv2D)           (None, 9, 9, 83)          62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_35 (Conv2D)           (None, 9, 9, 83)          62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_17 (MaxPooling (None, 4, 4, 83)          0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_17 (Batc (None, 4, 4, 83)          332       
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_36 (Conv2D)           (None, 4, 4, 83)          62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                conv2d_37 (Conv2D)           (None, 4, 4, 83)          62084     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_18 (MaxPooling (None, 2, 2, 83)          0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_18 (Batc (None, 2, 2, 83)          332       
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                flatten_2 (Flatten)          (None, 332)               0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                dense_6 (Dense)              (None, 89)                29637     
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                dropout_4 (Dropout)          (None, 89)                0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                dense_7 (Dense)              (None, 89)                8010      
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                dropout_5 (Dropout)          (None, 89)                0         
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                dense_8 (Dense)              (None, 2)                 180       
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                =================================================================
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                Total params: 849,567
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                Trainable params: 848,405
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                Non-trainable params: 1,162
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                None
  7%|▋         | 2/30 [07:42<1:46:59, 229.28s/it, best loss: 0.6380364894866943]2019-04-13 07:43:47.309103: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
  7%|▋         | 2/30 [07:58<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
  7%|▋         | 2/30 [09:59<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 18:02 - loss: 1.4772 - sparse_categorical_accuracy: 0.3633 - f1_score: 0.8468
  7%|▋         | 2/30 [09:59<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [10:00<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
  7%|▋         | 2/30 [10:00<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8:08 - loss: 1.1981 - sparse_categorical_accuracy: 0.4570 - f1_score: 0.8468 
  7%|▋         | 2/30 [10:00<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [10:02<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
  7%|▋         | 2/30 [10:02<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4:48 - loss: 1.0717 - sparse_categorical_accuracy: 0.5169 - f1_score: 0.8494
  7%|▋         | 2/30 [10:02<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [10:04<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
  7%|▋         | 2/30 [10:04<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3:08 - loss: 0.9643 - sparse_categorical_accuracy: 0.5635 - f1_score: 0.8462
  7%|▋         | 2/30 [10:04<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [10:05<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
  7%|▋         | 2/30 [10:05<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 2:07 - loss: 0.8957 - sparse_categorical_accuracy: 0.5945 - f1_score: 0.8458
  7%|▋         | 2/30 [10:05<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [10:07<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
  7%|▋         | 2/30 [10:07<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:25 - loss: 0.8819 - sparse_categorical_accuracy: 0.6113 - f1_score: 0.8477
  7%|▋         | 2/30 [10:07<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [10:09<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
  7%|▋         | 2/30 [10:09<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 55s - loss: 0.8364 - sparse_categorical_accuracy: 0.6289 - f1_score: 0.8487 
  7%|▋         | 2/30 [10:09<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [10:11<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
  7%|▋         | 2/30 [10:11<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 33s - loss: 0.8081 - sparse_categorical_accuracy: 0.6426 - f1_score: 0.8513
  7%|▋         | 2/30 [10:11<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [10:12<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
  7%|▋         | 2/30 [10:12<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 14s - loss: 0.7802 - sparse_categorical_accuracy: 0.6528 - f1_score: 0.8531
  7%|▋         | 2/30 [10:12<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:22<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
  7%|▋         | 2/30 [11:22<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - 204s 20s/step - loss: 0.7540 - sparse_categorical_accuracy: 0.6625 - f1_score: 0.8550 - val_loss: 1.0046 - val_sparse_categorical_accuracy: 0.5958 - val_f1_score: 0.8406

  7%|▋         | 2/30 [11:22<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                Epoch 2/2
  7%|▋         | 2/30 [11:22<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
  7%|▋         | 2/30 [11:24<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 14s - loss: 0.5365 - sparse_categorical_accuracy: 0.7266 - f1_score: 0.8571
  7%|▋         | 2/30 [11:24<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:25<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
  7%|▋         | 2/30 [11:25<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 13s - loss: 0.5377 - sparse_categorical_accuracy: 0.7520 - f1_score: 0.8647
  7%|▋         | 2/30 [11:25<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:27<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
  7%|▋         | 2/30 [11:27<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 11s - loss: 0.5481 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8561
  7%|▋         | 2/30 [11:27<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:29<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
  7%|▋         | 2/30 [11:29<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 10s - loss: 0.5303 - sparse_categorical_accuracy: 0.7568 - f1_score: 0.8577
  7%|▋         | 2/30 [11:29<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:30<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
  7%|▋         | 2/30 [11:30<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8s - loss: 0.5324 - sparse_categorical_accuracy: 0.7531 - f1_score: 0.8555 
  7%|▋         | 2/30 [11:30<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:32<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
  7%|▋         | 2/30 [11:32<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6s - loss: 0.5216 - sparse_categorical_accuracy: 0.7578 - f1_score: 0.8545
  7%|▋         | 2/30 [11:32<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:34<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
  7%|▋         | 2/30 [11:34<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 5s - loss: 0.5135 - sparse_categorical_accuracy: 0.7628 - f1_score: 0.8541
  7%|▋         | 2/30 [11:34<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:35<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
  7%|▋         | 2/30 [11:35<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3s - loss: 0.5131 - sparse_categorical_accuracy: 0.7637 - f1_score: 0.8558
  7%|▋         | 2/30 [11:35<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:37<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
  7%|▋         | 2/30 [11:37<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1s - loss: 0.5058 - sparse_categorical_accuracy: 0.7674 - f1_score: 0.8568
  7%|▋         | 2/30 [11:37<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                
  7%|▋         | 2/30 [11:40<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
  7%|▋         | 2/30 [11:40<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                 - 18s 2s/step - loss: 0.5124 - sparse_categorical_accuracy: 0.7664 - f1_score: 0.8581 - val_loss: 1.8170 - val_sparse_categorical_accuracy: 0.4542 - val_f1_score: 0.8406

  7%|▋         | 2/30 [11:40<1:46:59, 229.28s/it, best loss: 0.6380364894866943]                                                                                1.8169831037521362
  7%|▋         | 2/30 [11:48<1:46:59, 229.28s/it, best loss: 0.6380364894866943] 10%|█         | 3/30 [11:48<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                Layer (type)                 Output Shape              Param #   
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_38 (Conv2D)           (None, 299, 299, 8)       224       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_39 (Conv2D)           (None, 299, 299, 8)       584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_19 (MaxPooling (None, 149, 149, 8)       0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_19 (Batc (None, 149, 149, 8)       32        
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_40 (Conv2D)           (None, 149, 149, 8)       584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_41 (Conv2D)           (None, 149, 149, 8)       584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_20 (MaxPooling (None, 74, 74, 8)         0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_20 (Batc (None, 74, 74, 8)         32        
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_42 (Conv2D)           (None, 74, 74, 8)         584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_43 (Conv2D)           (None, 74, 74, 8)         584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_21 (MaxPooling (None, 37, 37, 8)         0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_21 (Batc (None, 37, 37, 8)         32        
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_44 (Conv2D)           (None, 37, 37, 8)         584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_45 (Conv2D)           (None, 37, 37, 8)         584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_22 (MaxPooling (None, 18, 18, 8)         0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_22 (Batc (None, 18, 18, 8)         32        
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_46 (Conv2D)           (None, 18, 18, 8)         584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_47 (Conv2D)           (None, 18, 18, 8)         584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_23 (MaxPooling (None, 9, 9, 8)           0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_23 (Batc (None, 9, 9, 8)           32        
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_48 (Conv2D)           (None, 9, 9, 8)           584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_49 (Conv2D)           (None, 9, 9, 8)           584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_24 (MaxPooling (None, 4, 4, 8)           0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_24 (Batc (None, 4, 4, 8)           32        
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_50 (Conv2D)           (None, 4, 4, 8)           584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                conv2d_51 (Conv2D)           (None, 4, 4, 8)           584       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_25 (MaxPooling (None, 2, 2, 8)           0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_25 (Batc (None, 2, 2, 8)           32        
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                flatten_3 (Flatten)          (None, 32)                0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                dense_9 (Dense)              (None, 65)                2145      
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                dropout_6 (Dropout)          (None, 65)                0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                dense_10 (Dense)             (None, 65)                4290      
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                dropout_7 (Dropout)          (None, 65)                0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                dense_11 (Dense)             (None, 65)                4290      
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                dropout_8 (Dropout)          (None, 65)                0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                dense_12 (Dense)             (None, 65)                4290      
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                dropout_9 (Dropout)          (None, 65)                0         
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                dense_13 (Dense)             (None, 2)                 132       
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                Total params: 23,187
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                Trainable params: 23,075
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                Non-trainable params: 112
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                None
 10%|█         | 3/30 [11:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]2019-04-13 07:47:57.164576: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 10%|█         | 3/30 [12:13<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 10%|█         | 3/30 [14:15<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 18:14 - loss: 1.4857 - sparse_categorical_accuracy: 0.5586 - f1_score: 0.8571
 10%|█         | 3/30 [14:15<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [14:16<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 10%|█         | 3/30 [14:16<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8:12 - loss: 1.2651 - sparse_categorical_accuracy: 0.5801 - f1_score: 0.8634 
 10%|█         | 3/30 [14:16<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [14:18<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 10%|█         | 3/30 [14:18<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4:50 - loss: 1.2354 - sparse_categorical_accuracy: 0.5859 - f1_score: 0.8596
 10%|█         | 3/30 [14:18<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [14:19<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 10%|█         | 3/30 [14:19<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3:09 - loss: 1.1895 - sparse_categorical_accuracy: 0.5820 - f1_score: 0.8603
 10%|█         | 3/30 [14:19<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [14:21<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 10%|█         | 3/30 [14:21<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 2:07 - loss: 1.1745 - sparse_categorical_accuracy: 0.5859 - f1_score: 0.8617
 10%|█         | 3/30 [14:21<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [14:22<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 10%|█         | 3/30 [14:22<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:26 - loss: 1.1933 - sparse_categorical_accuracy: 0.5814 - f1_score: 0.8575
 10%|█         | 3/30 [14:22<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [14:24<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 10%|█         | 3/30 [14:24<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 56s - loss: 1.1998 - sparse_categorical_accuracy: 0.5798 - f1_score: 0.8592 
 10%|█         | 3/30 [14:24<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [14:26<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 10%|█         | 3/30 [14:26<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 33s - loss: 1.1731 - sparse_categorical_accuracy: 0.5869 - f1_score: 0.8593
 10%|█         | 3/30 [14:26<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [14:27<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 10%|█         | 3/30 [14:27<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 14s - loss: 1.1507 - sparse_categorical_accuracy: 0.5885 - f1_score: 0.8576
 10%|█         | 3/30 [14:27<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:40<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 10%|█         | 3/30 [15:40<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - 206s 21s/step - loss: 1.1372 - sparse_categorical_accuracy: 0.5883 - f1_score: 0.8563 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 10%|█         | 3/30 [15:40<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                Epoch 2/2
 10%|█         | 3/30 [15:40<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 10%|█         | 3/30 [15:41<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 13s - loss: 1.0875 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8698
 10%|█         | 3/30 [15:41<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:43<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 10%|█         | 3/30 [15:43<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 12s - loss: 1.0448 - sparse_categorical_accuracy: 0.6270 - f1_score: 0.8570
 10%|█         | 3/30 [15:43<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:44<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 10%|█         | 3/30 [15:44<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 10s - loss: 1.0809 - sparse_categorical_accuracy: 0.6224 - f1_score: 0.8621
 10%|█         | 3/30 [15:44<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:46<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 10%|█         | 3/30 [15:46<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 9s - loss: 1.0310 - sparse_categorical_accuracy: 0.6270 - f1_score: 0.8602 
 10%|█         | 3/30 [15:46<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:47<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 10%|█         | 3/30 [15:47<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 7s - loss: 1.0167 - sparse_categorical_accuracy: 0.6289 - f1_score: 0.8586
 10%|█         | 3/30 [15:47<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:49<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 10%|█         | 3/30 [15:49<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6s - loss: 1.0018 - sparse_categorical_accuracy: 0.6270 - f1_score: 0.8604
 10%|█         | 3/30 [15:49<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:50<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 10%|█         | 3/30 [15:50<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4s - loss: 0.9894 - sparse_categorical_accuracy: 0.6300 - f1_score: 0.8585
 10%|█         | 3/30 [15:50<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 10%|█         | 3/30 [15:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3s - loss: 0.9727 - sparse_categorical_accuracy: 0.6338 - f1_score: 0.8580
 10%|█         | 3/30 [15:52<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:53<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 10%|█         | 3/30 [15:53<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1s - loss: 0.9649 - sparse_categorical_accuracy: 0.6311 - f1_score: 0.8562
 10%|█         | 3/30 [15:53<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                
 10%|█         | 3/30 [15:56<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 10%|█         | 3/30 [15:56<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                 - 17s 2s/step - loss: 0.9479 - sparse_categorical_accuracy: 0.6340 - f1_score: 0.8563 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 10%|█         | 3/30 [15:56<1:46:04, 235.72s/it, best loss: 0.6380364894866943]                                                                                0.6739259362220764
 10%|█         | 3/30 [16:08<1:46:04, 235.72s/it, best loss: 0.6380364894866943] 13%|█▎        | 4/30 [16:08<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                Layer (type)                 Output Shape              Param #   
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_52 (Conv2D)           (None, 299, 299, 62)      1736      
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_53 (Conv2D)           (None, 299, 299, 62)      34658     
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_26 (MaxPooling (None, 149, 149, 62)      0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_26 (Batc (None, 149, 149, 62)      248       
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_54 (Conv2D)           (None, 149, 149, 62)      34658     
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_55 (Conv2D)           (None, 149, 149, 62)      34658     
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_27 (MaxPooling (None, 74, 74, 62)        0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_27 (Batc (None, 74, 74, 62)        248       
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_56 (Conv2D)           (None, 74, 74, 62)        34658     
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_57 (Conv2D)           (None, 74, 74, 62)        34658     
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_28 (MaxPooling (None, 37, 37, 62)        0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_28 (Batc (None, 37, 37, 62)        248       
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_58 (Conv2D)           (None, 37, 37, 62)        34658     
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_59 (Conv2D)           (None, 37, 37, 62)        34658     
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_29 (MaxPooling (None, 18, 18, 62)        0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_29 (Batc (None, 18, 18, 62)        248       
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_60 (Conv2D)           (None, 18, 18, 62)        34658     
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                conv2d_61 (Conv2D)           (None, 18, 18, 62)        34658     
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_30 (MaxPooling (None, 9, 9, 62)          0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_30 (Batc (None, 9, 9, 62)          248       
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                flatten_4 (Flatten)          (None, 5022)              0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                dense_14 (Dense)             (None, 54)                271242    
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                dropout_10 (Dropout)         (None, 54)                0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                dense_15 (Dense)             (None, 54)                2970      
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                dropout_11 (Dropout)         (None, 54)                0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                dense_16 (Dense)             (None, 54)                2970      
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                dropout_12 (Dropout)         (None, 54)                0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                dense_17 (Dense)             (None, 54)                2970      
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                dropout_13 (Dropout)         (None, 54)                0         
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                dense_18 (Dense)             (None, 2)                 110       
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                Total params: 595,160
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                Trainable params: 594,540
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                Non-trainable params: 620
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                None
 13%|█▎        | 4/30 [16:13<1:45:17, 242.99s/it, best loss: 0.6380364894866943]2019-04-13 07:52:17.812734: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 13%|█▎        | 4/30 [16:41<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 13%|█▎        | 4/30 [18:49<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 19:11 - loss: 4.6886 - sparse_categorical_accuracy: 0.4219 - f1_score: 0.8546
 13%|█▎        | 4/30 [18:49<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [18:51<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 13%|█▎        | 4/30 [18:51<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8:38 - loss: 4.1805 - sparse_categorical_accuracy: 0.4531 - f1_score: 0.8559 
 13%|█▎        | 4/30 [18:51<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [18:53<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 13%|█▎        | 4/30 [18:53<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 5:06 - loss: 3.7693 - sparse_categorical_accuracy: 0.4753 - f1_score: 0.8605
 13%|█▎        | 4/30 [18:53<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [18:54<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 13%|█▎        | 4/30 [18:54<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3:19 - loss: 3.4918 - sparse_categorical_accuracy: 0.4883 - f1_score: 0.8590
 13%|█▎        | 4/30 [18:54<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [18:56<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 13%|█▎        | 4/30 [18:56<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 2:14 - loss: 3.2731 - sparse_categorical_accuracy: 0.4961 - f1_score: 0.8545
 13%|█▎        | 4/30 [18:56<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [18:57<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 13%|█▎        | 4/30 [18:57<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:30 - loss: 3.0844 - sparse_categorical_accuracy: 0.5033 - f1_score: 0.8515
 13%|█▎        | 4/30 [18:57<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [18:59<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 13%|█▎        | 4/30 [18:59<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 59s - loss: 2.9742 - sparse_categorical_accuracy: 0.5067 - f1_score: 0.8523 
 13%|█▎        | 4/30 [18:59<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [19:01<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 13%|█▎        | 4/30 [19:01<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 34s - loss: 2.7812 - sparse_categorical_accuracy: 0.5225 - f1_score: 0.8526
 13%|█▎        | 4/30 [19:01<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [19:02<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 13%|█▎        | 4/30 [19:02<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 15s - loss: 2.7041 - sparse_categorical_accuracy: 0.5308 - f1_score: 0.8545
 13%|█▎        | 4/30 [19:02<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:19<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 13%|█▎        | 4/30 [20:19<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - 218s 22s/step - loss: 2.5622 - sparse_categorical_accuracy: 0.5402 - f1_score: 0.8527 - val_loss: 2.6968 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 13%|█▎        | 4/30 [20:19<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                Epoch 2/2
 13%|█▎        | 4/30 [20:19<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 13%|█▎        | 4/30 [20:21<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 14s - loss: 1.6935 - sparse_categorical_accuracy: 0.6211 - f1_score: 0.8647
 13%|█▎        | 4/30 [20:21<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:22<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 13%|█▎        | 4/30 [20:22<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 13s - loss: 1.4877 - sparse_categorical_accuracy: 0.6602 - f1_score: 0.8635
 13%|█▎        | 4/30 [20:22<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:24<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 13%|█▎        | 4/30 [20:24<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 11s - loss: 1.6109 - sparse_categorical_accuracy: 0.6484 - f1_score: 0.8647
 13%|█▎        | 4/30 [20:24<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:26<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 13%|█▎        | 4/30 [20:26<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 9s - loss: 1.5837 - sparse_categorical_accuracy: 0.6562 - f1_score: 0.8622 
 13%|█▎        | 4/30 [20:26<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:27<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 13%|█▎        | 4/30 [20:27<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8s - loss: 1.5475 - sparse_categorical_accuracy: 0.6617 - f1_score: 0.8637
 13%|█▎        | 4/30 [20:27<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:29<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 13%|█▎        | 4/30 [20:29<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6s - loss: 1.4829 - sparse_categorical_accuracy: 0.6654 - f1_score: 0.8605
 13%|█▎        | 4/30 [20:29<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:31<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 13%|█▎        | 4/30 [20:31<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4s - loss: 1.4510 - sparse_categorical_accuracy: 0.6735 - f1_score: 0.8607
 13%|█▎        | 4/30 [20:31<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:32<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 13%|█▎        | 4/30 [20:32<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3s - loss: 1.4236 - sparse_categorical_accuracy: 0.6787 - f1_score: 0.8615
 13%|█▎        | 4/30 [20:32<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:34<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 13%|█▎        | 4/30 [20:34<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1s - loss: 1.3815 - sparse_categorical_accuracy: 0.6819 - f1_score: 0.8613
 13%|█▎        | 4/30 [20:34<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                
 13%|█▎        | 4/30 [20:37<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 13%|█▎        | 4/30 [20:37<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                 - 18s 2s/step - loss: 1.3661 - sparse_categorical_accuracy: 0.6855 - f1_score: 0.8617 - val_loss: 4.3429 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 13%|█▎        | 4/30 [20:37<1:45:17, 242.99s/it, best loss: 0.6380364894866943]                                                                                4.342925071716309
 13%|█▎        | 4/30 [20:53<1:45:17, 242.99s/it, best loss: 0.6380364894866943] 17%|█▋        | 5/30 [20:53<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                Layer (type)                 Output Shape              Param #   
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_62 (Conv2D)           (None, 299, 299, 29)      812       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_63 (Conv2D)           (None, 299, 299, 29)      7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_31 (MaxPooling (None, 149, 149, 29)      0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_31 (Batc (None, 149, 149, 29)      116       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_64 (Conv2D)           (None, 149, 149, 29)      7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_65 (Conv2D)           (None, 149, 149, 29)      7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_32 (MaxPooling (None, 74, 74, 29)        0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_32 (Batc (None, 74, 74, 29)        116       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_66 (Conv2D)           (None, 74, 74, 29)        7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_67 (Conv2D)           (None, 74, 74, 29)        7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_33 (MaxPooling (None, 37, 37, 29)        0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_33 (Batc (None, 37, 37, 29)        116       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_68 (Conv2D)           (None, 37, 37, 29)        7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_69 (Conv2D)           (None, 37, 37, 29)        7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_34 (MaxPooling (None, 18, 18, 29)        0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_34 (Batc (None, 18, 18, 29)        116       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_70 (Conv2D)           (None, 18, 18, 29)        7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_71 (Conv2D)           (None, 18, 18, 29)        7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_35 (MaxPooling (None, 9, 9, 29)          0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_35 (Batc (None, 9, 9, 29)          116       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_72 (Conv2D)           (None, 9, 9, 29)          7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_73 (Conv2D)           (None, 9, 9, 29)          7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_36 (MaxPooling (None, 4, 4, 29)          0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_36 (Batc (None, 4, 4, 29)          116       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_74 (Conv2D)           (None, 4, 4, 29)          7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                conv2d_75 (Conv2D)           (None, 4, 4, 29)          7598      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_37 (MaxPooling (None, 2, 2, 29)          0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_37 (Batc (None, 2, 2, 29)          116       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                flatten_5 (Flatten)          (None, 116)               0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dense_19 (Dense)             (None, 17)                1989      
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dropout_14 (Dropout)         (None, 17)                0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dense_20 (Dense)             (None, 17)                306       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dropout_15 (Dropout)         (None, 17)                0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dense_21 (Dense)             (None, 17)                306       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dropout_16 (Dropout)         (None, 17)                0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dense_22 (Dense)             (None, 17)                306       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dropout_17 (Dropout)         (None, 17)                0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dense_23 (Dense)             (None, 17)                306       
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dropout_18 (Dropout)         (None, 17)                0         
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                dense_24 (Dense)             (None, 2)                 36        
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                Total params: 103,647
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                Trainable params: 103,241
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                Non-trainable params: 406
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                None
 17%|█▋        | 5/30 [20:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]2019-04-13 07:57:02.154672: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 17%|█▋        | 5/30 [21:32<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 17%|█▋        | 5/30 [23:55<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 21:29 - loss: 1.3481 - sparse_categorical_accuracy: 0.5977 - f1_score: 0.7684
 17%|█▋        | 5/30 [23:55<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [23:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 17%|█▋        | 5/30 [23:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 9:39 - loss: 1.2808 - sparse_categorical_accuracy: 0.5898 - f1_score: 0.8037 
 17%|█▋        | 5/30 [23:57<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [23:59<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 17%|█▋        | 5/30 [23:59<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 5:41 - loss: 1.2135 - sparse_categorical_accuracy: 0.5990 - f1_score: 0.8190
 17%|█▋        | 5/30 [23:59<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [24:00<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 17%|█▋        | 5/30 [24:00<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3:42 - loss: 1.2333 - sparse_categorical_accuracy: 0.5967 - f1_score: 0.8285
 17%|█▋        | 5/30 [24:00<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [24:02<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 17%|█▋        | 5/30 [24:02<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 2:29 - loss: 1.2435 - sparse_categorical_accuracy: 0.6031 - f1_score: 0.8342
 17%|█▋        | 5/30 [24:02<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [24:04<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 17%|█▋        | 5/30 [24:04<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:41 - loss: 1.2052 - sparse_categorical_accuracy: 0.6074 - f1_score: 0.8393
 17%|█▋        | 5/30 [24:04<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [24:05<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 17%|█▋        | 5/30 [24:05<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:05 - loss: 1.2109 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8430
 17%|█▋        | 5/30 [24:05<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [24:07<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 17%|█▋        | 5/30 [24:07<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 38s - loss: 1.2023 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8463 
 17%|█▋        | 5/30 [24:07<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [24:09<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 17%|█▋        | 5/30 [24:09<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 17s - loss: 1.1828 - sparse_categorical_accuracy: 0.6076 - f1_score: 0.8478
 17%|█▋        | 5/30 [24:09<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:32<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 17%|█▋        | 5/30 [25:32<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - 240s 24s/step - loss: 1.1604 - sparse_categorical_accuracy: 0.6102 - f1_score: 0.8500 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 17%|█▋        | 5/30 [25:32<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                Epoch 2/2
 17%|█▋        | 5/30 [25:32<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 17%|█▋        | 5/30 [25:33<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 14s - loss: 0.8236 - sparse_categorical_accuracy: 0.6875 - f1_score: 0.8494
 17%|█▋        | 5/30 [25:33<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:35<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 17%|█▋        | 5/30 [25:35<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 12s - loss: 0.9211 - sparse_categorical_accuracy: 0.6465 - f1_score: 0.8558
 17%|█▋        | 5/30 [25:35<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:37<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 17%|█▋        | 5/30 [25:37<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 11s - loss: 0.9548 - sparse_categorical_accuracy: 0.6302 - f1_score: 0.8511
 17%|█▋        | 5/30 [25:37<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:38<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 17%|█▋        | 5/30 [25:38<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 9s - loss: 0.9674 - sparse_categorical_accuracy: 0.6348 - f1_score: 0.8526 
 17%|█▋        | 5/30 [25:38<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:40<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 17%|█▋        | 5/30 [25:40<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8s - loss: 0.9560 - sparse_categorical_accuracy: 0.6391 - f1_score: 0.8540
 17%|█▋        | 5/30 [25:40<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:42<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 17%|█▋        | 5/30 [25:42<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6s - loss: 0.9478 - sparse_categorical_accuracy: 0.6465 - f1_score: 0.8545
 17%|█▋        | 5/30 [25:42<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:43<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 17%|█▋        | 5/30 [25:43<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4s - loss: 0.9191 - sparse_categorical_accuracy: 0.6535 - f1_score: 0.8549
 17%|█▋        | 5/30 [25:43<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:45<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 17%|█▋        | 5/30 [25:45<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3s - loss: 0.8961 - sparse_categorical_accuracy: 0.6533 - f1_score: 0.8571
 17%|█▋        | 5/30 [25:45<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:47<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 17%|█▋        | 5/30 [25:47<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1s - loss: 0.8796 - sparse_categorical_accuracy: 0.6567 - f1_score: 0.8571
 17%|█▋        | 5/30 [25:47<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                
 17%|█▋        | 5/30 [25:50<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 17%|█▋        | 5/30 [25:50<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                 - 18s 2s/step - loss: 0.8678 - sparse_categorical_accuracy: 0.6566 - f1_score: 0.8561 - val_loss: 0.6709 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 17%|█▋        | 5/30 [25:50<1:46:26, 255.47s/it, best loss: 0.6380364894866943]                                                                                0.6709482669830322
 17%|█▋        | 5/30 [26:12<1:46:26, 255.47s/it, best loss: 0.6380364894866943] 20%|██        | 6/30 [26:12<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                Layer (type)                 Output Shape              Param #   
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_76 (Conv2D)           (None, 299, 299, 45)      1260      
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_77 (Conv2D)           (None, 299, 299, 45)      18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_38 (MaxPooling (None, 149, 149, 45)      0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_38 (Batc (None, 149, 149, 45)      180       
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_78 (Conv2D)           (None, 149, 149, 45)      18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_79 (Conv2D)           (None, 149, 149, 45)      18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_39 (MaxPooling (None, 74, 74, 45)        0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_39 (Batc (None, 74, 74, 45)        180       
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_80 (Conv2D)           (None, 74, 74, 45)        18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_81 (Conv2D)           (None, 74, 74, 45)        18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_40 (MaxPooling (None, 37, 37, 45)        0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_40 (Batc (None, 37, 37, 45)        180       
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_82 (Conv2D)           (None, 37, 37, 45)        18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_83 (Conv2D)           (None, 37, 37, 45)        18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_41 (MaxPooling (None, 18, 18, 45)        0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_41 (Batc (None, 18, 18, 45)        180       
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_84 (Conv2D)           (None, 18, 18, 45)        18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_85 (Conv2D)           (None, 18, 18, 45)        18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_42 (MaxPooling (None, 9, 9, 45)          0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_42 (Batc (None, 9, 9, 45)          180       
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_86 (Conv2D)           (None, 9, 9, 45)          18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_87 (Conv2D)           (None, 9, 9, 45)          18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_43 (MaxPooling (None, 4, 4, 45)          0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_43 (Batc (None, 4, 4, 45)          180       
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_88 (Conv2D)           (None, 4, 4, 45)          18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_89 (Conv2D)           (None, 4, 4, 45)          18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_44 (MaxPooling (None, 2, 2, 45)          0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_44 (Batc (None, 2, 2, 45)          180       
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_90 (Conv2D)           (None, 2, 2, 45)          18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                conv2d_91 (Conv2D)           (None, 2, 2, 45)          18270     
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_45 (MaxPooling (None, 1, 1, 45)          0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_45 (Batc (None, 1, 1, 45)          180       
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                flatten_6 (Flatten)          (None, 45)                0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                dense_25 (Dense)             (None, 72)                3312      
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                dropout_19 (Dropout)         (None, 72)                0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                dense_26 (Dense)             (None, 72)                5256      
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                dropout_20 (Dropout)         (None, 72)                0         
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                dense_27 (Dense)             (None, 2)                 146       
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                Total params: 285,464
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                Trainable params: 284,744
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                Non-trainable params: 720
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                None
 20%|██        | 6/30 [26:17<1:49:48, 274.53s/it, best loss: 0.6380364894866943]2019-04-13 08:02:22.282799: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 20%|██        | 6/30 [27:00<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 20%|██        | 6/30 [29:34<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 23:10 - loss: 2.0764 - sparse_categorical_accuracy: 0.5039 - f1_score: 0.8416
 20%|██        | 6/30 [29:34<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [29:36<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 20%|██        | 6/30 [29:36<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 10:24 - loss: 2.1383 - sparse_categorical_accuracy: 0.4883 - f1_score: 0.8544
 20%|██        | 6/30 [29:36<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [29:38<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 20%|██        | 6/30 [29:38<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6:08 - loss: 2.0734 - sparse_categorical_accuracy: 0.4896 - f1_score: 0.8579 
 20%|██        | 6/30 [29:38<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [29:39<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 20%|██        | 6/30 [29:39<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3:59 - loss: 2.0215 - sparse_categorical_accuracy: 0.4951 - f1_score: 0.8538
 20%|██        | 6/30 [29:39<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [29:41<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 20%|██        | 6/30 [29:41<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 2:41 - loss: 1.9680 - sparse_categorical_accuracy: 0.5047 - f1_score: 0.8580
 20%|██        | 6/30 [29:41<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [29:43<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 20%|██        | 6/30 [29:43<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:48 - loss: 1.9454 - sparse_categorical_accuracy: 0.5039 - f1_score: 0.8566
 20%|██        | 6/30 [29:43<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [29:44<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 20%|██        | 6/30 [29:44<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:10 - loss: 1.8914 - sparse_categorical_accuracy: 0.5011 - f1_score: 0.8585
 20%|██        | 6/30 [29:44<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [29:46<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 20%|██        | 6/30 [29:46<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 41s - loss: 1.8247 - sparse_categorical_accuracy: 0.5103 - f1_score: 0.8589 
 20%|██        | 6/30 [29:46<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [29:48<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 20%|██        | 6/30 [29:48<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 18s - loss: 1.7681 - sparse_categorical_accuracy: 0.5130 - f1_score: 0.8584
 20%|██        | 6/30 [29:48<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:22<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 20%|██        | 6/30 [31:22<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - 262s 26s/step - loss: 1.7234 - sparse_categorical_accuracy: 0.5180 - f1_score: 0.8593 - val_loss: 0.6223 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 20%|██        | 6/30 [31:22<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                Epoch 2/2
 20%|██        | 6/30 [31:22<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 20%|██        | 6/30 [31:23<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 15s - loss: 1.3865 - sparse_categorical_accuracy: 0.5742 - f1_score: 0.8622
 20%|██        | 6/30 [31:23<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:25<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 20%|██        | 6/30 [31:25<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 13s - loss: 1.3004 - sparse_categorical_accuracy: 0.5527 - f1_score: 0.8597
 20%|██        | 6/30 [31:25<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:27<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 20%|██        | 6/30 [31:27<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 11s - loss: 1.2741 - sparse_categorical_accuracy: 0.5586 - f1_score: 0.8563
 20%|██        | 6/30 [31:27<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:28<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 20%|██        | 6/30 [31:28<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 10s - loss: 1.2148 - sparse_categorical_accuracy: 0.5811 - f1_score: 0.8558
 20%|██        | 6/30 [31:28<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:30<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 20%|██        | 6/30 [31:30<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8s - loss: 1.2003 - sparse_categorical_accuracy: 0.5852 - f1_score: 0.8525 
 20%|██        | 6/30 [31:30<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:32<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 20%|██        | 6/30 [31:32<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6s - loss: 1.1977 - sparse_categorical_accuracy: 0.5827 - f1_score: 0.8502
 20%|██        | 6/30 [31:32<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:33<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 20%|██        | 6/30 [31:33<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 5s - loss: 1.2376 - sparse_categorical_accuracy: 0.5770 - f1_score: 0.8509
 20%|██        | 6/30 [31:33<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:35<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 20%|██        | 6/30 [31:35<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3s - loss: 1.2371 - sparse_categorical_accuracy: 0.5771 - f1_score: 0.8494
 20%|██        | 6/30 [31:35<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:37<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 20%|██        | 6/30 [31:37<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1s - loss: 1.2283 - sparse_categorical_accuracy: 0.5807 - f1_score: 0.8514
 20%|██        | 6/30 [31:37<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                
 20%|██        | 6/30 [31:40<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 20%|██        | 6/30 [31:40<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                 - 18s 2s/step - loss: 1.2072 - sparse_categorical_accuracy: 0.5801 - f1_score: 0.8514 - val_loss: 0.6383 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 20%|██        | 6/30 [31:40<1:49:48, 274.53s/it, best loss: 0.6380364894866943]                                                                                0.6382634043693542
 20%|██        | 6/30 [32:10<1:49:48, 274.53s/it, best loss: 0.6380364894866943] 23%|██▎       | 7/30 [32:10<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                Layer (type)                 Output Shape              Param #   
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                conv2d_92 (Conv2D)           (None, 299, 299, 60)      1680      
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                conv2d_93 (Conv2D)           (None, 299, 299, 60)      32460     
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_46 (MaxPooling (None, 149, 149, 60)      0         
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_46 (Batc (None, 149, 149, 60)      240       
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                conv2d_94 (Conv2D)           (None, 149, 149, 60)      32460     
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                conv2d_95 (Conv2D)           (None, 149, 149, 60)      32460     
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_47 (MaxPooling (None, 74, 74, 60)        0         
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_47 (Batc (None, 74, 74, 60)        240       
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                conv2d_96 (Conv2D)           (None, 74, 74, 60)        32460     
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                conv2d_97 (Conv2D)           (None, 74, 74, 60)        32460     
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_48 (MaxPooling (None, 37, 37, 60)        0         
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_48 (Batc (None, 37, 37, 60)        240       
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                conv2d_98 (Conv2D)           (None, 37, 37, 60)        32460     
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                conv2d_99 (Conv2D)           (None, 37, 37, 60)        32460     
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_49 (MaxPooling (None, 18, 18, 60)        0         
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_49 (Batc (None, 18, 18, 60)        240       
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                flatten_7 (Flatten)          (None, 19440)             0         
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                dense_28 (Dense)             (None, 9)                 174969    
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                dropout_21 (Dropout)         (None, 9)                 0         
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                dense_29 (Dense)             (None, 9)                 90        
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                dropout_22 (Dropout)         (None, 9)                 0         
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                dense_30 (Dense)             (None, 9)                 90        
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                dropout_23 (Dropout)         (None, 9)                 0         
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                dense_31 (Dense)             (None, 2)                 20        
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                Total params: 405,029
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                Trainable params: 404,549
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                Non-trainable params: 480
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                None
 23%|██▎       | 7/30 [32:13<1:54:47, 299.45s/it, best loss: 0.6380364894866943]2019-04-13 08:08:18.023006: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 23%|██▎       | 7/30 [33:08<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 23%|██▎       | 7/30 [35:48<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 23:55 - loss: 1.1945 - sparse_categorical_accuracy: 0.5703 - f1_score: 0.7649
 23%|██▎       | 7/30 [35:48<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [35:50<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 23%|██▎       | 7/30 [35:50<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 10:44 - loss: 1.0415 - sparse_categorical_accuracy: 0.5801 - f1_score: 0.8161
 23%|██▎       | 7/30 [35:50<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [35:51<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 23%|██▎       | 7/30 [35:51<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6:19 - loss: 0.9548 - sparse_categorical_accuracy: 0.6094 - f1_score: 0.8237 
 23%|██▎       | 7/30 [35:51<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [35:53<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 23%|██▎       | 7/30 [35:53<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4:06 - loss: 0.9097 - sparse_categorical_accuracy: 0.6172 - f1_score: 0.8301
 23%|██▎       | 7/30 [35:53<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [35:54<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 23%|██▎       | 7/30 [35:54<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 2:46 - loss: 0.8792 - sparse_categorical_accuracy: 0.6305 - f1_score: 0.8345
 23%|██▎       | 7/30 [35:54<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [35:56<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 23%|██▎       | 7/30 [35:56<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:51 - loss: 0.8818 - sparse_categorical_accuracy: 0.6400 - f1_score: 0.8383
 23%|██▎       | 7/30 [35:56<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [35:58<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 23%|██▎       | 7/30 [35:58<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:12 - loss: 0.8715 - sparse_categorical_accuracy: 0.6440 - f1_score: 0.8380
 23%|██▎       | 7/30 [35:58<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [35:59<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 23%|██▎       | 7/30 [35:59<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 42s - loss: 0.8667 - sparse_categorical_accuracy: 0.6470 - f1_score: 0.8401 
 23%|██▎       | 7/30 [35:59<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [36:01<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 23%|██▎       | 7/30 [36:01<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 19s - loss: 0.8556 - sparse_categorical_accuracy: 0.6489 - f1_score: 0.8405
 23%|██▎       | 7/30 [36:01<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:41<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 23%|██▎       | 7/30 [37:41<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - 273s 27s/step - loss: 0.8466 - sparse_categorical_accuracy: 0.6500 - f1_score: 0.8401 - val_loss: 1.8195 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 23%|██▎       | 7/30 [37:41<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                Epoch 2/2
 23%|██▎       | 7/30 [37:41<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 23%|██▎       | 7/30 [37:43<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 15s - loss: 0.7402 - sparse_categorical_accuracy: 0.7109 - f1_score: 0.8647
 23%|██▎       | 7/30 [37:43<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:45<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 23%|██▎       | 7/30 [37:45<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 13s - loss: 0.7166 - sparse_categorical_accuracy: 0.6953 - f1_score: 0.8506
 23%|██▎       | 7/30 [37:45<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:46<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 23%|██▎       | 7/30 [37:46<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 11s - loss: 0.7073 - sparse_categorical_accuracy: 0.6914 - f1_score: 0.8485
 23%|██▎       | 7/30 [37:46<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:48<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 23%|██▎       | 7/30 [37:48<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 10s - loss: 0.7147 - sparse_categorical_accuracy: 0.7021 - f1_score: 0.8532
 23%|██▎       | 7/30 [37:48<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:50<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 23%|██▎       | 7/30 [37:50<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8s - loss: 0.7119 - sparse_categorical_accuracy: 0.7094 - f1_score: 0.8534 
 23%|██▎       | 7/30 [37:50<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:51<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 23%|██▎       | 7/30 [37:51<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6s - loss: 0.7050 - sparse_categorical_accuracy: 0.7083 - f1_score: 0.8515
 23%|██▎       | 7/30 [37:51<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:53<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 23%|██▎       | 7/30 [37:53<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4s - loss: 0.7017 - sparse_categorical_accuracy: 0.7098 - f1_score: 0.8519
 23%|██▎       | 7/30 [37:53<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:55<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 23%|██▎       | 7/30 [37:55<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3s - loss: 0.7036 - sparse_categorical_accuracy: 0.7109 - f1_score: 0.8500
 23%|██▎       | 7/30 [37:55<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:56<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 23%|██▎       | 7/30 [37:56<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1s - loss: 0.7051 - sparse_categorical_accuracy: 0.7144 - f1_score: 0.8508
 23%|██▎       | 7/30 [37:56<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                
 23%|██▎       | 7/30 [37:59<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 23%|██▎       | 7/30 [37:59<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                 - 18s 2s/step - loss: 0.7096 - sparse_categorical_accuracy: 0.7199 - f1_score: 0.8522 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 23%|██▎       | 7/30 [37:59<1:54:47, 299.45s/it, best loss: 0.6380364894866943]                                                                                0.6805000305175781
 23%|██▎       | 7/30 [38:34<1:54:47, 299.45s/it, best loss: 0.6380364894866943] 27%|██▋       | 8/30 [38:34<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                Layer (type)                 Output Shape              Param #   
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_100 (Conv2D)          (None, 299, 299, 61)      1708      
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_101 (Conv2D)          (None, 299, 299, 61)      33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_50 (MaxPooling (None, 149, 149, 61)      0         
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_50 (Batc (None, 149, 149, 61)      244       
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_102 (Conv2D)          (None, 149, 149, 61)      33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_103 (Conv2D)          (None, 149, 149, 61)      33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_51 (MaxPooling (None, 74, 74, 61)        0         
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_51 (Batc (None, 74, 74, 61)        244       
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_104 (Conv2D)          (None, 74, 74, 61)        33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_105 (Conv2D)          (None, 74, 74, 61)        33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_52 (MaxPooling (None, 37, 37, 61)        0         
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_52 (Batc (None, 37, 37, 61)        244       
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_106 (Conv2D)          (None, 37, 37, 61)        33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_107 (Conv2D)          (None, 37, 37, 61)        33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_53 (MaxPooling (None, 18, 18, 61)        0         
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_53 (Batc (None, 18, 18, 61)        244       
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_108 (Conv2D)          (None, 18, 18, 61)        33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_109 (Conv2D)          (None, 18, 18, 61)        33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_54 (MaxPooling (None, 9, 9, 61)          0         
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_54 (Batc (None, 9, 9, 61)          244       
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_110 (Conv2D)          (None, 9, 9, 61)          33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                conv2d_111 (Conv2D)          (None, 9, 9, 61)          33550     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_55 (MaxPooling (None, 4, 4, 61)          0         
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_55 (Batc (None, 4, 4, 61)          244       
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                flatten_8 (Flatten)          (None, 976)               0         
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                dense_32 (Dense)             (None, 100)               97700     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                dropout_24 (Dropout)         (None, 100)               0         
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                dense_33 (Dense)             (None, 100)               10100     
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                dropout_25 (Dropout)         (None, 100)               0         
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                dense_34 (Dense)             (None, 2)                 202       
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                Total params: 480,224
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                Trainable params: 479,492
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                Non-trainable params: 732
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                None
 27%|██▋       | 8/30 [38:38<1:59:07, 324.90s/it, best loss: 0.6380364894866943]2019-04-13 08:14:42.615253: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 27%|██▋       | 8/30 [39:41<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 27%|██▋       | 8/30 [42:30<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 25:21 - loss: 0.6082 - sparse_categorical_accuracy: 0.6797 - f1_score: 0.8416
 27%|██▋       | 8/30 [42:30<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [42:32<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 27%|██▋       | 8/30 [42:32<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 11:22 - loss: 0.6164 - sparse_categorical_accuracy: 0.7227 - f1_score: 0.8494
 27%|██▋       | 8/30 [42:32<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [42:34<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 27%|██▋       | 8/30 [42:34<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6:42 - loss: 0.5798 - sparse_categorical_accuracy: 0.7396 - f1_score: 0.8562 
 27%|██▋       | 8/30 [42:34<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [42:35<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 27%|██▋       | 8/30 [42:35<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4:20 - loss: 0.5632 - sparse_categorical_accuracy: 0.7461 - f1_score: 0.8558
 27%|██▋       | 8/30 [42:35<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [42:37<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 27%|██▋       | 8/30 [42:37<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 2:55 - loss: 0.5436 - sparse_categorical_accuracy: 0.7516 - f1_score: 0.8571
 27%|██▋       | 8/30 [42:37<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [42:39<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 27%|██▋       | 8/30 [42:39<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:58 - loss: 0.5404 - sparse_categorical_accuracy: 0.7526 - f1_score: 0.8536
 27%|██▋       | 8/30 [42:39<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [42:40<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 27%|██▋       | 8/30 [42:40<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:16 - loss: 0.5270 - sparse_categorical_accuracy: 0.7600 - f1_score: 0.8559
 27%|██▋       | 8/30 [42:40<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [42:42<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 27%|██▋       | 8/30 [42:42<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 45s - loss: 0.5143 - sparse_categorical_accuracy: 0.7666 - f1_score: 0.8558 
 27%|██▋       | 8/30 [42:42<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [42:43<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 27%|██▋       | 8/30 [42:43<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 20s - loss: 0.5005 - sparse_categorical_accuracy: 0.7721 - f1_score: 0.8545
 27%|██▋       | 8/30 [42:43<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:29<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 27%|██▋       | 8/30 [44:29<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - 288s 29s/step - loss: 0.4854 - sparse_categorical_accuracy: 0.7801 - f1_score: 0.8550 - val_loss: 0.5917 - val_sparse_categorical_accuracy: 0.7292 - val_f1_score: 0.8406

 27%|██▋       | 8/30 [44:29<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                Epoch 2/2
 27%|██▋       | 8/30 [44:29<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 27%|██▋       | 8/30 [44:31<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 14s - loss: 0.2699 - sparse_categorical_accuracy: 0.8984 - f1_score: 0.8698
 27%|██▋       | 8/30 [44:31<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:32<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 27%|██▋       | 8/30 [44:32<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 13s - loss: 0.3716 - sparse_categorical_accuracy: 0.8457 - f1_score: 0.8685
 27%|██▋       | 8/30 [44:32<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:34<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 27%|██▋       | 8/30 [44:34<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 11s - loss: 0.3239 - sparse_categorical_accuracy: 0.8711 - f1_score: 0.8673
 27%|██▋       | 8/30 [44:34<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:36<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 27%|██▋       | 8/30 [44:36<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 9s - loss: 0.3324 - sparse_categorical_accuracy: 0.8643 - f1_score: 0.8602 
 27%|██▋       | 8/30 [44:36<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:37<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 27%|██▋       | 8/30 [44:37<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8s - loss: 0.3220 - sparse_categorical_accuracy: 0.8688 - f1_score: 0.8591
 27%|██▋       | 8/30 [44:37<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:39<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 27%|██▋       | 8/30 [44:39<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6s - loss: 0.3061 - sparse_categorical_accuracy: 0.8776 - f1_score: 0.8587
 27%|██▋       | 8/30 [44:39<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:40<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 27%|██▋       | 8/30 [44:40<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4s - loss: 0.3018 - sparse_categorical_accuracy: 0.8783 - f1_score: 0.8578
 27%|██▋       | 8/30 [44:40<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:42<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 27%|██▋       | 8/30 [44:42<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3s - loss: 0.2839 - sparse_categorical_accuracy: 0.8887 - f1_score: 0.8590
 27%|██▋       | 8/30 [44:42<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:44<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 27%|██▋       | 8/30 [44:44<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1s - loss: 0.2859 - sparse_categorical_accuracy: 0.8850 - f1_score: 0.8596
 27%|██▋       | 8/30 [44:44<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                
 27%|██▋       | 8/30 [44:47<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 27%|██▋       | 8/30 [44:47<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                 - 18s 2s/step - loss: 0.2711 - sparse_categorical_accuracy: 0.8922 - f1_score: 0.8604 - val_loss: 1.1296 - val_sparse_categorical_accuracy: 0.2792 - val_f1_score: 0.8406

 27%|██▋       | 8/30 [44:47<1:59:07, 324.90s/it, best loss: 0.6380364894866943]                                                                                1.1295843124389648
 27%|██▋       | 8/30 [45:29<1:59:07, 324.90s/it, best loss: 0.6380364894866943] 30%|███       | 9/30 [45:29<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                Layer (type)                 Output Shape              Param #   
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_112 (Conv2D)          (None, 299, 299, 70)      1960      
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_113 (Conv2D)          (None, 299, 299, 70)      44170     
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_56 (MaxPooling (None, 149, 149, 70)      0         
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_56 (Batc (None, 149, 149, 70)      280       
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_114 (Conv2D)          (None, 149, 149, 70)      44170     
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_115 (Conv2D)          (None, 149, 149, 70)      44170     
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_57 (MaxPooling (None, 74, 74, 70)        0         
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_57 (Batc (None, 74, 74, 70)        280       
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_116 (Conv2D)          (None, 74, 74, 70)        44170     
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_117 (Conv2D)          (None, 74, 74, 70)        44170     
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_58 (MaxPooling (None, 37, 37, 70)        0         
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_58 (Batc (None, 37, 37, 70)        280       
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_118 (Conv2D)          (None, 37, 37, 70)        44170     
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_119 (Conv2D)          (None, 37, 37, 70)        44170     
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_59 (MaxPooling (None, 18, 18, 70)        0         
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_59 (Batc (None, 18, 18, 70)        280       
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_120 (Conv2D)          (None, 18, 18, 70)        44170     
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                conv2d_121 (Conv2D)          (None, 18, 18, 70)        44170     
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                max_pooling2d_60 (MaxPooling (None, 9, 9, 70)          0         
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                batch_normalization_60 (Batc (None, 9, 9, 70)          280       
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                flatten_9 (Flatten)          (None, 5670)              0         
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                dense_35 (Dense)             (None, 67)                379957    
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                dropout_26 (Dropout)         (None, 67)                0         
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                dense_36 (Dense)             (None, 67)                4556      
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                dropout_27 (Dropout)         (None, 67)                0         
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                dense_37 (Dense)             (None, 67)                4556      
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                dropout_28 (Dropout)         (None, 67)                0         
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                dense_38 (Dense)             (None, 2)                 136       
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                =================================================================
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                Total params: 790,095
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                Trainable params: 789,395
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                Non-trainable params: 700
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                None
 30%|███       | 9/30 [45:34<2:03:12, 352.02s/it, best loss: 0.6380364894866943]2019-04-13 08:21:38.643370: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 30%|███       | 9/30 [46:47<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 30%|███       | 9/30 [49:47<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 27:01 - loss: 1.0742 - sparse_categorical_accuracy: 0.2656 - f1_score: 0.8597
 30%|███       | 9/30 [49:47<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [49:49<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 30%|███       | 9/30 [49:49<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 12:06 - loss: 0.8067 - sparse_categorical_accuracy: 0.4941 - f1_score: 0.8647
 30%|███       | 9/30 [49:49<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [49:50<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 30%|███       | 9/30 [49:50<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 7:07 - loss: 0.7460 - sparse_categorical_accuracy: 0.5807 - f1_score: 0.8613 
 30%|███       | 9/30 [49:50<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [49:52<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 30%|███       | 9/30 [49:52<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4:37 - loss: 0.6647 - sparse_categorical_accuracy: 0.6396 - f1_score: 0.8616
 30%|███       | 9/30 [49:52<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [49:54<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 30%|███       | 9/30 [49:54<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3:06 - loss: 0.6411 - sparse_categorical_accuracy: 0.6625 - f1_score: 0.8565
 30%|███       | 9/30 [49:54<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [49:55<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 30%|███       | 9/30 [49:55<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 2:05 - loss: 0.6041 - sparse_categorical_accuracy: 0.6855 - f1_score: 0.8575
 30%|███       | 9/30 [49:55<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [49:57<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 30%|███       | 9/30 [49:57<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1:21 - loss: 0.5860 - sparse_categorical_accuracy: 0.6992 - f1_score: 0.8567
 30%|███       | 9/30 [49:57<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [49:58<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 30%|███       | 9/30 [49:58<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 47s - loss: 0.5622 - sparse_categorical_accuracy: 0.7134 - f1_score: 0.8567 
 30%|███       | 9/30 [49:58<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [50:00<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 30%|███       | 9/30 [50:00<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 21s - loss: 0.5417 - sparse_categorical_accuracy: 0.7270 - f1_score: 0.8562
 30%|███       | 9/30 [50:00<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [51:53<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 30%|███       | 9/30 [51:53<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - 306s 31s/step - loss: 0.5222 - sparse_categorical_accuracy: 0.7359 - f1_score: 0.8542 - val_loss: 0.7790 - val_sparse_categorical_accuracy: 0.7333 - val_f1_score: 0.8406

 30%|███       | 9/30 [51:53<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                Epoch 2/2
 30%|███       | 9/30 [51:53<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 1/10 [==>...........................]
 30%|███       | 9/30 [51:54<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 14s - loss: 0.5759 - sparse_categorical_accuracy: 0.7656 - f1_score: 0.8546
 30%|███       | 9/30 [51:54<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [51:56<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 2/10 [=====>........................]
 30%|███       | 9/30 [51:56<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 13s - loss: 0.4684 - sparse_categorical_accuracy: 0.7949 - f1_score: 0.8559
 30%|███       | 9/30 [51:56<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [51:58<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 3/10 [========>.....................]
 30%|███       | 9/30 [51:58<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 11s - loss: 0.4625 - sparse_categorical_accuracy: 0.7982 - f1_score: 0.8563
 30%|███       | 9/30 [51:58<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [51:59<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 4/10 [===========>..................]
 30%|███       | 9/30 [51:59<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 9s - loss: 0.4242 - sparse_categorical_accuracy: 0.8115 - f1_score: 0.8590 
 30%|███       | 9/30 [51:59<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [52:01<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 5/10 [==============>...............]
 30%|███       | 9/30 [52:01<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 8s - loss: 0.4094 - sparse_categorical_accuracy: 0.8172 - f1_score: 0.8561
 30%|███       | 9/30 [52:01<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [52:02<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 6/10 [=================>............]
 30%|███       | 9/30 [52:02<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 6s - loss: 0.3957 - sparse_categorical_accuracy: 0.8236 - f1_score: 0.8571
 30%|███       | 9/30 [52:02<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [52:04<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 7/10 [====================>.........]
 30%|███       | 9/30 [52:04<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 4s - loss: 0.3757 - sparse_categorical_accuracy: 0.8326 - f1_score: 0.8575
 30%|███       | 9/30 [52:04<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [52:06<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 8/10 [=======================>......]
 30%|███       | 9/30 [52:06<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 3s - loss: 0.3584 - sparse_categorical_accuracy: 0.8423 - f1_score: 0.8571
 30%|███       | 9/30 [52:06<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [52:07<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 9/10 [==========================>...]
 30%|███       | 9/30 [52:07<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - ETA: 1s - loss: 0.3404 - sparse_categorical_accuracy: 0.8524 - f1_score: 0.8568
 30%|███       | 9/30 [52:07<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                
 30%|███       | 9/30 [52:10<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                10/10 [==============================]
 30%|███       | 9/30 [52:10<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                 - 18s 2s/step - loss: 0.3216 - sparse_categorical_accuracy: 0.8629 - f1_score: 0.8566 - val_loss: 1.3055 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 30%|███       | 9/30 [52:10<2:03:12, 352.02s/it, best loss: 0.6380364894866943]                                                                                1.3055161237716675
 30%|███       | 9/30 [52:59<2:03:12, 352.02s/it, best loss: 0.6380364894866943] 33%|███▎      | 10/30 [52:59<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 Layer (type)                 Output Shape              Param #   
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 =================================================================
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_122 (Conv2D)          (None, 299, 299, 87)      2436      
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_123 (Conv2D)          (None, 299, 299, 87)      68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 max_pooling2d_61 (MaxPooling (None, 149, 149, 87)      0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 batch_normalization_61 (Batc (None, 149, 149, 87)      348       
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_124 (Conv2D)          (None, 149, 149, 87)      68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_125 (Conv2D)          (None, 149, 149, 87)      68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 max_pooling2d_62 (MaxPooling (None, 74, 74, 87)        0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 batch_normalization_62 (Batc (None, 74, 74, 87)        348       
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_126 (Conv2D)          (None, 74, 74, 87)        68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_127 (Conv2D)          (None, 74, 74, 87)        68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 max_pooling2d_63 (MaxPooling (None, 37, 37, 87)        0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 batch_normalization_63 (Batc (None, 37, 37, 87)        348       
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_128 (Conv2D)          (None, 37, 37, 87)        68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_129 (Conv2D)          (None, 37, 37, 87)        68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 max_pooling2d_64 (MaxPooling (None, 18, 18, 87)        0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 batch_normalization_64 (Batc (None, 18, 18, 87)        348       
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_130 (Conv2D)          (None, 18, 18, 87)        68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_131 (Conv2D)          (None, 18, 18, 87)        68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 max_pooling2d_65 (MaxPooling (None, 9, 9, 87)          0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 batch_normalization_65 (Batc (None, 9, 9, 87)          348       
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_132 (Conv2D)          (None, 9, 9, 87)          68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_133 (Conv2D)          (None, 9, 9, 87)          68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 max_pooling2d_66 (MaxPooling (None, 4, 4, 87)          0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 batch_normalization_66 (Batc (None, 4, 4, 87)          348       
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_134 (Conv2D)          (None, 4, 4, 87)          68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 conv2d_135 (Conv2D)          (None, 4, 4, 87)          68208     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 max_pooling2d_67 (MaxPooling (None, 2, 2, 87)          0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 batch_normalization_67 (Batc (None, 2, 2, 87)          348       
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 flatten_10 (Flatten)         (None, 348)               0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 dense_39 (Dense)             (None, 44)                15356     
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 dropout_29 (Dropout)         (None, 44)                0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 dense_40 (Dense)             (None, 44)                1980      
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 dropout_30 (Dropout)         (None, 44)                0         
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 dense_41 (Dense)             (None, 2)                 90        
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 =================================================================
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 Total params: 909,002
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 Trainable params: 907,784
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 Non-trainable params: 1,218
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 None
 33%|███▎      | 10/30 [53:03<2:07:06, 381.34s/it, best loss: 0.6380364894866943]2019-04-13 08:29:07.872408: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                 Epoch 1/2
 33%|███▎      | 10/30 [54:26<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  1/10 [==>...........................]
 33%|███▎      | 10/30 [57:41<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  - ETA: 29:21 - loss: 2.5219 - sparse_categorical_accuracy: 0.4531 - f1_score: 0.8337
 33%|███▎      | 10/30 [57:41<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 
 33%|███▎      | 10/30 [57:43<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  2/10 [=====>........................]
 33%|███▎      | 10/30 [57:43<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  - ETA: 13:09 - loss: 2.1309 - sparse_categorical_accuracy: 0.4941 - f1_score: 0.8505
 33%|███▎      | 10/30 [57:43<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 
 33%|███▎      | 10/30 [57:45<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  3/10 [========>.....................]
 33%|███▎      | 10/30 [57:45<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  - ETA: 7:44 - loss: 2.0487 - sparse_categorical_accuracy: 0.5143 - f1_score: 0.8561 
 33%|███▎      | 10/30 [57:45<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 
 33%|███▎      | 10/30 [57:46<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  4/10 [===========>..................]
 33%|███▎      | 10/30 [57:46<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  - ETA: 5:00 - loss: 1.9457 - sparse_categorical_accuracy: 0.5293 - f1_score: 0.8570
 33%|███▎      | 10/30 [57:46<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 
 33%|███▎      | 10/30 [57:48<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  5/10 [==============>...............]
 33%|███▎      | 10/30 [57:48<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  - ETA: 3:22 - loss: 1.8297 - sparse_categorical_accuracy: 0.5461 - f1_score: 0.8570
 33%|███▎      | 10/30 [57:48<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 
 33%|███▎      | 10/30 [57:50<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  6/10 [=================>............]
 33%|███▎      | 10/30 [57:50<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  - ETA: 2:15 - loss: 1.7728 - sparse_categorical_accuracy: 0.5430 - f1_score: 0.8591
 33%|███▎      | 10/30 [57:50<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 
 33%|███▎      | 10/30 [57:51<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  7/10 [====================>.........]
 33%|███▎      | 10/30 [57:51<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  - ETA: 1:28 - loss: 1.6938 - sparse_categorical_accuracy: 0.5513 - f1_score: 0.8599
 33%|███▎      | 10/30 [57:51<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 
 33%|███▎      | 10/30 [57:53<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  8/10 [=======================>......]
 33%|███▎      | 10/30 [57:53<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  - ETA: 51s - loss: 1.6212 - sparse_categorical_accuracy: 0.5479 - f1_score: 0.8612 
 33%|███▎      | 10/30 [57:53<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 
 33%|███▎      | 10/30 [57:55<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  9/10 [==========================>...]
 33%|███▎      | 10/30 [57:55<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                  - ETA: 23s - loss: 1.5667 - sparse_categorical_accuracy: 0.5477 - f1_score: 0.8604
 33%|███▎      | 10/30 [57:55<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                 
 33%|███▎      | 10/30 [1:00:02<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   10/10 [==============================]
 33%|███▎      | 10/30 [1:00:02<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - 336s 34s/step - loss: 1.5172 - sparse_categorical_accuracy: 0.5543 - f1_score: 0.8614 - val_loss: 2.8050 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 33%|███▎      | 10/30 [1:00:02<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   Epoch 2/2
 33%|███▎      | 10/30 [1:00:02<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    1/10 [==>...........................]
 33%|███▎      | 10/30 [1:00:04<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 15s - loss: 1.0899 - sparse_categorical_accuracy: 0.5781 - f1_score: 0.8673
 33%|███▎      | 10/30 [1:00:04<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   
 33%|███▎      | 10/30 [1:00:05<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    2/10 [=====>........................]
 33%|███▎      | 10/30 [1:00:05<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 13s - loss: 0.9898 - sparse_categorical_accuracy: 0.6133 - f1_score: 0.8673
 33%|███▎      | 10/30 [1:00:05<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   
 33%|███▎      | 10/30 [1:00:07<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    3/10 [========>.....................]
 33%|███▎      | 10/30 [1:00:07<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 11s - loss: 0.9449 - sparse_categorical_accuracy: 0.6068 - f1_score: 0.8630
 33%|███▎      | 10/30 [1:00:07<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   
 33%|███▎      | 10/30 [1:00:09<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    4/10 [===========>..................]
 33%|███▎      | 10/30 [1:00:09<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 10s - loss: 0.9439 - sparse_categorical_accuracy: 0.6113 - f1_score: 0.8622
 33%|███▎      | 10/30 [1:00:09<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   
 33%|███▎      | 10/30 [1:00:10<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    5/10 [==============>...............]
 33%|███▎      | 10/30 [1:00:10<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 8s - loss: 0.9084 - sparse_categorical_accuracy: 0.6125 - f1_score: 0.8632 
 33%|███▎      | 10/30 [1:00:10<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   
 33%|███▎      | 10/30 [1:00:12<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    6/10 [=================>............]
 33%|███▎      | 10/30 [1:00:12<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 6s - loss: 0.8897 - sparse_categorical_accuracy: 0.6243 - f1_score: 0.8639
 33%|███▎      | 10/30 [1:00:12<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   
 33%|███▎      | 10/30 [1:00:14<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    7/10 [====================>.........]
 33%|███▎      | 10/30 [1:00:14<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 5s - loss: 0.8884 - sparse_categorical_accuracy: 0.6256 - f1_score: 0.8622
 33%|███▎      | 10/30 [1:00:14<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   
 33%|███▎      | 10/30 [1:00:16<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    8/10 [=======================>......]
 33%|███▎      | 10/30 [1:00:16<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 3s - loss: 0.8798 - sparse_categorical_accuracy: 0.6343 - f1_score: 0.8616
 33%|███▎      | 10/30 [1:00:16<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   
 33%|███▎      | 10/30 [1:00:17<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    9/10 [==========================>...]
 33%|███▎      | 10/30 [1:00:17<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 1s - loss: 0.8682 - sparse_categorical_accuracy: 0.6359 - f1_score: 0.8602
 33%|███▎      | 10/30 [1:00:17<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   
 33%|███▎      | 10/30 [1:00:20<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   10/10 [==============================]
 33%|███▎      | 10/30 [1:00:20<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                    - 18s 2s/step - loss: 0.8555 - sparse_categorical_accuracy: 0.6406 - f1_score: 0.8596 - val_loss: 4.4241 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 33%|███▎      | 10/30 [1:00:20<2:07:06, 381.34s/it, best loss: 0.6380364894866943]                                                                                   4.424061298370361
 33%|███▎      | 10/30 [1:01:19<2:07:06, 381.34s/it, best loss: 0.6380364894866943] 37%|███▋      | 11/30 [1:01:19<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   Layer (type)                 Output Shape              Param #   
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   =================================================================
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_136 (Conv2D)          (None, 299, 299, 104)     2912      
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_137 (Conv2D)          (None, 299, 299, 104)     97448     
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_68 (MaxPooling (None, 149, 149, 104)     0         
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_68 (Batc (None, 149, 149, 104)     416       
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_138 (Conv2D)          (None, 149, 149, 104)     97448     
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_139 (Conv2D)          (None, 149, 149, 104)     97448     
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_69 (MaxPooling (None, 74, 74, 104)       0         
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_69 (Batc (None, 74, 74, 104)       416       
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_140 (Conv2D)          (None, 74, 74, 104)       97448     
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_141 (Conv2D)          (None, 74, 74, 104)       97448     
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_70 (MaxPooling (None, 37, 37, 104)       0         
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_70 (Batc (None, 37, 37, 104)       416       
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_142 (Conv2D)          (None, 37, 37, 104)       97448     
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_143 (Conv2D)          (None, 37, 37, 104)       97448     
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_71 (MaxPooling (None, 18, 18, 104)       0         
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_71 (Batc (None, 18, 18, 104)       416       
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_144 (Conv2D)          (None, 18, 18, 104)       97448     
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   conv2d_145 (Conv2D)          (None, 18, 18, 104)       97448     
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_72 (MaxPooling (None, 9, 9, 104)         0         
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_72 (Batc (None, 9, 9, 104)         416       
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   flatten_11 (Flatten)         (None, 8424)              0         
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   dense_42 (Dense)             (None, 47)                395975    
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   dropout_31 (Dropout)         (None, 47)                0         
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   dense_43 (Dense)             (None, 47)                2256      
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   dropout_32 (Dropout)         (None, 47)                0         
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   dense_44 (Dense)             (None, 47)                2256      
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   dropout_33 (Dropout)         (None, 47)                0         
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   dense_45 (Dense)             (None, 2)                 96        
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   =================================================================
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   Total params: 1,282,607
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   Trainable params: 1,281,567
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   Non-trainable params: 1,040
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   None
 37%|███▋      | 11/30 [1:01:23<2:11:59, 416.84s/it, best loss: 0.6380364894866943]2019-04-13 08:37:28.178143: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 37%|███▋      | 11/30 [1:03:01<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    1/10 [==>...........................]
 37%|███▋      | 11/30 [1:06:35<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 32:03 - loss: 2.0877 - sparse_categorical_accuracy: 0.4922 - f1_score: 0.8667
 37%|███▋      | 11/30 [1:06:35<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:06:36<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    2/10 [=====>........................]
 37%|███▋      | 11/30 [1:06:36<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 14:21 - loss: 1.9935 - sparse_categorical_accuracy: 0.5000 - f1_score: 0.8657
 37%|███▋      | 11/30 [1:06:36<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:06:38<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    3/10 [========>.....................]
 37%|███▋      | 11/30 [1:06:38<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 8:26 - loss: 1.8702 - sparse_categorical_accuracy: 0.5065 - f1_score: 0.8603 
 37%|███▋      | 11/30 [1:06:38<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:06:40<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    4/10 [===========>..................]
 37%|███▋      | 11/30 [1:06:40<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 5:27 - loss: 1.7506 - sparse_categorical_accuracy: 0.5166 - f1_score: 0.8563
 37%|███▋      | 11/30 [1:06:40<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:06:41<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    5/10 [==============>...............]
 37%|███▋      | 11/30 [1:06:41<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 3:40 - loss: 1.6495 - sparse_categorical_accuracy: 0.5383 - f1_score: 0.8554
 37%|███▋      | 11/30 [1:06:41<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:06:43<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    6/10 [=================>............]
 37%|███▋      | 11/30 [1:06:43<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 2:27 - loss: 1.5713 - sparse_categorical_accuracy: 0.5573 - f1_score: 0.8561
 37%|███▋      | 11/30 [1:06:43<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:06:45<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    7/10 [====================>.........]
 37%|███▋      | 11/30 [1:06:45<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 1:35 - loss: 1.5318 - sparse_categorical_accuracy: 0.5586 - f1_score: 0.8577
 37%|███▋      | 11/30 [1:06:45<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:06:46<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    8/10 [=======================>......]
 37%|███▋      | 11/30 [1:06:46<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 56s - loss: 1.4733 - sparse_categorical_accuracy: 0.5732 - f1_score: 0.8576 
 37%|███▋      | 11/30 [1:06:46<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:06:48<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    9/10 [==========================>...]
 37%|███▋      | 11/30 [1:06:48<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 25s - loss: 1.4121 - sparse_categorical_accuracy: 0.5859 - f1_score: 0.8587
 37%|███▋      | 11/30 [1:06:48<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:03<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   10/10 [==============================]
 37%|███▋      | 11/30 [1:09:03<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - 362s 36s/step - loss: 1.3525 - sparse_categorical_accuracy: 0.5973 - f1_score: 0.8586 - val_loss: 1.5552 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 37%|███▋      | 11/30 [1:09:03<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   Epoch 2/2
 37%|███▋      | 11/30 [1:09:03<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    1/10 [==>...........................]
 37%|███▋      | 11/30 [1:09:05<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 14s - loss: 0.7795 - sparse_categorical_accuracy: 0.7188 - f1_score: 0.8698
 37%|███▋      | 11/30 [1:09:05<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:06<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    2/10 [=====>........................]
 37%|███▋      | 11/30 [1:09:06<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 13s - loss: 0.7870 - sparse_categorical_accuracy: 0.7188 - f1_score: 0.8596
 37%|███▋      | 11/30 [1:09:06<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:08<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    3/10 [========>.....................]
 37%|███▋      | 11/30 [1:09:08<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 11s - loss: 0.7642 - sparse_categorical_accuracy: 0.7253 - f1_score: 0.8571
 37%|███▋      | 11/30 [1:09:08<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:09<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    4/10 [===========>..................]
 37%|███▋      | 11/30 [1:09:09<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 9s - loss: 0.7574 - sparse_categorical_accuracy: 0.7266 - f1_score: 0.8571 
 37%|███▋      | 11/30 [1:09:09<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:11<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    5/10 [==============>...............]
 37%|███▋      | 11/30 [1:09:11<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 8s - loss: 0.7538 - sparse_categorical_accuracy: 0.7297 - f1_score: 0.8586
 37%|███▋      | 11/30 [1:09:11<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:13<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    6/10 [=================>............]
 37%|███▋      | 11/30 [1:09:13<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 6s - loss: 0.7496 - sparse_categorical_accuracy: 0.7311 - f1_score: 0.8584
 37%|███▋      | 11/30 [1:09:13<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:14<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    7/10 [====================>.........]
 37%|███▋      | 11/30 [1:09:14<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 4s - loss: 0.7377 - sparse_categorical_accuracy: 0.7327 - f1_score: 0.8582
 37%|███▋      | 11/30 [1:09:14<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:16<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    8/10 [=======================>......]
 37%|███▋      | 11/30 [1:09:16<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 3s - loss: 0.7295 - sparse_categorical_accuracy: 0.7344 - f1_score: 0.8584
 37%|███▋      | 11/30 [1:09:16<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:18<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    9/10 [==========================>...]
 37%|███▋      | 11/30 [1:09:18<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 1s - loss: 0.7269 - sparse_categorical_accuracy: 0.7357 - f1_score: 0.8585
 37%|███▋      | 11/30 [1:09:18<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   
 37%|███▋      | 11/30 [1:09:21<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   10/10 [==============================]
 37%|███▋      | 11/30 [1:09:21<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                    - 18s 2s/step - loss: 0.7224 - sparse_categorical_accuracy: 0.7383 - f1_score: 0.8597 - val_loss: 3.3597 - val_sparse_categorical_accuracy: 0.7125 - val_f1_score: 0.8406

 37%|███▋      | 11/30 [1:09:21<2:11:59, 416.84s/it, best loss: 0.6380364894866943]                                                                                   3.359652280807495
 37%|███▋      | 11/30 [1:10:27<2:11:59, 416.84s/it, best loss: 0.6380364894866943] 40%|████      | 12/30 [1:10:27<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   Layer (type)                 Output Shape              Param #   
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   =================================================================
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_146 (Conv2D)          (None, 299, 299, 14)      392       
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_147 (Conv2D)          (None, 299, 299, 14)      1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_73 (MaxPooling (None, 149, 149, 14)      0         
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_73 (Batc (None, 149, 149, 14)      56        
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_148 (Conv2D)          (None, 149, 149, 14)      1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_149 (Conv2D)          (None, 149, 149, 14)      1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_74 (MaxPooling (None, 74, 74, 14)        0         
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_74 (Batc (None, 74, 74, 14)        56        
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_150 (Conv2D)          (None, 74, 74, 14)        1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_151 (Conv2D)          (None, 74, 74, 14)        1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_75 (MaxPooling (None, 37, 37, 14)        0         
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_75 (Batc (None, 37, 37, 14)        56        
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_152 (Conv2D)          (None, 37, 37, 14)        1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_153 (Conv2D)          (None, 37, 37, 14)        1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_76 (MaxPooling (None, 18, 18, 14)        0         
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_76 (Batc (None, 18, 18, 14)        56        
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_154 (Conv2D)          (None, 18, 18, 14)        1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_155 (Conv2D)          (None, 18, 18, 14)        1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_77 (MaxPooling (None, 9, 9, 14)          0         
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_77 (Batc (None, 9, 9, 14)          56        
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_156 (Conv2D)          (None, 9, 9, 14)          1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   conv2d_157 (Conv2D)          (None, 9, 9, 14)          1778      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_78 (MaxPooling (None, 4, 4, 14)          0         
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_78 (Batc (None, 4, 4, 14)          56        
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   flatten_12 (Flatten)         (None, 224)               0         
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   dense_46 (Dense)             (None, 78)                17550     
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   dropout_34 (Dropout)         (None, 78)                0         
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   dense_47 (Dense)             (None, 78)                6162      
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   dropout_35 (Dropout)         (None, 78)                0         
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   dense_48 (Dense)             (None, 2)                 158       
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   =================================================================
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   Total params: 44,156
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   Trainable params: 43,988
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   Non-trainable params: 168
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   None
 40%|████      | 12/30 [1:10:31<2:16:53, 456.31s/it, best loss: 0.6380364894866943]2019-04-13 08:46:35.843379: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 40%|████      | 12/30 [1:12:18<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    1/10 [==>...........................]
 40%|████      | 12/30 [1:16:01<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 33:27 - loss: 0.9538 - sparse_categorical_accuracy: 0.4258 - f1_score: 0.8622
 40%|████      | 12/30 [1:16:01<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:16:02<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    2/10 [=====>........................]
 40%|████      | 12/30 [1:16:02<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 14:57 - loss: 0.8198 - sparse_categorical_accuracy: 0.4961 - f1_score: 0.8584
 40%|████      | 12/30 [1:16:02<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:16:04<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    3/10 [========>.....................]
 40%|████      | 12/30 [1:16:04<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 8:47 - loss: 0.7651 - sparse_categorical_accuracy: 0.5495 - f1_score: 0.8580 
 40%|████      | 12/30 [1:16:04<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:16:05<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    4/10 [===========>..................]
 40%|████      | 12/30 [1:16:05<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 5:41 - loss: 0.7280 - sparse_categorical_accuracy: 0.5938 - f1_score: 0.8545
 40%|████      | 12/30 [1:16:05<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:16:07<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    5/10 [==============>...............]
 40%|████      | 12/30 [1:16:07<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 3:48 - loss: 0.7001 - sparse_categorical_accuracy: 0.6203 - f1_score: 0.8525
 40%|████      | 12/30 [1:16:07<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:16:08<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    6/10 [=================>............]
 40%|████      | 12/30 [1:16:08<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 2:33 - loss: 0.6782 - sparse_categorical_accuracy: 0.6465 - f1_score: 0.8558
 40%|████      | 12/30 [1:16:08<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:16:10<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    7/10 [====================>.........]
 40%|████      | 12/30 [1:16:10<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 1:39 - loss: 0.6655 - sparse_categorical_accuracy: 0.6618 - f1_score: 0.8563
 40%|████      | 12/30 [1:16:10<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:16:11<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    8/10 [=======================>......]
 40%|████      | 12/30 [1:16:11<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 58s - loss: 0.6600 - sparse_categorical_accuracy: 0.6733 - f1_score: 0.8574 
 40%|████      | 12/30 [1:16:11<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:16:13<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    9/10 [==========================>...]
 40%|████      | 12/30 [1:16:13<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 26s - loss: 0.6430 - sparse_categorical_accuracy: 0.6827 - f1_score: 0.8574
 40%|████      | 12/30 [1:16:13<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:35<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   10/10 [==============================]
 40%|████      | 12/30 [1:18:35<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - 377s 38s/step - loss: 0.6318 - sparse_categorical_accuracy: 0.6891 - f1_score: 0.8566 - val_loss: 0.6207 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 40%|████      | 12/30 [1:18:35<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   Epoch 2/2
 40%|████      | 12/30 [1:18:35<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    1/10 [==>...........................]
 40%|████      | 12/30 [1:18:36<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 13s - loss: 0.5366 - sparse_categorical_accuracy: 0.7422 - f1_score: 0.8364
 40%|████      | 12/30 [1:18:36<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:38<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    2/10 [=====>........................]
 40%|████      | 12/30 [1:18:38<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 11s - loss: 0.5318 - sparse_categorical_accuracy: 0.7461 - f1_score: 0.8390
 40%|████      | 12/30 [1:18:38<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:39<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    3/10 [========>.....................]
 40%|████      | 12/30 [1:18:39<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 10s - loss: 0.5245 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8450
 40%|████      | 12/30 [1:18:39<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:41<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    4/10 [===========>..................]
 40%|████      | 12/30 [1:18:41<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 8s - loss: 0.5173 - sparse_categorical_accuracy: 0.7549 - f1_score: 0.8518 
 40%|████      | 12/30 [1:18:41<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:42<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    5/10 [==============>...............]
 40%|████      | 12/30 [1:18:42<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 7s - loss: 0.5373 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8508
 40%|████      | 12/30 [1:18:42<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:44<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    6/10 [=================>............]
 40%|████      | 12/30 [1:18:44<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 5s - loss: 0.5358 - sparse_categorical_accuracy: 0.7507 - f1_score: 0.8506
 40%|████      | 12/30 [1:18:44<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:45<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    7/10 [====================>.........]
 40%|████      | 12/30 [1:18:45<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 4s - loss: 0.5332 - sparse_categorical_accuracy: 0.7517 - f1_score: 0.8508
 40%|████      | 12/30 [1:18:45<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:47<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    8/10 [=======================>......]
 40%|████      | 12/30 [1:18:47<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 2s - loss: 0.5200 - sparse_categorical_accuracy: 0.7598 - f1_score: 0.8510
 40%|████      | 12/30 [1:18:47<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:48<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    9/10 [==========================>...]
 40%|████      | 12/30 [1:18:48<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 1s - loss: 0.5165 - sparse_categorical_accuracy: 0.7622 - f1_score: 0.8519
 40%|████      | 12/30 [1:18:48<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   
 40%|████      | 12/30 [1:18:51<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   10/10 [==============================]
 40%|████      | 12/30 [1:18:51<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                    - 16s 2s/step - loss: 0.5146 - sparse_categorical_accuracy: 0.7637 - f1_score: 0.8530 - val_loss: 0.6410 - val_sparse_categorical_accuracy: 0.7208 - val_f1_score: 0.8406

 40%|████      | 12/30 [1:18:51<2:16:53, 456.31s/it, best loss: 0.6380364894866943]                                                                                   0.6409854292869568
 40%|████      | 12/30 [1:20:09<2:16:53, 456.31s/it, best loss: 0.6380364894866943] 43%|████▎     | 13/30 [1:20:09<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   Layer (type)                 Output Shape              Param #   
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   =================================================================
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_158 (Conv2D)          (None, 299, 299, 64)      1792      
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_159 (Conv2D)          (None, 299, 299, 64)      36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_79 (MaxPooling (None, 149, 149, 64)      0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_79 (Batc (None, 149, 149, 64)      256       
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_160 (Conv2D)          (None, 149, 149, 64)      36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_161 (Conv2D)          (None, 149, 149, 64)      36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_80 (MaxPooling (None, 74, 74, 64)        0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_80 (Batc (None, 74, 74, 64)        256       
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_162 (Conv2D)          (None, 74, 74, 64)        36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_163 (Conv2D)          (None, 74, 74, 64)        36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_81 (MaxPooling (None, 37, 37, 64)        0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_81 (Batc (None, 37, 37, 64)        256       
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_164 (Conv2D)          (None, 37, 37, 64)        36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_165 (Conv2D)          (None, 37, 37, 64)        36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_82 (MaxPooling (None, 18, 18, 64)        0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_82 (Batc (None, 18, 18, 64)        256       
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_166 (Conv2D)          (None, 18, 18, 64)        36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_167 (Conv2D)          (None, 18, 18, 64)        36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_83 (MaxPooling (None, 9, 9, 64)          0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_83 (Batc (None, 9, 9, 64)          256       
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_168 (Conv2D)          (None, 9, 9, 64)          36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_169 (Conv2D)          (None, 9, 9, 64)          36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_84 (MaxPooling (None, 4, 4, 64)          0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_84 (Batc (None, 4, 4, 64)          256       
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_170 (Conv2D)          (None, 4, 4, 64)          36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_171 (Conv2D)          (None, 4, 4, 64)          36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_85 (MaxPooling (None, 2, 2, 64)          0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_85 (Batc (None, 2, 2, 64)          256       
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_172 (Conv2D)          (None, 2, 2, 64)          36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   conv2d_173 (Conv2D)          (None, 2, 2, 64)          36928     
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   max_pooling2d_86 (MaxPooling (None, 1, 1, 64)          0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   batch_normalization_86 (Batc (None, 1, 1, 64)          256       
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   flatten_13 (Flatten)         (None, 64)                0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dense_49 (Dense)             (None, 98)                6370      
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dropout_36 (Dropout)         (None, 98)                0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dense_50 (Dense)             (None, 98)                9702      
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dropout_37 (Dropout)         (None, 98)                0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dense_51 (Dense)             (None, 98)                9702      
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dropout_38 (Dropout)         (None, 98)                0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dense_52 (Dense)             (None, 98)                9702      
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dropout_39 (Dropout)         (None, 98)                0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dense_53 (Dense)             (None, 98)                9702      
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dropout_40 (Dropout)         (None, 98)                0         
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   dense_54 (Dense)             (None, 2)                 198       
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   =================================================================
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   Total params: 603,136
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   Trainable params: 602,112
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   Non-trainable params: 1,024
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   None
 43%|████▎     | 13/30 [1:20:13<2:19:56, 493.93s/it, best loss: 0.6380364894866943]2019-04-13 08:56:17.719942: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 43%|████▎     | 13/30 [1:22:17<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    1/10 [==>...........................]
 43%|████▎     | 13/30 [1:26:25<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 37:13 - loss: 1.2621 - sparse_categorical_accuracy: 0.5156 - f1_score: 0.8673
 43%|████▎     | 13/30 [1:26:25<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:26:27<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    2/10 [=====>........................]
 43%|████▎     | 13/30 [1:26:27<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 16:39 - loss: 1.2449 - sparse_categorical_accuracy: 0.5215 - f1_score: 0.8596
 43%|████▎     | 13/30 [1:26:27<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:26:28<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    3/10 [========>.....................]
 43%|████▎     | 13/30 [1:26:28<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 9:46 - loss: 1.2351 - sparse_categorical_accuracy: 0.5260 - f1_score: 0.8510 
 43%|████▎     | 13/30 [1:26:28<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:26:30<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    4/10 [===========>..................]
 43%|████▎     | 13/30 [1:26:30<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 6:19 - loss: 1.2151 - sparse_categorical_accuracy: 0.5322 - f1_score: 0.8525
 43%|████▎     | 13/30 [1:26:30<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:26:32<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    5/10 [==============>...............]
 43%|████▎     | 13/30 [1:26:32<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 4:14 - loss: 1.1369 - sparse_categorical_accuracy: 0.5508 - f1_score: 0.8540
 43%|████▎     | 13/30 [1:26:32<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:26:33<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    6/10 [=================>............]
 43%|████▎     | 13/30 [1:26:33<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 2:50 - loss: 1.1313 - sparse_categorical_accuracy: 0.5592 - f1_score: 0.8528
 43%|████▎     | 13/30 [1:26:33<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:26:35<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    7/10 [====================>.........]
 43%|████▎     | 13/30 [1:26:35<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 1:50 - loss: 1.0885 - sparse_categorical_accuracy: 0.5686 - f1_score: 0.8545
 43%|████▎     | 13/30 [1:26:35<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:26:36<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    8/10 [=======================>......]
 43%|████▎     | 13/30 [1:26:36<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 1:04 - loss: 1.0531 - sparse_categorical_accuracy: 0.5801 - f1_score: 0.8561
 43%|████▎     | 13/30 [1:26:36<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:26:38<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    9/10 [==========================>...]
 43%|████▎     | 13/30 [1:26:38<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 29s - loss: 1.0141 - sparse_categorical_accuracy: 0.5868 - f1_score: 0.8556 
 43%|████▎     | 13/30 [1:26:38<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:14<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   10/10 [==============================]
 43%|████▎     | 13/30 [1:29:14<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - 417s 42s/step - loss: 0.9863 - sparse_categorical_accuracy: 0.5945 - f1_score: 0.8558 - val_loss: 0.6110 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 43%|████▎     | 13/30 [1:29:14<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   Epoch 2/2
 43%|████▎     | 13/30 [1:29:14<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    1/10 [==>...........................]
 43%|████▎     | 13/30 [1:29:15<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 15s - loss: 0.6936 - sparse_categorical_accuracy: 0.7109 - f1_score: 0.8647
 43%|████▎     | 13/30 [1:29:15<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:17<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    2/10 [=====>........................]
 43%|████▎     | 13/30 [1:29:17<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 13s - loss: 0.7879 - sparse_categorical_accuracy: 0.6875 - f1_score: 0.8571
 43%|████▎     | 13/30 [1:29:17<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:19<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    3/10 [========>.....................]
 43%|████▎     | 13/30 [1:29:19<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 11s - loss: 0.8545 - sparse_categorical_accuracy: 0.6875 - f1_score: 0.8571
 43%|████▎     | 13/30 [1:29:19<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:20<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    4/10 [===========>..................]
 43%|████▎     | 13/30 [1:29:20<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 9s - loss: 0.8193 - sparse_categorical_accuracy: 0.6885 - f1_score: 0.8565 
 43%|████▎     | 13/30 [1:29:20<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:22<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    5/10 [==============>...............]
 43%|████▎     | 13/30 [1:29:22<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 8s - loss: 0.7987 - sparse_categorical_accuracy: 0.6891 - f1_score: 0.8581
 43%|████▎     | 13/30 [1:29:22<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:24<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    6/10 [=================>............]
 43%|████▎     | 13/30 [1:29:24<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 6s - loss: 0.7763 - sparse_categorical_accuracy: 0.6927 - f1_score: 0.8575
 43%|████▎     | 13/30 [1:29:24<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:25<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    7/10 [====================>.........]
 43%|████▎     | 13/30 [1:29:25<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 4s - loss: 0.7759 - sparse_categorical_accuracy: 0.6959 - f1_score: 0.8586
 43%|████▎     | 13/30 [1:29:25<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:27<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    8/10 [=======================>......]
 43%|████▎     | 13/30 [1:29:27<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 3s - loss: 0.7762 - sparse_categorical_accuracy: 0.6973 - f1_score: 0.8584
 43%|████▎     | 13/30 [1:29:27<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:29<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    9/10 [==========================>...]
 43%|████▎     | 13/30 [1:29:29<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - ETA: 1s - loss: 0.7595 - sparse_categorical_accuracy: 0.7005 - f1_score: 0.8591
 43%|████▎     | 13/30 [1:29:29<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   
 43%|████▎     | 13/30 [1:29:32<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   10/10 [==============================]
 43%|████▎     | 13/30 [1:29:32<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                    - 18s 2s/step - loss: 0.7546 - sparse_categorical_accuracy: 0.7012 - f1_score: 0.8592 - val_loss: 0.6245 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 43%|████▎     | 13/30 [1:29:32<2:19:56, 493.93s/it, best loss: 0.6380364894866943]                                                                                   0.6244885921478271
 43%|████▎     | 13/30 [1:31:04<2:19:56, 493.93s/it, best loss: 0.6380364894866943] 47%|████▋     | 14/30 [1:31:04<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   Layer (type)                 Output Shape              Param #   
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_174 (Conv2D)          (None, 299, 299, 13)      364       
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_175 (Conv2D)          (None, 299, 299, 13)      1534      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_87 (MaxPooling (None, 149, 149, 13)      0         
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_87 (Batc (None, 149, 149, 13)      52        
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_176 (Conv2D)          (None, 149, 149, 13)      1534      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_177 (Conv2D)          (None, 149, 149, 13)      1534      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_88 (MaxPooling (None, 74, 74, 13)        0         
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_88 (Batc (None, 74, 74, 13)        52        
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_178 (Conv2D)          (None, 74, 74, 13)        1534      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_179 (Conv2D)          (None, 74, 74, 13)        1534      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_89 (MaxPooling (None, 37, 37, 13)        0         
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_89 (Batc (None, 37, 37, 13)        52        
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_180 (Conv2D)          (None, 37, 37, 13)        1534      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_181 (Conv2D)          (None, 37, 37, 13)        1534      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_90 (MaxPooling (None, 18, 18, 13)        0         
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_90 (Batc (None, 18, 18, 13)        52        
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_182 (Conv2D)          (None, 18, 18, 13)        1534      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   conv2d_183 (Conv2D)          (None, 18, 18, 13)        1534      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_91 (MaxPooling (None, 9, 9, 13)          0         
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_91 (Batc (None, 9, 9, 13)          52        
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   flatten_14 (Flatten)         (None, 1053)              0         
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   dense_55 (Dense)             (None, 9)                 9486      
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   dropout_41 (Dropout)         (None, 9)                 0         
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   dense_56 (Dense)             (None, 9)                 90        
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   dropout_42 (Dropout)         (None, 9)                 0         
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   dense_57 (Dense)             (None, 9)                 90        
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   dropout_43 (Dropout)         (None, 9)                 0         
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   dense_58 (Dense)             (None, 2)                 20        
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   Total params: 24,116
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   Trainable params: 23,986
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   Non-trainable params: 130
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   None
 47%|████▋     | 14/30 [1:31:08<2:24:35, 542.23s/it, best loss: 0.6244885921478271]2019-04-13 09:07:12.729316: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 47%|████▋     | 14/30 [1:33:33<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 47%|████▋     | 14/30 [1:37:51<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 38:35 - loss: 1.2546 - sparse_categorical_accuracy: 0.6953 - f1_score: 0.1887
 47%|████▋     | 14/30 [1:37:51<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:37:52<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 47%|████▋     | 14/30 [1:37:52<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 17:15 - loss: 1.3527 - sparse_categorical_accuracy: 0.6543 - f1_score: 0.5165
 47%|████▋     | 14/30 [1:37:52<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:37:54<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 47%|████▋     | 14/30 [1:37:54<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 10:07 - loss: 1.3444 - sparse_categorical_accuracy: 0.6784 - f1_score: 0.6326
 47%|████▋     | 14/30 [1:37:54<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:37:55<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 47%|████▋     | 14/30 [1:37:55<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 6:32 - loss: 1.2779 - sparse_categorical_accuracy: 0.6973 - f1_score: 0.6906 
 47%|████▋     | 14/30 [1:37:55<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:37:57<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 47%|████▋     | 14/30 [1:37:57<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 4:23 - loss: 1.1949 - sparse_categorical_accuracy: 0.7117 - f1_score: 0.7259
 47%|████▋     | 14/30 [1:37:57<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:37:58<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 47%|████▋     | 14/30 [1:37:58<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 2:56 - loss: 1.2042 - sparse_categorical_accuracy: 0.7168 - f1_score: 0.7499
 47%|████▋     | 14/30 [1:37:58<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:38:00<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 47%|████▋     | 14/30 [1:38:00<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1:54 - loss: 1.1655 - sparse_categorical_accuracy: 0.7215 - f1_score: 0.7652
 47%|████▋     | 14/30 [1:38:00<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:38:01<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 47%|████▋     | 14/30 [1:38:01<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1:07 - loss: 1.1505 - sparse_categorical_accuracy: 0.7212 - f1_score: 0.7751
 47%|████▋     | 14/30 [1:38:01<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:38:03<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 47%|████▋     | 14/30 [1:38:03<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 29s - loss: 1.1429 - sparse_categorical_accuracy: 0.7222 - f1_score: 0.7848 
 47%|████▋     | 14/30 [1:38:03<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:40:46<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 47%|████▋     | 14/30 [1:40:46<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - 433s 43s/step - loss: 1.1313 - sparse_categorical_accuracy: 0.7219 - f1_score: 0.7912 - val_loss: 1.2072 - val_sparse_categorical_accuracy: 0.2750 - val_f1_score: 0.8406

 47%|████▋     | 14/30 [1:40:46<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   Epoch 2/2
 47%|████▋     | 14/30 [1:40:46<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 47%|████▋     | 14/30 [1:40:48<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 14s - loss: 1.2267 - sparse_categorical_accuracy: 0.7188 - f1_score: 0.8571
 47%|████▋     | 14/30 [1:40:48<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:40:49<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 47%|████▋     | 14/30 [1:40:49<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 12s - loss: 1.0733 - sparse_categorical_accuracy: 0.7344 - f1_score: 0.8571
 47%|████▋     | 14/30 [1:40:49<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:40:51<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 47%|████▋     | 14/30 [1:40:51<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 10s - loss: 1.1195 - sparse_categorical_accuracy: 0.7201 - f1_score: 0.8546
 47%|████▋     | 14/30 [1:40:51<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:40:52<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 47%|████▋     | 14/30 [1:40:52<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 9s - loss: 1.1275 - sparse_categorical_accuracy: 0.7168 - f1_score: 0.8533 
 47%|████▋     | 14/30 [1:40:52<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:40:54<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 47%|████▋     | 14/30 [1:40:54<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 7s - loss: 1.1399 - sparse_categorical_accuracy: 0.7164 - f1_score: 0.8510
 47%|████▋     | 14/30 [1:40:54<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:40:56<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 47%|████▋     | 14/30 [1:40:56<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 6s - loss: 1.0827 - sparse_categorical_accuracy: 0.7214 - f1_score: 0.8520
 47%|████▋     | 14/30 [1:40:56<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:40:57<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 47%|████▋     | 14/30 [1:40:57<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 4s - loss: 1.0502 - sparse_categorical_accuracy: 0.7243 - f1_score: 0.8531
 47%|████▋     | 14/30 [1:40:57<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:40:59<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 47%|████▋     | 14/30 [1:40:59<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 3s - loss: 1.0269 - sparse_categorical_accuracy: 0.7231 - f1_score: 0.8520
 47%|████▋     | 14/30 [1:40:59<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:41:00<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 47%|████▋     | 14/30 [1:41:00<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1s - loss: 1.0138 - sparse_categorical_accuracy: 0.7257 - f1_score: 0.8537
 47%|████▋     | 14/30 [1:41:00<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   
 47%|████▋     | 14/30 [1:41:03<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 47%|████▋     | 14/30 [1:41:03<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                    - 17s 2s/step - loss: 1.0267 - sparse_categorical_accuracy: 0.7250 - f1_score: 0.8533 - val_loss: 1.0313 - val_sparse_categorical_accuracy: 0.2750 - val_f1_score: 0.8406

 47%|████▋     | 14/30 [1:41:03<2:24:35, 542.23s/it, best loss: 0.6244885921478271]                                                                                   1.0312546491622925
 47%|████▋     | 14/30 [1:42:47<2:24:35, 542.23s/it, best loss: 0.6244885921478271] 50%|█████     | 15/30 [1:42:47<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   Layer (type)                 Output Shape              Param #   
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   conv2d_184 (Conv2D)          (None, 299, 299, 29)      812       
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   conv2d_185 (Conv2D)          (None, 299, 299, 29)      7598      
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_92 (MaxPooling (None, 149, 149, 29)      0         
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_92 (Batc (None, 149, 149, 29)      116       
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   conv2d_186 (Conv2D)          (None, 149, 149, 29)      7598      
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   conv2d_187 (Conv2D)          (None, 149, 149, 29)      7598      
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_93 (MaxPooling (None, 74, 74, 29)        0         
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_93 (Batc (None, 74, 74, 29)        116       
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   conv2d_188 (Conv2D)          (None, 74, 74, 29)        7598      
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   conv2d_189 (Conv2D)          (None, 74, 74, 29)        7598      
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_94 (MaxPooling (None, 37, 37, 29)        0         
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_94 (Batc (None, 37, 37, 29)        116       
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   conv2d_190 (Conv2D)          (None, 37, 37, 29)        7598      
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   conv2d_191 (Conv2D)          (None, 37, 37, 29)        7598      
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_95 (MaxPooling (None, 18, 18, 29)        0         
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_95 (Batc (None, 18, 18, 29)        116       
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   flatten_15 (Flatten)         (None, 9396)              0         
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   dense_59 (Dense)             (None, 40)                375880    
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   dropout_44 (Dropout)         (None, 40)                0         
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   dense_60 (Dense)             (None, 2)                 82        
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   Total params: 430,424
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   Trainable params: 430,192
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   Non-trainable params: 232
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   None
 50%|█████     | 15/30 [1:42:52<2:27:39, 590.66s/it, best loss: 0.6244885921478271]2019-04-13 09:18:56.783365: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 50%|█████     | 15/30 [1:45:33<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 50%|█████     | 15/30 [1:50:07<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 41:03 - loss: 1.5869 - sparse_categorical_accuracy: 0.4766 - f1_score: 0.8647
 50%|█████     | 15/30 [1:50:07<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:50:08<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 50%|█████     | 15/30 [1:50:08<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 18:21 - loss: 1.5941 - sparse_categorical_accuracy: 0.6211 - f1_score: 0.8660
 50%|█████     | 15/30 [1:50:08<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:50:10<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 50%|█████     | 15/30 [1:50:10<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 10:45 - loss: 1.5304 - sparse_categorical_accuracy: 0.6667 - f1_score: 0.8664
 50%|█████     | 15/30 [1:50:10<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:50:11<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 50%|█████     | 15/30 [1:50:11<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 6:57 - loss: 1.3233 - sparse_categorical_accuracy: 0.7012 - f1_score: 0.8673 
 50%|█████     | 15/30 [1:50:11<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:50:13<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 50%|█████     | 15/30 [1:50:13<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 4:39 - loss: 1.2078 - sparse_categorical_accuracy: 0.7078 - f1_score: 0.8673
 50%|█████     | 15/30 [1:50:13<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:50:14<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 50%|█████     | 15/30 [1:50:14<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 3:07 - loss: 1.1578 - sparse_categorical_accuracy: 0.7109 - f1_score: 0.8630
 50%|█████     | 15/30 [1:50:14<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:50:16<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 50%|█████     | 15/30 [1:50:16<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 2:01 - loss: 1.0804 - sparse_categorical_accuracy: 0.7221 - f1_score: 0.8636
 50%|█████     | 15/30 [1:50:16<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:50:17<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 50%|█████     | 15/30 [1:50:17<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1:11 - loss: 1.0415 - sparse_categorical_accuracy: 0.7222 - f1_score: 0.8621
 50%|█████     | 15/30 [1:50:17<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:50:19<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 50%|█████     | 15/30 [1:50:19<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 31s - loss: 1.0047 - sparse_categorical_accuracy: 0.7274 - f1_score: 0.8602 
 50%|█████     | 15/30 [1:50:19<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:21<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 50%|█████     | 15/30 [1:53:21<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - 468s 47s/step - loss: 0.9697 - sparse_categorical_accuracy: 0.7344 - f1_score: 0.8609 - val_loss: 0.9652 - val_sparse_categorical_accuracy: 0.7208 - val_f1_score: 0.8406

 50%|█████     | 15/30 [1:53:21<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   Epoch 2/2
 50%|█████     | 15/30 [1:53:21<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 50%|█████     | 15/30 [1:53:22<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 14s - loss: 0.5582 - sparse_categorical_accuracy: 0.7852 - f1_score: 0.8494
 50%|█████     | 15/30 [1:53:22<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:24<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 50%|█████     | 15/30 [1:53:24<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 12s - loss: 0.5573 - sparse_categorical_accuracy: 0.7832 - f1_score: 0.8533
 50%|█████     | 15/30 [1:53:24<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:25<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 50%|█████     | 15/30 [1:53:25<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 10s - loss: 0.5348 - sparse_categorical_accuracy: 0.7852 - f1_score: 0.8520
 50%|█████     | 15/30 [1:53:25<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:27<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 50%|█████     | 15/30 [1:53:27<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 9s - loss: 0.5009 - sparse_categorical_accuracy: 0.7910 - f1_score: 0.8539 
 50%|█████     | 15/30 [1:53:27<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:28<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 50%|█████     | 15/30 [1:53:28<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 7s - loss: 0.4979 - sparse_categorical_accuracy: 0.7883 - f1_score: 0.8520
 50%|█████     | 15/30 [1:53:28<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:30<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 50%|█████     | 15/30 [1:53:30<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 6s - loss: 0.4726 - sparse_categorical_accuracy: 0.7962 - f1_score: 0.8541
 50%|█████     | 15/30 [1:53:30<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:32<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 50%|█████     | 15/30 [1:53:32<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 4s - loss: 0.4755 - sparse_categorical_accuracy: 0.7924 - f1_score: 0.8516
 50%|█████     | 15/30 [1:53:32<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:33<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 50%|█████     | 15/30 [1:53:33<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 3s - loss: 0.4584 - sparse_categorical_accuracy: 0.7983 - f1_score: 0.8539
 50%|█████     | 15/30 [1:53:33<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:35<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 50%|█████     | 15/30 [1:53:35<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1s - loss: 0.4570 - sparse_categorical_accuracy: 0.7973 - f1_score: 0.8545
 50%|█████     | 15/30 [1:53:35<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   
 50%|█████     | 15/30 [1:53:37<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 50%|█████     | 15/30 [1:53:37<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                    - 16s 2s/step - loss: 0.4518 - sparse_categorical_accuracy: 0.7992 - f1_score: 0.8540 - val_loss: 0.8268 - val_sparse_categorical_accuracy: 0.7125 - val_f1_score: 0.8406

 50%|█████     | 15/30 [1:53:37<2:27:39, 590.66s/it, best loss: 0.6244885921478271]                                                                                   0.8268285393714905
 50%|█████     | 15/30 [1:55:25<2:27:39, 590.66s/it, best loss: 0.6244885921478271] 53%|█████▎    | 16/30 [1:55:25<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   Layer (type)                 Output Shape              Param #   
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_192 (Conv2D)          (None, 299, 299, 97)      2716      
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_193 (Conv2D)          (None, 299, 299, 97)      84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_96 (MaxPooling (None, 149, 149, 97)      0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_96 (Batc (None, 149, 149, 97)      388       
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_194 (Conv2D)          (None, 149, 149, 97)      84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_195 (Conv2D)          (None, 149, 149, 97)      84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_97 (MaxPooling (None, 74, 74, 97)        0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_97 (Batc (None, 74, 74, 97)        388       
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_196 (Conv2D)          (None, 74, 74, 97)        84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_197 (Conv2D)          (None, 74, 74, 97)        84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_98 (MaxPooling (None, 37, 37, 97)        0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_98 (Batc (None, 37, 37, 97)        388       
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_198 (Conv2D)          (None, 37, 37, 97)        84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_199 (Conv2D)          (None, 37, 37, 97)        84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_99 (MaxPooling (None, 18, 18, 97)        0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_99 (Batc (None, 18, 18, 97)        388       
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_200 (Conv2D)          (None, 18, 18, 97)        84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_201 (Conv2D)          (None, 18, 18, 97)        84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_100 (MaxPoolin (None, 9, 9, 97)          0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_100 (Bat (None, 9, 9, 97)          388       
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_202 (Conv2D)          (None, 9, 9, 97)          84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   conv2d_203 (Conv2D)          (None, 9, 9, 97)          84778     
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_101 (MaxPoolin (None, 4, 4, 97)          0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_101 (Bat (None, 4, 4, 97)          388       
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   flatten_16 (Flatten)         (None, 1552)              0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   dense_61 (Dense)             (None, 67)                104051    
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   dropout_45 (Dropout)         (None, 67)                0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   dense_62 (Dense)             (None, 67)                4556      
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   dropout_46 (Dropout)         (None, 67)                0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   dense_63 (Dense)             (None, 67)                4556      
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   dropout_47 (Dropout)         (None, 67)                0         
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   dense_64 (Dense)             (None, 2)                 136       
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   Total params: 1,050,901
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   Trainable params: 1,049,737
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   Non-trainable params: 1,164
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   None
 53%|█████▎    | 16/30 [1:55:29<2:29:28, 640.64s/it, best loss: 0.6244885921478271]2019-04-13 09:31:34.329481: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 53%|█████▎    | 16/30 [1:58:18<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 53%|█████▎    | 16/30 [2:03:13<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 44:16 - loss: 0.8686 - sparse_categorical_accuracy: 0.3242 - f1_score: 0.8673
 53%|█████▎    | 16/30 [2:03:13<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:03:15<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 53%|█████▎    | 16/30 [2:03:15<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 19:46 - loss: 0.7251 - sparse_categorical_accuracy: 0.5195 - f1_score: 0.8673
 53%|█████▎    | 16/30 [2:03:15<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:03:16<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 53%|█████▎    | 16/30 [2:03:16<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 11:36 - loss: 0.6641 - sparse_categorical_accuracy: 0.6003 - f1_score: 0.8630
 53%|█████▎    | 16/30 [2:03:16<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:03:18<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 53%|█████▎    | 16/30 [2:03:18<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 7:29 - loss: 0.6261 - sparse_categorical_accuracy: 0.6436 - f1_score: 0.8647 
 53%|█████▎    | 16/30 [2:03:18<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:03:19<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 53%|█████▎    | 16/30 [2:03:19<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 5:01 - loss: 0.6030 - sparse_categorical_accuracy: 0.6672 - f1_score: 0.8622
 53%|█████▎    | 16/30 [2:03:19<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:03:21<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 53%|█████▎    | 16/30 [2:03:21<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 3:22 - loss: 0.5832 - sparse_categorical_accuracy: 0.6816 - f1_score: 0.8579
 53%|█████▎    | 16/30 [2:03:21<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:03:23<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 53%|█████▎    | 16/30 [2:03:23<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 2:10 - loss: 0.5760 - sparse_categorical_accuracy: 0.6959 - f1_score: 0.8589
 53%|█████▎    | 16/30 [2:03:23<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:03:24<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 53%|█████▎    | 16/30 [2:03:24<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1:16 - loss: 0.5551 - sparse_categorical_accuracy: 0.7095 - f1_score: 0.8583
 53%|█████▎    | 16/30 [2:03:24<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:03:26<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 53%|█████▎    | 16/30 [2:03:26<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 34s - loss: 0.5450 - sparse_categorical_accuracy: 0.7153 - f1_score: 0.8565 
 53%|█████▎    | 16/30 [2:03:26<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:35<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 53%|█████▎    | 16/30 [2:06:35<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - 497s 50s/step - loss: 0.5340 - sparse_categorical_accuracy: 0.7246 - f1_score: 0.8575 - val_loss: 3.2336 - val_sparse_categorical_accuracy: 0.3958 - val_f1_score: 0.8406

 53%|█████▎    | 16/30 [2:06:35<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   Epoch 2/2
 53%|█████▎    | 16/30 [2:06:35<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 53%|█████▎    | 16/30 [2:06:37<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 14s - loss: 0.3782 - sparse_categorical_accuracy: 0.8008 - f1_score: 0.8416
 53%|█████▎    | 16/30 [2:06:37<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:38<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 53%|█████▎    | 16/30 [2:06:38<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 13s - loss: 0.3526 - sparse_categorical_accuracy: 0.8145 - f1_score: 0.8468
 53%|█████▎    | 16/30 [2:06:38<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:40<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 53%|█████▎    | 16/30 [2:06:40<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 11s - loss: 0.3599 - sparse_categorical_accuracy: 0.8177 - f1_score: 0.8433
 53%|█████▎    | 16/30 [2:06:40<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:42<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 53%|█████▎    | 16/30 [2:06:42<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 9s - loss: 0.3750 - sparse_categorical_accuracy: 0.8154 - f1_score: 0.8481 
 53%|█████▎    | 16/30 [2:06:42<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:43<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 53%|█████▎    | 16/30 [2:06:43<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 8s - loss: 0.3588 - sparse_categorical_accuracy: 0.8289 - f1_score: 0.8483
 53%|█████▎    | 16/30 [2:06:43<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:45<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 53%|█████▎    | 16/30 [2:06:45<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 6s - loss: 0.3493 - sparse_categorical_accuracy: 0.8346 - f1_score: 0.8506
 53%|█████▎    | 16/30 [2:06:45<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:47<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 53%|█████▎    | 16/30 [2:06:47<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 4s - loss: 0.3443 - sparse_categorical_accuracy: 0.8382 - f1_score: 0.8530
 53%|█████▎    | 16/30 [2:06:47<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:48<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 53%|█████▎    | 16/30 [2:06:48<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 3s - loss: 0.3304 - sparse_categorical_accuracy: 0.8477 - f1_score: 0.8535
 53%|█████▎    | 16/30 [2:06:48<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:50<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 53%|█████▎    | 16/30 [2:06:50<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1s - loss: 0.3200 - sparse_categorical_accuracy: 0.8559 - f1_score: 0.8548
 53%|█████▎    | 16/30 [2:06:50<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   
 53%|█████▎    | 16/30 [2:06:53<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 53%|█████▎    | 16/30 [2:06:53<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                    - 18s 2s/step - loss: 0.3059 - sparse_categorical_accuracy: 0.8625 - f1_score: 0.8537 - val_loss: 1.0869 - val_sparse_categorical_accuracy: 0.5042 - val_f1_score: 0.8406

 53%|█████▎    | 16/30 [2:06:53<2:29:28, 640.64s/it, best loss: 0.6244885921478271]                                                                                   1.0868991613388062
 53%|█████▎    | 16/30 [2:08:51<2:29:28, 640.64s/it, best loss: 0.6244885921478271] 57%|█████▋    | 17/30 [2:08:51<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   Layer (type)                 Output Shape              Param #   
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_204 (Conv2D)          (None, 299, 299, 13)      364       
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_205 (Conv2D)          (None, 299, 299, 13)      1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_102 (MaxPoolin (None, 149, 149, 13)      0         
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_102 (Bat (None, 149, 149, 13)      52        
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_206 (Conv2D)          (None, 149, 149, 13)      1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_207 (Conv2D)          (None, 149, 149, 13)      1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_103 (MaxPoolin (None, 74, 74, 13)        0         
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_103 (Bat (None, 74, 74, 13)        52        
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_208 (Conv2D)          (None, 74, 74, 13)        1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_209 (Conv2D)          (None, 74, 74, 13)        1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_104 (MaxPoolin (None, 37, 37, 13)        0         
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_104 (Bat (None, 37, 37, 13)        52        
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_210 (Conv2D)          (None, 37, 37, 13)        1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_211 (Conv2D)          (None, 37, 37, 13)        1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_105 (MaxPoolin (None, 18, 18, 13)        0         
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_105 (Bat (None, 18, 18, 13)        52        
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_212 (Conv2D)          (None, 18, 18, 13)        1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_213 (Conv2D)          (None, 18, 18, 13)        1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_106 (MaxPoolin (None, 9, 9, 13)          0         
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_106 (Bat (None, 9, 9, 13)          52        
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_214 (Conv2D)          (None, 9, 9, 13)          1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   conv2d_215 (Conv2D)          (None, 9, 9, 13)          1534      
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_107 (MaxPoolin (None, 4, 4, 13)          0         
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_107 (Bat (None, 4, 4, 13)          52        
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   flatten_17 (Flatten)         (None, 208)               0         
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   dense_65 (Dense)             (None, 68)                14212     
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   dropout_48 (Dropout)         (None, 68)                0         
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   dense_66 (Dense)             (None, 2)                 138       
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   Total params: 31,900
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   Trainable params: 31,744
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   Non-trainable params: 156
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   None
 57%|█████▋    | 17/30 [2:08:55<2:29:34, 690.33s/it, best loss: 0.6244885921478271]2019-04-13 09:45:00.142063: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 57%|█████▋    | 17/30 [2:11:59<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 57%|█████▋    | 17/30 [2:17:04<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 45:44 - loss: 1.4800 - sparse_categorical_accuracy: 0.3359 - f1_score: 0.8442
 57%|█████▋    | 17/30 [2:17:04<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:17:06<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 57%|█████▋    | 17/30 [2:17:06<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 20:25 - loss: 1.3408 - sparse_categorical_accuracy: 0.3418 - f1_score: 0.8558
 57%|█████▋    | 17/30 [2:17:06<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:17:07<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 57%|█████▋    | 17/30 [2:17:07<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 11:58 - loss: 1.2183 - sparse_categorical_accuracy: 0.3893 - f1_score: 0.8579
 57%|█████▋    | 17/30 [2:17:07<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:17:09<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 57%|█████▋    | 17/30 [2:17:09<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 7:44 - loss: 1.1175 - sparse_categorical_accuracy: 0.4258 - f1_score: 0.8545 
 57%|█████▋    | 17/30 [2:17:09<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:17:10<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 57%|█████▋    | 17/30 [2:17:10<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 5:11 - loss: 1.0303 - sparse_categorical_accuracy: 0.4695 - f1_score: 0.8575
 57%|█████▋    | 17/30 [2:17:10<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:17:12<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 57%|█████▋    | 17/30 [2:17:12<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 3:28 - loss: 0.9681 - sparse_categorical_accuracy: 0.4993 - f1_score: 0.8579
 57%|█████▋    | 17/30 [2:17:12<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:17:13<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 57%|█████▋    | 17/30 [2:17:13<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 2:14 - loss: 0.9137 - sparse_categorical_accuracy: 0.5285 - f1_score: 0.8567
 57%|█████▋    | 17/30 [2:17:13<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:17:15<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 57%|█████▋    | 17/30 [2:17:15<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1:18 - loss: 0.8690 - sparse_categorical_accuracy: 0.5547 - f1_score: 0.8580
 57%|█████▋    | 17/30 [2:17:15<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:17:16<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 57%|█████▋    | 17/30 [2:17:16<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 35s - loss: 0.8334 - sparse_categorical_accuracy: 0.5755 - f1_score: 0.8571 
 57%|█████▋    | 17/30 [2:17:16<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:33<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 57%|█████▋    | 17/30 [2:20:33<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - 514s 51s/step - loss: 0.7997 - sparse_categorical_accuracy: 0.5949 - f1_score: 0.8578 - val_loss: 0.6246 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 57%|█████▋    | 17/30 [2:20:33<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   Epoch 2/2
 57%|█████▋    | 17/30 [2:20:33<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 57%|█████▋    | 17/30 [2:20:35<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 13s - loss: 0.5597 - sparse_categorical_accuracy: 0.7734 - f1_score: 0.8647
 57%|█████▋    | 17/30 [2:20:35<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:36<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 57%|█████▋    | 17/30 [2:20:36<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 11s - loss: 0.5374 - sparse_categorical_accuracy: 0.7754 - f1_score: 0.8622
 57%|█████▋    | 17/30 [2:20:36<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:38<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 57%|█████▋    | 17/30 [2:20:38<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 10s - loss: 0.5182 - sparse_categorical_accuracy: 0.7786 - f1_score: 0.8631
 57%|█████▋    | 17/30 [2:20:38<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:39<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 57%|█████▋    | 17/30 [2:20:39<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 8s - loss: 0.5207 - sparse_categorical_accuracy: 0.7764 - f1_score: 0.8570 
 57%|█████▋    | 17/30 [2:20:39<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:41<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 57%|█████▋    | 17/30 [2:20:41<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 7s - loss: 0.5259 - sparse_categorical_accuracy: 0.7758 - f1_score: 0.8571
 57%|█████▋    | 17/30 [2:20:41<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:42<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 57%|█████▋    | 17/30 [2:20:42<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 5s - loss: 0.5242 - sparse_categorical_accuracy: 0.7773 - f1_score: 0.8536
 57%|█████▋    | 17/30 [2:20:42<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:44<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 57%|█████▋    | 17/30 [2:20:44<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 4s - loss: 0.5104 - sparse_categorical_accuracy: 0.7852 - f1_score: 0.8534
 57%|█████▋    | 17/30 [2:20:44<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:45<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 57%|█████▋    | 17/30 [2:20:45<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 2s - loss: 0.5047 - sparse_categorical_accuracy: 0.7881 - f1_score: 0.8554
 57%|█████▋    | 17/30 [2:20:45<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:47<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 57%|█████▋    | 17/30 [2:20:47<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1s - loss: 0.4983 - sparse_categorical_accuracy: 0.7904 - f1_score: 0.8536
 57%|█████▋    | 17/30 [2:20:47<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   
 57%|█████▋    | 17/30 [2:20:49<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 57%|█████▋    | 17/30 [2:20:49<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                    - 16s 2s/step - loss: 0.4902 - sparse_categorical_accuracy: 0.7949 - f1_score: 0.8557 - val_loss: 0.6443 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 57%|█████▋    | 17/30 [2:20:49<2:29:34, 690.33s/it, best loss: 0.6244885921478271]                                                                                   0.6443206071853638
 57%|█████▋    | 17/30 [2:23:01<2:29:34, 690.33s/it, best loss: 0.6244885921478271] 60%|██████    | 18/30 [2:23:01<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   Layer (type)                 Output Shape              Param #   
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_216 (Conv2D)          (None, 299, 299, 19)      532       
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_217 (Conv2D)          (None, 299, 299, 19)      3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_108 (MaxPoolin (None, 149, 149, 19)      0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_108 (Bat (None, 149, 149, 19)      76        
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_218 (Conv2D)          (None, 149, 149, 19)      3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_219 (Conv2D)          (None, 149, 149, 19)      3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_109 (MaxPoolin (None, 74, 74, 19)        0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_109 (Bat (None, 74, 74, 19)        76        
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_220 (Conv2D)          (None, 74, 74, 19)        3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_221 (Conv2D)          (None, 74, 74, 19)        3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_110 (MaxPoolin (None, 37, 37, 19)        0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_110 (Bat (None, 37, 37, 19)        76        
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_222 (Conv2D)          (None, 37, 37, 19)        3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_223 (Conv2D)          (None, 37, 37, 19)        3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_111 (MaxPoolin (None, 18, 18, 19)        0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_111 (Bat (None, 18, 18, 19)        76        
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_224 (Conv2D)          (None, 18, 18, 19)        3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_225 (Conv2D)          (None, 18, 18, 19)        3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_112 (MaxPoolin (None, 9, 9, 19)          0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_112 (Bat (None, 9, 9, 19)          76        
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_226 (Conv2D)          (None, 9, 9, 19)          3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_227 (Conv2D)          (None, 9, 9, 19)          3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_113 (MaxPoolin (None, 4, 4, 19)          0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_113 (Bat (None, 4, 4, 19)          76        
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_228 (Conv2D)          (None, 4, 4, 19)          3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   conv2d_229 (Conv2D)          (None, 4, 4, 19)          3268      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_114 (MaxPoolin (None, 2, 2, 19)          0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_114 (Bat (None, 2, 2, 19)          76        
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   flatten_18 (Flatten)         (None, 76)                0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   dense_67 (Dense)             (None, 65)                5005      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   dropout_49 (Dropout)         (None, 65)                0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   dense_68 (Dense)             (None, 65)                4290      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   dropout_50 (Dropout)         (None, 65)                0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   dense_69 (Dense)             (None, 65)                4290      
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   dropout_51 (Dropout)         (None, 65)                0         
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   dense_70 (Dense)             (None, 2)                 132       
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   Total params: 57,265
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   Trainable params: 56,999
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   Non-trainable params: 266
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   None
 60%|██████    | 18/30 [2:23:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]2019-04-13 09:59:10.020772: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 60%|██████    | 18/30 [2:26:31<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 60%|██████    | 18/30 [2:32:03<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 49:52 - loss: 0.5772 - sparse_categorical_accuracy: 0.7734 - f1_score: 0.8722
 60%|██████    | 18/30 [2:32:03<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:32:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 60%|██████    | 18/30 [2:32:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 22:16 - loss: 0.6054 - sparse_categorical_accuracy: 0.7617 - f1_score: 0.8647
 60%|██████    | 18/30 [2:32:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:32:07<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 60%|██████    | 18/30 [2:32:07<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 13:03 - loss: 0.5951 - sparse_categorical_accuracy: 0.7604 - f1_score: 0.8655
 60%|██████    | 18/30 [2:32:07<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:32:08<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 60%|██████    | 18/30 [2:32:08<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 8:25 - loss: 0.5899 - sparse_categorical_accuracy: 0.7617 - f1_score: 0.8653 
 60%|██████    | 18/30 [2:32:08<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:32:10<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 60%|██████    | 18/30 [2:32:10<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 5:38 - loss: 0.5777 - sparse_categorical_accuracy: 0.7617 - f1_score: 0.8657
 60%|██████    | 18/30 [2:32:10<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:32:11<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 60%|██████    | 18/30 [2:32:11<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 3:46 - loss: 0.5668 - sparse_categorical_accuracy: 0.7617 - f1_score: 0.8664
 60%|██████    | 18/30 [2:32:11<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:32:13<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 60%|██████    | 18/30 [2:32:13<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 2:26 - loss: 0.5662 - sparse_categorical_accuracy: 0.7578 - f1_score: 0.8643
 60%|██████    | 18/30 [2:32:13<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:32:14<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 60%|██████    | 18/30 [2:32:14<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1:25 - loss: 0.5607 - sparse_categorical_accuracy: 0.7588 - f1_score: 0.8647
 60%|██████    | 18/30 [2:32:14<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:32:16<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 60%|██████    | 18/30 [2:32:16<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 38s - loss: 0.5581 - sparse_categorical_accuracy: 0.7552 - f1_score: 0.8624 
 60%|██████    | 18/30 [2:32:16<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:35:50<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 60%|██████    | 18/30 [2:35:50<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - 559s 56s/step - loss: 0.5519 - sparse_categorical_accuracy: 0.7559 - f1_score: 0.8629 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 60%|██████    | 18/30 [2:35:50<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   Epoch 2/2
 60%|██████    | 18/30 [2:35:50<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 60%|██████    | 18/30 [2:35:52<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 14s - loss: 0.4838 - sparse_categorical_accuracy: 0.7695 - f1_score: 0.8722
 60%|██████    | 18/30 [2:35:52<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:35:53<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 60%|██████    | 18/30 [2:35:53<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 12s - loss: 0.5150 - sparse_categorical_accuracy: 0.7520 - f1_score: 0.8569
 60%|██████    | 18/30 [2:35:53<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:35:55<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 60%|██████    | 18/30 [2:35:55<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 11s - loss: 0.5202 - sparse_categorical_accuracy: 0.7474 - f1_score: 0.8527
 60%|██████    | 18/30 [2:35:55<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:35:57<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 60%|██████    | 18/30 [2:35:57<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 9s - loss: 0.5089 - sparse_categorical_accuracy: 0.7529 - f1_score: 0.8551 
 60%|██████    | 18/30 [2:35:57<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:35:58<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 60%|██████    | 18/30 [2:35:58<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 7s - loss: 0.5078 - sparse_categorical_accuracy: 0.7547 - f1_score: 0.8545
 60%|██████    | 18/30 [2:35:58<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:36:00<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 60%|██████    | 18/30 [2:36:00<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 6s - loss: 0.5026 - sparse_categorical_accuracy: 0.7559 - f1_score: 0.8541
 60%|██████    | 18/30 [2:36:00<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:36:01<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 60%|██████    | 18/30 [2:36:01<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 4s - loss: 0.5020 - sparse_categorical_accuracy: 0.7550 - f1_score: 0.8515
 60%|██████    | 18/30 [2:36:01<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:36:03<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 60%|██████    | 18/30 [2:36:03<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 3s - loss: 0.4996 - sparse_categorical_accuracy: 0.7524 - f1_score: 0.8496
 60%|██████    | 18/30 [2:36:03<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:36:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 60%|██████    | 18/30 [2:36:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1s - loss: 0.4902 - sparse_categorical_accuracy: 0.7574 - f1_score: 0.8505
 60%|██████    | 18/30 [2:36:05<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   
 60%|██████    | 18/30 [2:36:08<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 60%|██████    | 18/30 [2:36:08<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                    - 17s 2s/step - loss: 0.4906 - sparse_categorical_accuracy: 0.7602 - f1_score: 0.8509 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.7083 - val_f1_score: 0.8406

 60%|██████    | 18/30 [2:36:08<2:27:40, 738.38s/it, best loss: 0.6244885921478271]                                                                                   0.6877539753913879
 60%|██████    | 18/30 [2:38:36<2:27:40, 738.38s/it, best loss: 0.6244885921478271] 63%|██████▎   | 19/30 [2:38:36<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   Layer (type)                 Output Shape              Param #   
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_230 (Conv2D)          (None, 299, 299, 95)      2660      
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_231 (Conv2D)          (None, 299, 299, 95)      81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_115 (MaxPoolin (None, 149, 149, 95)      0         
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_115 (Bat (None, 149, 149, 95)      380       
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_232 (Conv2D)          (None, 149, 149, 95)      81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_233 (Conv2D)          (None, 149, 149, 95)      81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_116 (MaxPoolin (None, 74, 74, 95)        0         
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_116 (Bat (None, 74, 74, 95)        380       
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_234 (Conv2D)          (None, 74, 74, 95)        81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_235 (Conv2D)          (None, 74, 74, 95)        81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_117 (MaxPoolin (None, 37, 37, 95)        0         
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_117 (Bat (None, 37, 37, 95)        380       
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_236 (Conv2D)          (None, 37, 37, 95)        81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_237 (Conv2D)          (None, 37, 37, 95)        81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_118 (MaxPoolin (None, 18, 18, 95)        0         
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_118 (Bat (None, 18, 18, 95)        380       
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_238 (Conv2D)          (None, 18, 18, 95)        81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_239 (Conv2D)          (None, 18, 18, 95)        81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_119 (MaxPoolin (None, 9, 9, 95)          0         
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_119 (Bat (None, 9, 9, 95)          380       
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_240 (Conv2D)          (None, 9, 9, 95)          81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   conv2d_241 (Conv2D)          (None, 9, 9, 95)          81320     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   max_pooling2d_120 (MaxPoolin (None, 4, 4, 95)          0         
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   batch_normalization_120 (Bat (None, 4, 4, 95)          380       
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   flatten_19 (Flatten)         (None, 1520)              0         
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   dense_71 (Dense)             (None, 65)                98865     
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   dropout_52 (Dropout)         (None, 65)                0         
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   dense_72 (Dense)             (None, 2)                 132       
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   =================================================================
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   Total params: 998,457
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   Trainable params: 997,317
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   Non-trainable params: 1,140
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   None
 63%|██████▎   | 19/30 [2:38:39<2:26:08, 797.14s/it, best loss: 0.6244885921478271]2019-04-13 10:14:44.228823: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 63%|██████▎   | 19/30 [2:42:28<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 63%|██████▎   | 19/30 [2:48:21<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 52:57 - loss: 1.4864 - sparse_categorical_accuracy: 0.3789 - f1_score: 0.8520
 63%|██████▎   | 19/30 [2:48:21<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:48:22<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 63%|██████▎   | 19/30 [2:48:22<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 23:38 - loss: 1.2066 - sparse_categorical_accuracy: 0.5645 - f1_score: 0.8468
 63%|██████▎   | 19/30 [2:48:22<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:48:24<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 63%|██████▎   | 19/30 [2:48:24<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 13:50 - loss: 1.1267 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8503
 63%|██████▎   | 19/30 [2:48:24<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:48:26<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 63%|██████▎   | 19/30 [2:48:26<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 8:56 - loss: 1.0120 - sparse_categorical_accuracy: 0.6250 - f1_score: 0.8501 
 63%|██████▎   | 19/30 [2:48:26<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:48:27<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 63%|██████▎   | 19/30 [2:48:27<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 5:59 - loss: 0.9218 - sparse_categorical_accuracy: 0.6492 - f1_score: 0.8530
 63%|██████▎   | 19/30 [2:48:27<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:48:29<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 63%|██████▎   | 19/30 [2:48:29<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 4:00 - loss: 0.8711 - sparse_categorical_accuracy: 0.6647 - f1_score: 0.8537
 63%|██████▎   | 19/30 [2:48:29<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:48:30<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 63%|██████▎   | 19/30 [2:48:30<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 2:35 - loss: 0.8286 - sparse_categorical_accuracy: 0.6775 - f1_score: 0.8556
 63%|██████▎   | 19/30 [2:48:30<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:48:32<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 63%|██████▎   | 19/30 [2:48:32<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1:30 - loss: 0.7928 - sparse_categorical_accuracy: 0.6865 - f1_score: 0.8532
 63%|██████▎   | 19/30 [2:48:32<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:48:33<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 63%|██████▎   | 19/30 [2:48:33<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 40s - loss: 0.7593 - sparse_categorical_accuracy: 0.6949 - f1_score: 0.8537 
 63%|██████▎   | 19/30 [2:48:33<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:25<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 63%|██████▎   | 19/30 [2:52:25<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - 597s 60s/step - loss: 0.7237 - sparse_categorical_accuracy: 0.7082 - f1_score: 0.8550 - val_loss: 3.1697 - val_sparse_categorical_accuracy: 0.3500 - val_f1_score: 0.8406

 63%|██████▎   | 19/30 [2:52:25<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   Epoch 2/2
 63%|██████▎   | 19/30 [2:52:25<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    1/10 [==>...........................]
 63%|██████▎   | 19/30 [2:52:26<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 13s - loss: 0.4264 - sparse_categorical_accuracy: 0.7930 - f1_score: 0.8442
 63%|██████▎   | 19/30 [2:52:26<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:28<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    2/10 [=====>........................]
 63%|██████▎   | 19/30 [2:52:28<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 12s - loss: 0.4509 - sparse_categorical_accuracy: 0.8047 - f1_score: 0.8481
 63%|██████▎   | 19/30 [2:52:28<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:29<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    3/10 [========>.....................]
 63%|██████▎   | 19/30 [2:52:29<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 10s - loss: 0.4476 - sparse_categorical_accuracy: 0.8021 - f1_score: 0.8442
 63%|██████▎   | 19/30 [2:52:29<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:31<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    4/10 [===========>..................]
 63%|██████▎   | 19/30 [2:52:31<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 9s - loss: 0.4215 - sparse_categorical_accuracy: 0.8125 - f1_score: 0.8525 
 63%|██████▎   | 19/30 [2:52:31<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:32<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    5/10 [==============>...............]
 63%|██████▎   | 19/30 [2:52:32<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 7s - loss: 0.4134 - sparse_categorical_accuracy: 0.8180 - f1_score: 0.8534
 63%|██████▎   | 19/30 [2:52:32<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:34<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    6/10 [=================>............]
 63%|██████▎   | 19/30 [2:52:34<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 6s - loss: 0.3921 - sparse_categorical_accuracy: 0.8301 - f1_score: 0.8540
 63%|██████▎   | 19/30 [2:52:34<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:35<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    7/10 [====================>.........]
 63%|██████▎   | 19/30 [2:52:35<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 4s - loss: 0.3957 - sparse_categorical_accuracy: 0.8315 - f1_score: 0.8559
 63%|██████▎   | 19/30 [2:52:35<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:37<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    8/10 [=======================>......]
 63%|██████▎   | 19/30 [2:52:37<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 3s - loss: 0.3816 - sparse_categorical_accuracy: 0.8369 - f1_score: 0.8576
 63%|██████▎   | 19/30 [2:52:37<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:38<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    9/10 [==========================>...]
 63%|██████▎   | 19/30 [2:52:38<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - ETA: 1s - loss: 0.3695 - sparse_categorical_accuracy: 0.8403 - f1_score: 0.8564
 63%|██████▎   | 19/30 [2:52:38<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   
 63%|██████▎   | 19/30 [2:52:41<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   10/10 [==============================]
 63%|██████▎   | 19/30 [2:52:41<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                    - 17s 2s/step - loss: 0.3762 - sparse_categorical_accuracy: 0.8355 - f1_score: 0.8552 - val_loss: 7.4659 - val_sparse_categorical_accuracy: 0.3458 - val_f1_score: 0.8406

 63%|██████▎   | 19/30 [2:52:41<2:26:08, 797.14s/it, best loss: 0.6244885921478271]                                                                                   7.465947151184082
 63%|██████▎   | 19/30 [2:55:21<2:26:08, 797.14s/it, best loss: 0.6244885921478271] 67%|██████▋   | 20/30 [2:55:21<2:23:15, 859.51s/it, best loss: 0.6244885921478271]
Traceback (most recent call last):
  File "hyperparameter-tuning.py", line 78, in <module>
    max_evals = MAX_EVALS, trials = bayes_trials)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/fmin.py", line 388, in fmin
    show_progressbar=show_progressbar,
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/base.py", line 639, in fmin
    show_progressbar=show_progressbar)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/fmin.py", line 407, in fmin
    rval.exhaust()
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/fmin.py", line 262, in exhaust
    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/fmin.py", line 211, in run
    self.rstate.randint(2 ** 31 - 1))
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/tpe.py", line 900, in suggest
    print_node_on_error=False)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/pyll/base.py", line 913, in rec_eval
    rval = scope._impls[node.name](*args, **kwargs)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/tpe.py", line 465, in adaptive_parzen_normal
    assert prior_sigma > 0
AssertionError
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7f10f553bf98>>
Traceback (most recent call last):
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
  0%|          | 0/30 [00:00<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    Layer (type)                 Output Shape              Param #   
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    =================================================================
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d (Conv2D)              (None, 299, 299, 28)      784       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_1 (Conv2D)            (None, 299, 299, 28)      7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    max_pooling2d (MaxPooling2D) (None, 149, 149, 28)      0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    batch_normalization (BatchNo (None, 149, 149, 28)      112       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_2 (Conv2D)            (None, 149, 149, 28)      7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_3 (Conv2D)            (None, 149, 149, 28)      7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    max_pooling2d_1 (MaxPooling2 (None, 74, 74, 28)        0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    batch_normalization_1 (Batch (None, 74, 74, 28)        112       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_4 (Conv2D)            (None, 74, 74, 28)        7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_5 (Conv2D)            (None, 74, 74, 28)        7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    max_pooling2d_2 (MaxPooling2 (None, 37, 37, 28)        0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    batch_normalization_2 (Batch (None, 37, 37, 28)        112       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_6 (Conv2D)            (None, 37, 37, 28)        7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_7 (Conv2D)            (None, 37, 37, 28)        7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    max_pooling2d_3 (MaxPooling2 (None, 18, 18, 28)        0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    batch_normalization_3 (Batch (None, 18, 18, 28)        112       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_8 (Conv2D)            (None, 18, 18, 28)        7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_9 (Conv2D)            (None, 18, 18, 28)        7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    max_pooling2d_4 (MaxPooling2 (None, 9, 9, 28)          0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    batch_normalization_4 (Batch (None, 9, 9, 28)          112       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_10 (Conv2D)           (None, 9, 9, 28)          7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_11 (Conv2D)           (None, 9, 9, 28)          7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    max_pooling2d_5 (MaxPooling2 (None, 4, 4, 28)          0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    batch_normalization_5 (Batch (None, 4, 4, 28)          112       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_12 (Conv2D)           (None, 4, 4, 28)          7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_13 (Conv2D)           (None, 4, 4, 28)          7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    max_pooling2d_6 (MaxPooling2 (None, 2, 2, 28)          0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    batch_normalization_6 (Batch (None, 2, 2, 28)          112       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_14 (Conv2D)           (None, 2, 2, 28)          7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    conv2d_15 (Conv2D)           (None, 2, 2, 28)          7084      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    max_pooling2d_7 (MaxPooling2 (None, 1, 1, 28)          0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    batch_normalization_7 (Batch (None, 1, 1, 28)          112       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    flatten (Flatten)            (None, 28)                0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    dense (Dense)                (None, 56)                1624      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    dropout (Dropout)            (None, 56)                0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    dense_1 (Dense)              (None, 56)                3192      
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    dropout_1 (Dropout)          (None, 56)                0         
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    dense_2 (Dense)              (None, 2)                 114       
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    =================================================================
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    Total params: 112,870
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    Trainable params: 112,422
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    Non-trainable params: 448
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    _________________________________________________________________
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]                                                    None
  0%|          | 0/30 [00:05<?, ?it/s, best loss: ?]2019-04-13 12:08:48.238787: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.
  FutureWarning)

WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                    Epoch 1/2
  0%|          | 0/30 [00:19<?, ?it/s, best loss: ?]                                                     1/10 [==>...........................]
  0%|          | 0/30 [01:24<?, ?it/s, best loss: ?]                                                     - ETA: 9:47 - loss: 1.5366 - sparse_categorical_accuracy: 0.3867 - f1_score: 0.8698
  0%|          | 0/30 [01:24<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [01:26<?, ?it/s, best loss: ?]                                                     2/10 [=====>........................]
  0%|          | 0/30 [01:26<?, ?it/s, best loss: ?]                                                     - ETA: 4:28 - loss: 1.4438 - sparse_categorical_accuracy: 0.4141 - f1_score: 0.8583
  0%|          | 0/30 [01:26<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [01:28<?, ?it/s, best loss: ?]                                                     3/10 [========>.....................]
  0%|          | 0/30 [01:28<?, ?it/s, best loss: ?]                                                     - ETA: 2:40 - loss: 1.3837 - sparse_categorical_accuracy: 0.4115 - f1_score: 0.8562
  0%|          | 0/30 [01:28<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [01:30<?, ?it/s, best loss: ?]                                                     4/10 [===========>..................]
  0%|          | 0/30 [01:30<?, ?it/s, best loss: ?]                                                     - ETA: 1:45 - loss: 1.3364 - sparse_categorical_accuracy: 0.4268 - f1_score: 0.8558
  0%|          | 0/30 [01:30<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [01:31<?, ?it/s, best loss: ?]                                                     5/10 [==============>...............]
  0%|          | 0/30 [01:31<?, ?it/s, best loss: ?]                                                     - ETA: 1:12 - loss: 1.2640 - sparse_categorical_accuracy: 0.4477 - f1_score: 0.8540
  0%|          | 0/30 [01:31<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [01:33<?, ?it/s, best loss: ?]                                                     6/10 [=================>............]
  0%|          | 0/30 [01:33<?, ?it/s, best loss: ?]                                                     - ETA: 49s - loss: 1.2363 - sparse_categorical_accuracy: 0.4473 - f1_score: 0.8550 
  0%|          | 0/30 [01:33<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [01:35<?, ?it/s, best loss: ?]                                                     7/10 [====================>.........]
  0%|          | 0/30 [01:35<?, ?it/s, best loss: ?]                                                     - ETA: 32s - loss: 1.2008 - sparse_categorical_accuracy: 0.4576 - f1_score: 0.8534
  0%|          | 0/30 [01:35<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [01:37<?, ?it/s, best loss: ?]                                                     8/10 [=======================>......]
  0%|          | 0/30 [01:37<?, ?it/s, best loss: ?]                                                     - ETA: 19s - loss: 1.1742 - sparse_categorical_accuracy: 0.4648 - f1_score: 0.8542
  0%|          | 0/30 [01:37<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [01:38<?, ?it/s, best loss: ?]                                                     9/10 [==========================>...]
  0%|          | 0/30 [01:38<?, ?it/s, best loss: ?]                                                     - ETA: 8s - loss: 1.1501 - sparse_categorical_accuracy: 0.4735 - f1_score: 0.8525 
  0%|          | 0/30 [01:38<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:41<?, ?it/s, best loss: ?]                                                    10/10 [==============================]
  0%|          | 0/30 [02:41<?, ?it/s, best loss: ?]                                                     - 142s 14s/step - loss: 1.1231 - sparse_categorical_accuracy: 0.4789 - f1_score: 0.8537 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

  0%|          | 0/30 [02:41<?, ?it/s, best loss: ?]                                                    Epoch 2/2
  0%|          | 0/30 [02:41<?, ?it/s, best loss: ?]                                                     1/10 [==>...........................]
  0%|          | 0/30 [02:42<?, ?it/s, best loss: ?]                                                     - ETA: 15s - loss: 0.7989 - sparse_categorical_accuracy: 0.5156 - f1_score: 0.8520
  0%|          | 0/30 [02:42<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:44<?, ?it/s, best loss: ?]                                                     2/10 [=====>........................]
  0%|          | 0/30 [02:44<?, ?it/s, best loss: ?]                                                     - ETA: 13s - loss: 0.7910 - sparse_categorical_accuracy: 0.5449 - f1_score: 0.8546
  0%|          | 0/30 [02:44<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:46<?, ?it/s, best loss: ?]                                                     3/10 [========>.....................]
  0%|          | 0/30 [02:46<?, ?it/s, best loss: ?]                                                     - ETA: 11s - loss: 0.7806 - sparse_categorical_accuracy: 0.5560 - f1_score: 0.8588
  0%|          | 0/30 [02:46<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:48<?, ?it/s, best loss: ?]                                                     4/10 [===========>..................]
  0%|          | 0/30 [02:48<?, ?it/s, best loss: ?]                                                     - ETA: 10s - loss: 0.7665 - sparse_categorical_accuracy: 0.5654 - f1_score: 0.8584
  0%|          | 0/30 [02:48<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:49<?, ?it/s, best loss: ?]                                                     5/10 [==============>...............]
  0%|          | 0/30 [02:49<?, ?it/s, best loss: ?]                                                     - ETA: 8s - loss: 0.7706 - sparse_categorical_accuracy: 0.5734 - f1_score: 0.8566 
  0%|          | 0/30 [02:49<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:51<?, ?it/s, best loss: ?]                                                     6/10 [=================>............]
  0%|          | 0/30 [02:51<?, ?it/s, best loss: ?]                                                     - ETA: 6s - loss: 0.7603 - sparse_categorical_accuracy: 0.5807 - f1_score: 0.8554
  0%|          | 0/30 [02:51<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:53<?, ?it/s, best loss: ?]                                                     7/10 [====================>.........]
  0%|          | 0/30 [02:53<?, ?it/s, best loss: ?]                                                     - ETA: 5s - loss: 0.7555 - sparse_categorical_accuracy: 0.5898 - f1_score: 0.8560
  0%|          | 0/30 [02:53<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:54<?, ?it/s, best loss: ?]                                                     8/10 [=======================>......]
  0%|          | 0/30 [02:54<?, ?it/s, best loss: ?]                                                     - ETA: 3s - loss: 0.7456 - sparse_categorical_accuracy: 0.5986 - f1_score: 0.8571
  0%|          | 0/30 [02:54<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:56<?, ?it/s, best loss: ?]                                                     9/10 [==========================>...]
  0%|          | 0/30 [02:56<?, ?it/s, best loss: ?]                                                     - ETA: 1s - loss: 0.7443 - sparse_categorical_accuracy: 0.6003 - f1_score: 0.8582
  0%|          | 0/30 [02:56<?, ?it/s, best loss: ?]                                                    
  0%|          | 0/30 [02:59<?, ?it/s, best loss: ?]                                                    10/10 [==============================]
  0%|          | 0/30 [02:59<?, ?it/s, best loss: ?]                                                     - 19s 2s/step - loss: 0.7434 - sparse_categorical_accuracy: 0.6023 - f1_score: 0.8568 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

  0%|          | 0/30 [02:59<?, ?it/s, best loss: ?]                                                    0.6578827500343323
  0%|          | 0/30 [03:02<?, ?it/s, best loss: ?]  3%|▎         | 1/30 [03:02<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                Layer (type)                 Output Shape              Param #   
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                =================================================================
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_16 (Conv2D)           (None, 299, 299, 91)      2548      
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_17 (Conv2D)           (None, 299, 299, 91)      74620     
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_8 (MaxPooling2 (None, 149, 149, 91)      0         
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_8 (Batch (None, 149, 149, 91)      364       
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_18 (Conv2D)           (None, 149, 149, 91)      74620     
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_19 (Conv2D)           (None, 149, 149, 91)      74620     
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_9 (MaxPooling2 (None, 74, 74, 91)        0         
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_9 (Batch (None, 74, 74, 91)        364       
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_20 (Conv2D)           (None, 74, 74, 91)        74620     
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_21 (Conv2D)           (None, 74, 74, 91)        74620     
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_10 (MaxPooling (None, 37, 37, 91)        0         
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_10 (Batc (None, 37, 37, 91)        364       
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_22 (Conv2D)           (None, 37, 37, 91)        74620     
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_23 (Conv2D)           (None, 37, 37, 91)        74620     
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_11 (MaxPooling (None, 18, 18, 91)        0         
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_11 (Batc (None, 18, 18, 91)        364       
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_24 (Conv2D)           (None, 18, 18, 91)        74620     
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                conv2d_25 (Conv2D)           (None, 18, 18, 91)        74620     
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_12 (MaxPooling (None, 9, 9, 91)          0         
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_12 (Batc (None, 9, 9, 91)          364       
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                flatten_1 (Flatten)          (None, 7371)              0         
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                dense_3 (Dense)              (None, 37)                272764    
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                dropout_2 (Dropout)          (None, 37)                0         
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                dense_4 (Dense)              (None, 37)                1406      
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                dropout_3 (Dropout)          (None, 37)                0         
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                dense_5 (Dense)              (None, 37)                1406      
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                dropout_4 (Dropout)          (None, 37)                0         
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                dense_6 (Dense)              (None, 2)                 76        
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                =================================================================
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                Total params: 951,600
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                Trainable params: 950,690
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                Non-trainable params: 910
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                None
  3%|▎         | 1/30 [03:07<1:28:18, 182.72s/it, best loss: 0.6578827500343323]2019-04-13 12:11:45.129587: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
  3%|▎         | 1/30 [03:20<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
  3%|▎         | 1/30 [05:15<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 17:12 - loss: 0.8836 - sparse_categorical_accuracy: 0.5117 - f1_score: 0.8442
  3%|▎         | 1/30 [05:15<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [05:17<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
  3%|▎         | 1/30 [05:17<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 7:45 - loss: 0.7921 - sparse_categorical_accuracy: 0.5820 - f1_score: 0.8558 
  3%|▎         | 1/30 [05:17<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [05:18<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
  3%|▎         | 1/30 [05:18<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 4:35 - loss: 0.7344 - sparse_categorical_accuracy: 0.6185 - f1_score: 0.8536
  3%|▎         | 1/30 [05:18<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [05:20<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
  3%|▎         | 1/30 [05:20<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:59 - loss: 0.7193 - sparse_categorical_accuracy: 0.6289 - f1_score: 0.8539
  3%|▎         | 1/30 [05:20<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [05:22<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
  3%|▎         | 1/30 [05:22<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:01 - loss: 0.6982 - sparse_categorical_accuracy: 0.6484 - f1_score: 0.8545
  3%|▎         | 1/30 [05:22<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [05:23<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
  3%|▎         | 1/30 [05:23<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:22 - loss: 0.6813 - sparse_categorical_accuracy: 0.6602 - f1_score: 0.8562
  3%|▎         | 1/30 [05:23<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [05:25<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
  3%|▎         | 1/30 [05:25<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 53s - loss: 0.6726 - sparse_categorical_accuracy: 0.6641 - f1_score: 0.8553 
  3%|▎         | 1/30 [05:25<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [05:27<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
  3%|▎         | 1/30 [05:27<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 31s - loss: 0.6556 - sparse_categorical_accuracy: 0.6724 - f1_score: 0.8568
  3%|▎         | 1/30 [05:27<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [05:29<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
  3%|▎         | 1/30 [05:29<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 14s - loss: 0.6491 - sparse_categorical_accuracy: 0.6749 - f1_score: 0.8559
  3%|▎         | 1/30 [05:29<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:36<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
  3%|▎         | 1/30 [06:36<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - 196s 20s/step - loss: 0.6386 - sparse_categorical_accuracy: 0.6789 - f1_score: 0.8540 - val_loss: 2.5839 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

  3%|▎         | 1/30 [06:36<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                Epoch 2/2
  3%|▎         | 1/30 [06:36<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
  3%|▎         | 1/30 [06:38<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 15s - loss: 0.5611 - sparse_categorical_accuracy: 0.6992 - f1_score: 0.8673
  3%|▎         | 1/30 [06:38<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:39<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
  3%|▎         | 1/30 [06:39<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 13s - loss: 0.5683 - sparse_categorical_accuracy: 0.7070 - f1_score: 0.8609
  3%|▎         | 1/30 [06:39<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:41<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
  3%|▎         | 1/30 [06:41<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 11s - loss: 0.5581 - sparse_categorical_accuracy: 0.7135 - f1_score: 0.8580
  3%|▎         | 1/30 [06:41<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:43<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
  3%|▎         | 1/30 [06:43<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 10s - loss: 0.5603 - sparse_categorical_accuracy: 0.7168 - f1_score: 0.8597
  3%|▎         | 1/30 [06:43<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:45<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
  3%|▎         | 1/30 [06:45<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8s - loss: 0.5516 - sparse_categorical_accuracy: 0.7211 - f1_score: 0.8586 
  3%|▎         | 1/30 [06:45<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:46<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
  3%|▎         | 1/30 [06:46<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6s - loss: 0.5427 - sparse_categorical_accuracy: 0.7233 - f1_score: 0.8575
  3%|▎         | 1/30 [06:46<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:48<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
  3%|▎         | 1/30 [06:48<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5s - loss: 0.5290 - sparse_categorical_accuracy: 0.7271 - f1_score: 0.8586
  3%|▎         | 1/30 [06:48<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:50<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
  3%|▎         | 1/30 [06:50<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3s - loss: 0.5225 - sparse_categorical_accuracy: 0.7319 - f1_score: 0.8584
  3%|▎         | 1/30 [06:50<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:51<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
  3%|▎         | 1/30 [06:51<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1s - loss: 0.5097 - sparse_categorical_accuracy: 0.7365 - f1_score: 0.8597
  3%|▎         | 1/30 [06:51<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                
  3%|▎         | 1/30 [06:55<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
  3%|▎         | 1/30 [06:55<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                 - 19s 2s/step - loss: 0.5089 - sparse_categorical_accuracy: 0.7395 - f1_score: 0.8589 - val_loss: 2.8997 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

  3%|▎         | 1/30 [06:55<1:28:18, 182.72s/it, best loss: 0.6578827500343323]                                                                                2.899678945541382
  3%|▎         | 1/30 [07:00<1:28:18, 182.72s/it, best loss: 0.6578827500343323]  7%|▋         | 2/30 [07:00<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                Layer (type)                 Output Shape              Param #   
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                =================================================================
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_26 (Conv2D)           (None, 299, 299, 11)      308       
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_27 (Conv2D)           (None, 299, 299, 11)      1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_13 (MaxPooling (None, 149, 149, 11)      0         
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_13 (Batc (None, 149, 149, 11)      44        
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_28 (Conv2D)           (None, 149, 149, 11)      1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_29 (Conv2D)           (None, 149, 149, 11)      1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_14 (MaxPooling (None, 74, 74, 11)        0         
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_14 (Batc (None, 74, 74, 11)        44        
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_30 (Conv2D)           (None, 74, 74, 11)        1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_31 (Conv2D)           (None, 74, 74, 11)        1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_15 (MaxPooling (None, 37, 37, 11)        0         
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_15 (Batc (None, 37, 37, 11)        44        
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_32 (Conv2D)           (None, 37, 37, 11)        1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_33 (Conv2D)           (None, 37, 37, 11)        1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_16 (MaxPooling (None, 18, 18, 11)        0         
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_16 (Batc (None, 18, 18, 11)        44        
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_34 (Conv2D)           (None, 18, 18, 11)        1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_35 (Conv2D)           (None, 18, 18, 11)        1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_17 (MaxPooling (None, 9, 9, 11)          0         
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_17 (Batc (None, 9, 9, 11)          44        
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_36 (Conv2D)           (None, 9, 9, 11)          1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_37 (Conv2D)           (None, 9, 9, 11)          1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_18 (MaxPooling (None, 4, 4, 11)          0         
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_18 (Batc (None, 4, 4, 11)          44        
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_38 (Conv2D)           (None, 4, 4, 11)          1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                conv2d_39 (Conv2D)           (None, 4, 4, 11)          1100      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_19 (MaxPooling (None, 2, 2, 11)          0         
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_19 (Batc (None, 2, 2, 11)          44        
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                flatten_2 (Flatten)          (None, 44)                0         
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                dense_7 (Dense)              (None, 98)                4410      
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                dropout_5 (Dropout)          (None, 98)                0         
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                dense_8 (Dense)              (None, 2)                 198       
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                =================================================================
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                Total params: 19,524
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                Trainable params: 19,370
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                Non-trainable params: 154
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                None
  7%|▋         | 2/30 [07:06<1:32:56, 199.16s/it, best loss: 0.6578827500343323]2019-04-13 12:15:44.502790: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
  7%|▋         | 2/30 [07:23<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
  7%|▋         | 2/30 [09:20<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 17:32 - loss: 1.2816 - sparse_categorical_accuracy: 0.3164 - f1_score: 0.8442
  7%|▋         | 2/30 [09:20<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [09:21<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
  7%|▋         | 2/30 [09:21<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 7:54 - loss: 1.2170 - sparse_categorical_accuracy: 0.3359 - f1_score: 0.8429 
  7%|▋         | 2/30 [09:21<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [09:23<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
  7%|▋         | 2/30 [09:23<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 4:40 - loss: 1.1274 - sparse_categorical_accuracy: 0.3763 - f1_score: 0.8477
  7%|▋         | 2/30 [09:23<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [09:25<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
  7%|▋         | 2/30 [09:25<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3:02 - loss: 1.0501 - sparse_categorical_accuracy: 0.3945 - f1_score: 0.8462
  7%|▋         | 2/30 [09:25<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [09:26<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
  7%|▋         | 2/30 [09:26<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:03 - loss: 0.9892 - sparse_categorical_accuracy: 0.4180 - f1_score: 0.8509
  7%|▋         | 2/30 [09:26<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [09:28<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
  7%|▋         | 2/30 [09:28<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:23 - loss: 0.9353 - sparse_categorical_accuracy: 0.4486 - f1_score: 0.8502
  7%|▋         | 2/30 [09:28<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [09:30<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
  7%|▋         | 2/30 [09:30<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 54s - loss: 0.8994 - sparse_categorical_accuracy: 0.4676 - f1_score: 0.8501 
  7%|▋         | 2/30 [09:30<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [09:31<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
  7%|▋         | 2/30 [09:31<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 32s - loss: 0.8701 - sparse_categorical_accuracy: 0.4907 - f1_score: 0.8507
  7%|▋         | 2/30 [09:31<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [09:33<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
  7%|▋         | 2/30 [09:33<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 14s - loss: 0.8398 - sparse_categorical_accuracy: 0.5148 - f1_score: 0.8514
  7%|▋         | 2/30 [09:33<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:39<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
  7%|▋         | 2/30 [10:39<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - 196s 20s/step - loss: 0.8221 - sparse_categorical_accuracy: 0.5367 - f1_score: 0.8520 - val_loss: 0.6727 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

  7%|▋         | 2/30 [10:39<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                Epoch 2/2
  7%|▋         | 2/30 [10:39<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
  7%|▋         | 2/30 [10:41<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 14s - loss: 0.5536 - sparse_categorical_accuracy: 0.7344 - f1_score: 0.8698
  7%|▋         | 2/30 [10:41<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:43<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
  7%|▋         | 2/30 [10:43<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 13s - loss: 0.5820 - sparse_categorical_accuracy: 0.7246 - f1_score: 0.8583
  7%|▋         | 2/30 [10:43<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:44<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
  7%|▋         | 2/30 [10:44<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 11s - loss: 0.5847 - sparse_categorical_accuracy: 0.7266 - f1_score: 0.8604
  7%|▋         | 2/30 [10:44<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:46<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
  7%|▋         | 2/30 [10:46<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 10s - loss: 0.5650 - sparse_categorical_accuracy: 0.7412 - f1_score: 0.8646
  7%|▋         | 2/30 [10:46<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:48<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
  7%|▋         | 2/30 [10:48<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8s - loss: 0.5544 - sparse_categorical_accuracy: 0.7461 - f1_score: 0.8657 
  7%|▋         | 2/30 [10:48<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:49<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
  7%|▋         | 2/30 [10:49<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6s - loss: 0.5661 - sparse_categorical_accuracy: 0.7409 - f1_score: 0.8617
  7%|▋         | 2/30 [10:49<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:51<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
  7%|▋         | 2/30 [10:51<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5s - loss: 0.5713 - sparse_categorical_accuracy: 0.7383 - f1_score: 0.8599
  7%|▋         | 2/30 [10:51<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:53<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
  7%|▋         | 2/30 [10:53<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3s - loss: 0.5739 - sparse_categorical_accuracy: 0.7373 - f1_score: 0.8580
  7%|▋         | 2/30 [10:53<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:54<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
  7%|▋         | 2/30 [10:54<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1s - loss: 0.5709 - sparse_categorical_accuracy: 0.7396 - f1_score: 0.8573
  7%|▋         | 2/30 [10:54<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                
  7%|▋         | 2/30 [10:57<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
  7%|▋         | 2/30 [10:57<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                 - 18s 2s/step - loss: 0.5754 - sparse_categorical_accuracy: 0.7402 - f1_score: 0.8573 - val_loss: 0.6603 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

  7%|▋         | 2/30 [10:57<1:32:56, 199.16s/it, best loss: 0.6578827500343323]                                                                                0.660286009311676
  7%|▋         | 2/30 [11:07<1:32:56, 199.16s/it, best loss: 0.6578827500343323] 10%|█         | 3/30 [11:07<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                Layer (type)                 Output Shape              Param #   
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_40 (Conv2D)           (None, 299, 299, 26)      728       
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_41 (Conv2D)           (None, 299, 299, 26)      6110      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_20 (MaxPooling (None, 149, 149, 26)      0         
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_20 (Batc (None, 149, 149, 26)      104       
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_42 (Conv2D)           (None, 149, 149, 26)      6110      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_43 (Conv2D)           (None, 149, 149, 26)      6110      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_21 (MaxPooling (None, 74, 74, 26)        0         
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_21 (Batc (None, 74, 74, 26)        104       
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_44 (Conv2D)           (None, 74, 74, 26)        6110      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_45 (Conv2D)           (None, 74, 74, 26)        6110      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_22 (MaxPooling (None, 37, 37, 26)        0         
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_22 (Batc (None, 37, 37, 26)        104       
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_46 (Conv2D)           (None, 37, 37, 26)        6110      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_47 (Conv2D)           (None, 37, 37, 26)        6110      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_23 (MaxPooling (None, 18, 18, 26)        0         
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_23 (Batc (None, 18, 18, 26)        104       
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_48 (Conv2D)           (None, 18, 18, 26)        6110      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                conv2d_49 (Conv2D)           (None, 18, 18, 26)        6110      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_24 (MaxPooling (None, 9, 9, 26)          0         
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_24 (Batc (None, 9, 9, 26)          104       
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                flatten_3 (Flatten)          (None, 2106)              0         
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                dense_9 (Dense)              (None, 88)                185416    
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                dropout_6 (Dropout)          (None, 88)                0         
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                dense_10 (Dense)             (None, 88)                7832      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                dropout_7 (Dropout)          (None, 88)                0         
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                dense_11 (Dense)             (None, 88)                7832      
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                dropout_8 (Dropout)          (None, 88)                0         
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                dense_12 (Dense)             (None, 2)                 178       
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                Total params: 257,496
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                Trainable params: 257,236
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                Non-trainable params: 260
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                None
 10%|█         | 3/30 [11:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]2019-04-13 12:19:48.978682: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 10%|█         | 3/30 [11:32<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 10%|█         | 3/30 [13:37<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 18:39 - loss: 1.1366 - sparse_categorical_accuracy: 0.3477 - f1_score: 0.8747
 10%|█         | 3/30 [13:37<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [13:38<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 10%|█         | 3/30 [13:38<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8:24 - loss: 0.9077 - sparse_categorical_accuracy: 0.4961 - f1_score: 0.8710 
 10%|█         | 3/30 [13:38<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [13:40<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 10%|█         | 3/30 [13:40<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 4:58 - loss: 0.7917 - sparse_categorical_accuracy: 0.5755 - f1_score: 0.8697
 10%|█         | 3/30 [13:40<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [13:42<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 10%|█         | 3/30 [13:42<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3:14 - loss: 0.7728 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8607
 10%|█         | 3/30 [13:42<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [13:43<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 10%|█         | 3/30 [13:43<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:11 - loss: 0.7435 - sparse_categorical_accuracy: 0.6328 - f1_score: 0.8590
 10%|█         | 3/30 [13:43<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [13:45<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 10%|█         | 3/30 [13:45<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:28 - loss: 0.7218 - sparse_categorical_accuracy: 0.6523 - f1_score: 0.8578
 10%|█         | 3/30 [13:45<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [13:47<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 10%|█         | 3/30 [13:47<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 57s - loss: 0.7056 - sparse_categorical_accuracy: 0.6641 - f1_score: 0.8548 
 10%|█         | 3/30 [13:47<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [13:48<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 10%|█         | 3/30 [13:48<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 34s - loss: 0.6870 - sparse_categorical_accuracy: 0.6763 - f1_score: 0.8554
 10%|█         | 3/30 [13:48<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [13:50<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 10%|█         | 3/30 [13:50<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 15s - loss: 0.6838 - sparse_categorical_accuracy: 0.6819 - f1_score: 0.8556
 10%|█         | 3/30 [13:50<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:06<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 10%|█         | 3/30 [15:06<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - 214s 21s/step - loss: 0.6785 - sparse_categorical_accuracy: 0.6891 - f1_score: 0.8565 - val_loss: 0.6270 - val_sparse_categorical_accuracy: 0.7292 - val_f1_score: 0.8406

 10%|█         | 3/30 [15:06<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                Epoch 2/2
 10%|█         | 3/30 [15:06<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 10%|█         | 3/30 [15:08<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 15s - loss: 0.5786 - sparse_categorical_accuracy: 0.7461 - f1_score: 0.8546
 10%|█         | 3/30 [15:08<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 10%|█         | 3/30 [15:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 13s - loss: 0.5398 - sparse_categorical_accuracy: 0.7422 - f1_score: 0.8533
 10%|█         | 3/30 [15:10<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:11<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 10%|█         | 3/30 [15:11<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 12s - loss: 0.5460 - sparse_categorical_accuracy: 0.7305 - f1_score: 0.8529
 10%|█         | 3/30 [15:11<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:13<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 10%|█         | 3/30 [15:13<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 10s - loss: 0.5279 - sparse_categorical_accuracy: 0.7412 - f1_score: 0.8507
 10%|█         | 3/30 [15:13<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:15<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 10%|█         | 3/30 [15:15<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8s - loss: 0.5214 - sparse_categorical_accuracy: 0.7406 - f1_score: 0.8515 
 10%|█         | 3/30 [15:15<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:17<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 10%|█         | 3/30 [15:17<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6s - loss: 0.5193 - sparse_categorical_accuracy: 0.7448 - f1_score: 0.8537
 10%|█         | 3/30 [15:17<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:18<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 10%|█         | 3/30 [15:18<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5s - loss: 0.5223 - sparse_categorical_accuracy: 0.7439 - f1_score: 0.8542
 10%|█         | 3/30 [15:18<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:20<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 10%|█         | 3/30 [15:20<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3s - loss: 0.5146 - sparse_categorical_accuracy: 0.7446 - f1_score: 0.8539
 10%|█         | 3/30 [15:20<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:21<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 10%|█         | 3/30 [15:21<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1s - loss: 0.5096 - sparse_categorical_accuracy: 0.7470 - f1_score: 0.8531
 10%|█         | 3/30 [15:21<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                
 10%|█         | 3/30 [15:25<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 10%|█         | 3/30 [15:25<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                 - 18s 2s/step - loss: 0.5050 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8512 - val_loss: 0.6692 - val_sparse_categorical_accuracy: 0.6750 - val_f1_score: 0.8406

 10%|█         | 3/30 [15:25<1:36:03, 213.48s/it, best loss: 0.6578827500343323]                                                                                0.6691614985466003
 10%|█         | 3/30 [15:36<1:36:03, 213.48s/it, best loss: 0.6578827500343323] 13%|█▎        | 4/30 [15:36<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                Layer (type)                 Output Shape              Param #   
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_50 (Conv2D)           (None, 299, 299, 19)      532       
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_51 (Conv2D)           (None, 299, 299, 19)      3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_25 (MaxPooling (None, 149, 149, 19)      0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_25 (Batc (None, 149, 149, 19)      76        
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_52 (Conv2D)           (None, 149, 149, 19)      3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_53 (Conv2D)           (None, 149, 149, 19)      3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_26 (MaxPooling (None, 74, 74, 19)        0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_26 (Batc (None, 74, 74, 19)        76        
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_54 (Conv2D)           (None, 74, 74, 19)        3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_55 (Conv2D)           (None, 74, 74, 19)        3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_27 (MaxPooling (None, 37, 37, 19)        0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_27 (Batc (None, 37, 37, 19)        76        
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_56 (Conv2D)           (None, 37, 37, 19)        3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_57 (Conv2D)           (None, 37, 37, 19)        3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_28 (MaxPooling (None, 18, 18, 19)        0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_28 (Batc (None, 18, 18, 19)        76        
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_58 (Conv2D)           (None, 18, 18, 19)        3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_59 (Conv2D)           (None, 18, 18, 19)        3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_29 (MaxPooling (None, 9, 9, 19)          0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_29 (Batc (None, 9, 9, 19)          76        
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_60 (Conv2D)           (None, 9, 9, 19)          3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                conv2d_61 (Conv2D)           (None, 9, 9, 19)          3268      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_30 (MaxPooling (None, 4, 4, 19)          0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_30 (Batc (None, 4, 4, 19)          76        
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                flatten_4 (Flatten)          (None, 304)               0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dense_13 (Dense)             (None, 10)                3050      
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dropout_9 (Dropout)          (None, 10)                0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dense_14 (Dense)             (None, 10)                110       
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dropout_10 (Dropout)         (None, 10)                0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dense_15 (Dense)             (None, 10)                110       
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dropout_11 (Dropout)         (None, 10)                0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dense_16 (Dense)             (None, 10)                110       
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dropout_12 (Dropout)         (None, 10)                0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dense_17 (Dense)             (None, 10)                110       
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dropout_13 (Dropout)         (None, 10)                0         
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                dense_18 (Dense)             (None, 2)                 22        
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                Total params: 40,448
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                Trainable params: 40,220
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                Non-trainable params: 228
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                None
 13%|█▎        | 4/30 [15:41<1:39:46, 230.25s/it, best loss: 0.6578827500343323]2019-04-13 12:24:19.249876: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 13%|█▎        | 4/30 [16:08<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 13%|█▎        | 4/30 [18:20<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 19:45 - loss: 1.0333 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.2698
 13%|█▎        | 4/30 [18:20<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [18:21<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 13%|█▎        | 4/30 [18:21<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8:53 - loss: 0.9710 - sparse_categorical_accuracy: 0.7129 - f1_score: 0.5698 
 13%|█▎        | 4/30 [18:21<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [18:23<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 13%|█▎        | 4/30 [18:23<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5:15 - loss: 0.9550 - sparse_categorical_accuracy: 0.7057 - f1_score: 0.6595
 13%|█▎        | 4/30 [18:23<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [18:25<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 13%|█▎        | 4/30 [18:25<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3:25 - loss: 0.9588 - sparse_categorical_accuracy: 0.6992 - f1_score: 0.7044
 13%|█▎        | 4/30 [18:25<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [18:26<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 13%|█▎        | 4/30 [18:26<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:18 - loss: 0.9505 - sparse_categorical_accuracy: 0.7109 - f1_score: 0.7370
 13%|█▎        | 4/30 [18:26<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [18:28<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 13%|█▎        | 4/30 [18:28<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:33 - loss: 0.9479 - sparse_categorical_accuracy: 0.7148 - f1_score: 0.7566
 13%|█▎        | 4/30 [18:28<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [18:30<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 13%|█▎        | 4/30 [18:30<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:00 - loss: 0.9257 - sparse_categorical_accuracy: 0.7165 - f1_score: 0.7680
 13%|█▎        | 4/30 [18:30<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [18:31<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 13%|█▎        | 4/30 [18:31<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 35s - loss: 0.8951 - sparse_categorical_accuracy: 0.7178 - f1_score: 0.7782 
 13%|█▎        | 4/30 [18:31<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [18:33<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 13%|█▎        | 4/30 [18:33<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 16s - loss: 0.9091 - sparse_categorical_accuracy: 0.7148 - f1_score: 0.7852
 13%|█▎        | 4/30 [18:33<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [19:51<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 13%|█▎        | 4/30 [19:51<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - 223s 22s/step - loss: 0.8940 - sparse_categorical_accuracy: 0.7148 - f1_score: 0.7924 - val_loss: 0.6832 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 13%|█▎        | 4/30 [19:51<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                Epoch 2/2
 13%|█▎        | 4/30 [19:51<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 13%|█▎        | 4/30 [19:52<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 15s - loss: 0.7841 - sparse_categorical_accuracy: 0.7148 - f1_score: 0.8364
 13%|█▎        | 4/30 [19:52<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [19:54<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 13%|█▎        | 4/30 [19:54<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 13s - loss: 0.7906 - sparse_categorical_accuracy: 0.7129 - f1_score: 0.8403
 13%|█▎        | 4/30 [19:54<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [19:56<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 13%|█▎        | 4/30 [19:56<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 11s - loss: 0.8313 - sparse_categorical_accuracy: 0.7266 - f1_score: 0.8501
 13%|█▎        | 4/30 [19:56<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [19:57<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 13%|█▎        | 4/30 [19:57<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 9s - loss: 0.7949 - sparse_categorical_accuracy: 0.7236 - f1_score: 0.8487 
 13%|█▎        | 4/30 [19:57<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [19:59<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 13%|█▎        | 4/30 [19:59<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8s - loss: 0.7980 - sparse_categorical_accuracy: 0.7227 - f1_score: 0.8509
 13%|█▎        | 4/30 [19:59<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [20:01<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 13%|█▎        | 4/30 [20:01<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6s - loss: 0.7850 - sparse_categorical_accuracy: 0.7240 - f1_score: 0.8511
 13%|█▎        | 4/30 [20:01<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [20:02<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 13%|█▎        | 4/30 [20:02<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 4s - loss: 0.8054 - sparse_categorical_accuracy: 0.7188 - f1_score: 0.8493
 13%|█▎        | 4/30 [20:02<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [20:04<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 13%|█▎        | 4/30 [20:04<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3s - loss: 0.7924 - sparse_categorical_accuracy: 0.7207 - f1_score: 0.8509
 13%|█▎        | 4/30 [20:04<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [20:06<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 13%|█▎        | 4/30 [20:06<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1s - loss: 0.7979 - sparse_categorical_accuracy: 0.7227 - f1_score: 0.8528
 13%|█▎        | 4/30 [20:06<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                
 13%|█▎        | 4/30 [20:09<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 13%|█▎        | 4/30 [20:09<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                 - 18s 2s/step - loss: 0.8057 - sparse_categorical_accuracy: 0.7207 - f1_score: 0.8522 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 13%|█▎        | 4/30 [20:09<1:39:46, 230.25s/it, best loss: 0.6578827500343323]                                                                                0.6742202639579773
 13%|█▎        | 4/30 [20:26<1:39:46, 230.25s/it, best loss: 0.6578827500343323] 17%|█▋        | 5/30 [20:26<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                Layer (type)                 Output Shape              Param #   
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_62 (Conv2D)           (None, 299, 299, 91)      2548      
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_63 (Conv2D)           (None, 299, 299, 91)      74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_31 (MaxPooling (None, 149, 149, 91)      0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_31 (Batc (None, 149, 149, 91)      364       
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_64 (Conv2D)           (None, 149, 149, 91)      74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_65 (Conv2D)           (None, 149, 149, 91)      74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_32 (MaxPooling (None, 74, 74, 91)        0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_32 (Batc (None, 74, 74, 91)        364       
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_66 (Conv2D)           (None, 74, 74, 91)        74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_67 (Conv2D)           (None, 74, 74, 91)        74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_33 (MaxPooling (None, 37, 37, 91)        0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_33 (Batc (None, 37, 37, 91)        364       
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_68 (Conv2D)           (None, 37, 37, 91)        74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_69 (Conv2D)           (None, 37, 37, 91)        74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_34 (MaxPooling (None, 18, 18, 91)        0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_34 (Batc (None, 18, 18, 91)        364       
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_70 (Conv2D)           (None, 18, 18, 91)        74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_71 (Conv2D)           (None, 18, 18, 91)        74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_35 (MaxPooling (None, 9, 9, 91)          0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_35 (Batc (None, 9, 9, 91)          364       
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_72 (Conv2D)           (None, 9, 9, 91)          74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_73 (Conv2D)           (None, 9, 9, 91)          74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_36 (MaxPooling (None, 4, 4, 91)          0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_36 (Batc (None, 4, 4, 91)          364       
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_74 (Conv2D)           (None, 4, 4, 91)          74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_75 (Conv2D)           (None, 4, 4, 91)          74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_37 (MaxPooling (None, 2, 2, 91)          0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_37 (Batc (None, 2, 2, 91)          364       
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_76 (Conv2D)           (None, 2, 2, 91)          74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                conv2d_77 (Conv2D)           (None, 2, 2, 91)          74620     
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_38 (MaxPooling (None, 1, 1, 91)          0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_38 (Batc (None, 1, 1, 91)          364       
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                flatten_5 (Flatten)          (None, 91)                0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                dense_19 (Dense)             (None, 59)                5428      
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                dropout_14 (Dropout)         (None, 59)                0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                dense_20 (Dense)             (None, 59)                3540      
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                dropout_15 (Dropout)         (None, 59)                0         
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                dense_21 (Dense)             (None, 2)                 120       
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                Total params: 1,133,848
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                Trainable params: 1,132,392
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                Non-trainable params: 1,456
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                None
 17%|█▋        | 5/30 [20:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]2019-04-13 12:29:08.898347: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 17%|█▋        | 5/30 [21:06<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 17%|█▋        | 5/30 [23:36<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 22:27 - loss: 0.9823 - sparse_categorical_accuracy: 0.4570 - f1_score: 0.8364
 17%|█▋        | 5/30 [23:36<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [23:38<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 17%|█▋        | 5/30 [23:38<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 10:05 - loss: 0.9095 - sparse_categorical_accuracy: 0.4766 - f1_score: 0.8506
 17%|█▋        | 5/30 [23:38<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [23:39<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 17%|█▋        | 5/30 [23:39<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5:57 - loss: 0.8801 - sparse_categorical_accuracy: 0.4922 - f1_score: 0.8528 
 17%|█▋        | 5/30 [23:39<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [23:41<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 17%|█▋        | 5/30 [23:41<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3:52 - loss: 0.8579 - sparse_categorical_accuracy: 0.5117 - f1_score: 0.8551
 17%|█▋        | 5/30 [23:41<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [23:43<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 17%|█▋        | 5/30 [23:43<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:36 - loss: 0.8365 - sparse_categorical_accuracy: 0.5344 - f1_score: 0.8550
 17%|█▋        | 5/30 [23:43<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [23:45<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 17%|█▋        | 5/30 [23:45<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:45 - loss: 0.8164 - sparse_categorical_accuracy: 0.5612 - f1_score: 0.8566
 17%|█▋        | 5/30 [23:45<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [23:47<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 17%|█▋        | 5/30 [23:47<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:08 - loss: 0.8006 - sparse_categorical_accuracy: 0.5720 - f1_score: 0.8534
 17%|█▋        | 5/30 [23:47<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [23:48<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 17%|█▋        | 5/30 [23:48<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 40s - loss: 0.7839 - sparse_categorical_accuracy: 0.5903 - f1_score: 0.8548 
 17%|█▋        | 5/30 [23:48<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [23:50<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 17%|█▋        | 5/30 [23:50<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 18s - loss: 0.7609 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8553
 17%|█▋        | 5/30 [23:50<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:18<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 17%|█▋        | 5/30 [25:18<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - 252s 25s/step - loss: 0.7418 - sparse_categorical_accuracy: 0.6160 - f1_score: 0.8547 - val_loss: 0.9549 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 17%|█▋        | 5/30 [25:18<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                Epoch 2/2
 17%|█▋        | 5/30 [25:18<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 17%|█▋        | 5/30 [25:20<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 15s - loss: 0.6465 - sparse_categorical_accuracy: 0.6953 - f1_score: 0.8647
 17%|█▋        | 5/30 [25:20<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:22<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 17%|█▋        | 5/30 [25:22<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 13s - loss: 0.6106 - sparse_categorical_accuracy: 0.7129 - f1_score: 0.8647
 17%|█▋        | 5/30 [25:22<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:23<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 17%|█▋        | 5/30 [25:23<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 12s - loss: 0.6052 - sparse_categorical_accuracy: 0.7174 - f1_score: 0.8596
 17%|█▋        | 5/30 [25:23<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:25<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 17%|█▋        | 5/30 [25:25<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 10s - loss: 0.6071 - sparse_categorical_accuracy: 0.7188 - f1_score: 0.8564
 17%|█▋        | 5/30 [25:25<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:27<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 17%|█▋        | 5/30 [25:27<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8s - loss: 0.5996 - sparse_categorical_accuracy: 0.7242 - f1_score: 0.8524 
 17%|█▋        | 5/30 [25:27<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:29<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 17%|█▋        | 5/30 [25:29<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6s - loss: 0.5851 - sparse_categorical_accuracy: 0.7350 - f1_score: 0.8549
 17%|█▋        | 5/30 [25:29<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 17%|█▋        | 5/30 [25:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5s - loss: 0.5897 - sparse_categorical_accuracy: 0.7349 - f1_score: 0.8552
 17%|█▋        | 5/30 [25:30<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:32<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 17%|█▋        | 5/30 [25:32<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3s - loss: 0.5751 - sparse_categorical_accuracy: 0.7407 - f1_score: 0.8564
 17%|█▋        | 5/30 [25:32<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:34<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 17%|█▋        | 5/30 [25:34<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1s - loss: 0.5661 - sparse_categorical_accuracy: 0.7435 - f1_score: 0.8576
 17%|█▋        | 5/30 [25:34<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                
 17%|█▋        | 5/30 [25:37<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 17%|█▋        | 5/30 [25:37<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                 - 19s 2s/step - loss: 0.5561 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8586 - val_loss: 0.9795 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 17%|█▋        | 5/30 [25:37<1:43:23, 248.14s/it, best loss: 0.6578827500343323]                                                                                0.9794528484344482
 17%|█▋        | 5/30 [26:01<1:43:23, 248.14s/it, best loss: 0.6578827500343323] 20%|██        | 6/30 [26:01<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                Layer (type)                 Output Shape              Param #   
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_78 (Conv2D)           (None, 299, 299, 75)      2100      
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_79 (Conv2D)           (None, 299, 299, 75)      50700     
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_39 (MaxPooling (None, 149, 149, 75)      0         
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_39 (Batc (None, 149, 149, 75)      300       
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_80 (Conv2D)           (None, 149, 149, 75)      50700     
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_81 (Conv2D)           (None, 149, 149, 75)      50700     
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_40 (MaxPooling (None, 74, 74, 75)        0         
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_40 (Batc (None, 74, 74, 75)        300       
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_82 (Conv2D)           (None, 74, 74, 75)        50700     
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_83 (Conv2D)           (None, 74, 74, 75)        50700     
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_41 (MaxPooling (None, 37, 37, 75)        0         
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_41 (Batc (None, 37, 37, 75)        300       
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_84 (Conv2D)           (None, 37, 37, 75)        50700     
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_85 (Conv2D)           (None, 37, 37, 75)        50700     
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_42 (MaxPooling (None, 18, 18, 75)        0         
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_42 (Batc (None, 18, 18, 75)        300       
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_86 (Conv2D)           (None, 18, 18, 75)        50700     
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                conv2d_87 (Conv2D)           (None, 18, 18, 75)        50700     
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_43 (MaxPooling (None, 9, 9, 75)          0         
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_43 (Batc (None, 9, 9, 75)          300       
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                flatten_6 (Flatten)          (None, 6075)              0         
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                dense_22 (Dense)             (None, 61)                370636    
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                dropout_16 (Dropout)         (None, 61)                0         
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                dense_23 (Dense)             (None, 61)                3782      
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                dropout_17 (Dropout)         (None, 61)                0         
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                dense_24 (Dense)             (None, 61)                3782      
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                dropout_18 (Dropout)         (None, 61)                0         
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                dense_25 (Dense)             (None, 2)                 124       
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                Total params: 838,224
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                Trainable params: 837,474
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                Non-trainable params: 750
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                None
 20%|██        | 6/30 [26:05<1:49:41, 274.24s/it, best loss: 0.6578827500343323]2019-04-13 12:34:43.138351: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 20%|██        | 6/30 [26:50<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 20%|██        | 6/30 [29:25<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 23:15 - loss: 3.8338 - sparse_categorical_accuracy: 0.5938 - f1_score: 0.6725
 20%|██        | 6/30 [29:25<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [29:27<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 20%|██        | 6/30 [29:27<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 10:27 - loss: 3.7311 - sparse_categorical_accuracy: 0.5996 - f1_score: 0.7597
 20%|██        | 6/30 [29:27<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [29:28<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 20%|██        | 6/30 [29:28<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6:09 - loss: 3.5333 - sparse_categorical_accuracy: 0.6094 - f1_score: 0.7896 
 20%|██        | 6/30 [29:28<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [29:30<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 20%|██        | 6/30 [29:30<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 4:00 - loss: 3.4801 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8045
 20%|██        | 6/30 [29:30<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [29:32<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 20%|██        | 6/30 [29:32<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:41 - loss: 3.4332 - sparse_categorical_accuracy: 0.6031 - f1_score: 0.8120
 20%|██        | 6/30 [29:32<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [29:33<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 20%|██        | 6/30 [29:33<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:49 - loss: 3.3888 - sparse_categorical_accuracy: 0.6061 - f1_score: 0.8173
 20%|██        | 6/30 [29:33<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [29:35<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 20%|██        | 6/30 [29:35<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:10 - loss: 3.3786 - sparse_categorical_accuracy: 0.6060 - f1_score: 0.8252
 20%|██        | 6/30 [29:35<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [29:37<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 20%|██        | 6/30 [29:37<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 41s - loss: 3.3692 - sparse_categorical_accuracy: 0.6030 - f1_score: 0.8269 
 20%|██        | 6/30 [29:37<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [29:39<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 20%|██        | 6/30 [29:39<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 18s - loss: 3.3315 - sparse_categorical_accuracy: 0.6072 - f1_score: 0.8311
 20%|██        | 6/30 [29:39<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:16<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 20%|██        | 6/30 [31:16<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - 266s 27s/step - loss: 3.3414 - sparse_categorical_accuracy: 0.6066 - f1_score: 0.8342 - val_loss: 1.7389 - val_sparse_categorical_accuracy: 0.2750 - val_f1_score: 0.8406

 20%|██        | 6/30 [31:16<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                Epoch 2/2
 20%|██        | 6/30 [31:16<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 20%|██        | 6/30 [31:17<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 15s - loss: 3.3274 - sparse_categorical_accuracy: 0.6055 - f1_score: 0.8571
 20%|██        | 6/30 [31:17<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:19<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 20%|██        | 6/30 [31:19<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 13s - loss: 2.9402 - sparse_categorical_accuracy: 0.6289 - f1_score: 0.8609
 20%|██        | 6/30 [31:19<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:21<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 20%|██        | 6/30 [31:21<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 11s - loss: 2.9211 - sparse_categorical_accuracy: 0.6484 - f1_score: 0.8630
 20%|██        | 6/30 [31:21<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:23<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 20%|██        | 6/30 [31:23<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 10s - loss: 2.8962 - sparse_categorical_accuracy: 0.6455 - f1_score: 0.8616
 20%|██        | 6/30 [31:23<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:24<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 20%|██        | 6/30 [31:24<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8s - loss: 2.7569 - sparse_categorical_accuracy: 0.6500 - f1_score: 0.8576 
 20%|██        | 6/30 [31:24<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:26<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 20%|██        | 6/30 [31:26<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6s - loss: 2.7487 - sparse_categorical_accuracy: 0.6491 - f1_score: 0.8567
 20%|██        | 6/30 [31:26<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:28<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 20%|██        | 6/30 [31:28<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5s - loss: 2.7356 - sparse_categorical_accuracy: 0.6551 - f1_score: 0.8578
 20%|██        | 6/30 [31:28<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:29<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 20%|██        | 6/30 [31:29<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3s - loss: 2.7452 - sparse_categorical_accuracy: 0.6509 - f1_score: 0.8558
 20%|██        | 6/30 [31:29<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:31<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 20%|██        | 6/30 [31:31<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1s - loss: 2.6910 - sparse_categorical_accuracy: 0.6506 - f1_score: 0.8559
 20%|██        | 6/30 [31:31<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                
 20%|██        | 6/30 [31:34<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 20%|██        | 6/30 [31:34<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                 - 18s 2s/step - loss: 2.6219 - sparse_categorical_accuracy: 0.6543 - f1_score: 0.8550 - val_loss: 3.5515 - val_sparse_categorical_accuracy: 0.2750 - val_f1_score: 0.8406

 20%|██        | 6/30 [31:34<1:49:41, 274.24s/it, best loss: 0.6578827500343323]                                                                                3.551532030105591
 20%|██        | 6/30 [32:03<1:49:41, 274.24s/it, best loss: 0.6578827500343323] 23%|██▎       | 7/30 [32:03<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                Layer (type)                 Output Shape              Param #   
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_88 (Conv2D)           (None, 299, 299, 27)      756       
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_89 (Conv2D)           (None, 299, 299, 27)      6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_44 (MaxPooling (None, 149, 149, 27)      0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_44 (Batc (None, 149, 149, 27)      108       
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_90 (Conv2D)           (None, 149, 149, 27)      6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_91 (Conv2D)           (None, 149, 149, 27)      6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_45 (MaxPooling (None, 74, 74, 27)        0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_45 (Batc (None, 74, 74, 27)        108       
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_92 (Conv2D)           (None, 74, 74, 27)        6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_93 (Conv2D)           (None, 74, 74, 27)        6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_46 (MaxPooling (None, 37, 37, 27)        0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_46 (Batc (None, 37, 37, 27)        108       
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_94 (Conv2D)           (None, 37, 37, 27)        6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_95 (Conv2D)           (None, 37, 37, 27)        6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_47 (MaxPooling (None, 18, 18, 27)        0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_47 (Batc (None, 18, 18, 27)        108       
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_96 (Conv2D)           (None, 18, 18, 27)        6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_97 (Conv2D)           (None, 18, 18, 27)        6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_48 (MaxPooling (None, 9, 9, 27)          0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_48 (Batc (None, 9, 9, 27)          108       
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_98 (Conv2D)           (None, 9, 9, 27)          6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                conv2d_99 (Conv2D)           (None, 9, 9, 27)          6588      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_49 (MaxPooling (None, 4, 4, 27)          0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_49 (Batc (None, 4, 4, 27)          108       
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                flatten_7 (Flatten)          (None, 432)               0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dense_26 (Dense)             (None, 93)                40269     
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dropout_19 (Dropout)         (None, 93)                0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dense_27 (Dense)             (None, 93)                8742      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dropout_20 (Dropout)         (None, 93)                0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dense_28 (Dense)             (None, 93)                8742      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dropout_21 (Dropout)         (None, 93)                0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dense_29 (Dense)             (None, 93)                8742      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dropout_22 (Dropout)         (None, 93)                0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dense_30 (Dense)             (None, 93)                8742      
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dropout_23 (Dropout)         (None, 93)                0         
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                dense_31 (Dense)             (None, 2)                 188       
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                Total params: 149,297
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                Trainable params: 148,973
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                Non-trainable params: 324
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                None
 23%|██▎       | 7/30 [32:07<1:55:10, 300.45s/it, best loss: 0.6578827500343323]2019-04-13 12:40:45.350872: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 23%|██▎       | 7/30 [33:01<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 23%|██▎       | 7/30 [35:51<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 25:25 - loss: 2.7586 - sparse_categorical_accuracy: 0.5547 - f1_score: 0.8546
 23%|██▎       | 7/30 [35:51<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [35:52<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 23%|██▎       | 7/30 [35:52<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 11:24 - loss: 2.3336 - sparse_categorical_accuracy: 0.5703 - f1_score: 0.8609
 23%|██▎       | 7/30 [35:52<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [35:54<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 23%|██▎       | 7/30 [35:54<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6:43 - loss: 2.3259 - sparse_categorical_accuracy: 0.5729 - f1_score: 0.8597 
 23%|██▎       | 7/30 [35:54<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [35:55<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 23%|██▎       | 7/30 [35:55<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 4:21 - loss: 2.1954 - sparse_categorical_accuracy: 0.5771 - f1_score: 0.8590
 23%|██▎       | 7/30 [35:55<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [35:57<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 23%|██▎       | 7/30 [35:57<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:56 - loss: 2.2050 - sparse_categorical_accuracy: 0.5766 - f1_score: 0.8576
 23%|██▎       | 7/30 [35:57<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [35:59<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 23%|██▎       | 7/30 [35:59<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:58 - loss: 2.1150 - sparse_categorical_accuracy: 0.5885 - f1_score: 0.8575
 23%|██▎       | 7/30 [35:59<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [36:00<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 23%|██▎       | 7/30 [36:00<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:16 - loss: 2.0564 - sparse_categorical_accuracy: 0.5915 - f1_score: 0.8589
 23%|██▎       | 7/30 [36:00<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [36:02<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 23%|██▎       | 7/30 [36:02<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 45s - loss: 1.9985 - sparse_categorical_accuracy: 0.5967 - f1_score: 0.8600 
 23%|██▎       | 7/30 [36:02<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [36:04<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 23%|██▎       | 7/30 [36:04<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 20s - loss: 1.9354 - sparse_categorical_accuracy: 0.6024 - f1_score: 0.8582
 23%|██▎       | 7/30 [36:04<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [37:46<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 23%|██▎       | 7/30 [37:46<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - 285s 29s/step - loss: 1.9087 - sparse_categorical_accuracy: 0.6070 - f1_score: 0.8581 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 23%|██▎       | 7/30 [37:46<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                Epoch 2/2
 23%|██▎       | 7/30 [37:46<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 23%|██▎       | 7/30 [37:48<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 16s - loss: 1.4529 - sparse_categorical_accuracy: 0.6211 - f1_score: 0.8364
 23%|██▎       | 7/30 [37:48<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [37:50<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 23%|██▎       | 7/30 [37:50<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 14s - loss: 1.3940 - sparse_categorical_accuracy: 0.6543 - f1_score: 0.8480
 23%|██▎       | 7/30 [37:50<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [37:52<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 23%|██▎       | 7/30 [37:52<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 12s - loss: 1.3490 - sparse_categorical_accuracy: 0.6523 - f1_score: 0.8536
 23%|██▎       | 7/30 [37:52<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [37:53<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 23%|██▎       | 7/30 [37:53<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 10s - loss: 1.2829 - sparse_categorical_accuracy: 0.6592 - f1_score: 0.8493
 23%|██▎       | 7/30 [37:53<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [37:55<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 23%|██▎       | 7/30 [37:55<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8s - loss: 1.2777 - sparse_categorical_accuracy: 0.6531 - f1_score: 0.8467 
 23%|██▎       | 7/30 [37:55<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [37:57<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 23%|██▎       | 7/30 [37:57<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6s - loss: 1.2436 - sparse_categorical_accuracy: 0.6576 - f1_score: 0.8480
 23%|██▎       | 7/30 [37:57<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [37:58<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 23%|██▎       | 7/30 [37:58<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5s - loss: 1.2123 - sparse_categorical_accuracy: 0.6546 - f1_score: 0.8471
 23%|██▎       | 7/30 [37:58<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [38:00<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 23%|██▎       | 7/30 [38:00<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3s - loss: 1.2084 - sparse_categorical_accuracy: 0.6528 - f1_score: 0.8490
 23%|██▎       | 7/30 [38:00<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [38:02<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 23%|██▎       | 7/30 [38:02<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1s - loss: 1.1870 - sparse_categorical_accuracy: 0.6519 - f1_score: 0.8510
 23%|██▎       | 7/30 [38:02<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                
 23%|██▎       | 7/30 [38:05<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 23%|██▎       | 7/30 [38:05<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                 - 19s 2s/step - loss: 1.1617 - sparse_categorical_accuracy: 0.6504 - f1_score: 0.8509 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 23%|██▎       | 7/30 [38:05<1:55:10, 300.45s/it, best loss: 0.6578827500343323]                                                                                0.6721892952919006
 23%|██▎       | 7/30 [38:42<1:55:10, 300.45s/it, best loss: 0.6578827500343323] 27%|██▋       | 8/30 [38:42<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                Layer (type)                 Output Shape              Param #   
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                conv2d_100 (Conv2D)          (None, 299, 299, 125)     3500      
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                conv2d_101 (Conv2D)          (None, 299, 299, 125)     140750    
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_50 (MaxPooling (None, 149, 149, 125)     0         
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_50 (Batc (None, 149, 149, 125)     500       
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                conv2d_102 (Conv2D)          (None, 149, 149, 125)     140750    
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                conv2d_103 (Conv2D)          (None, 149, 149, 125)     140750    
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_51 (MaxPooling (None, 74, 74, 125)       0         
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_51 (Batc (None, 74, 74, 125)       500       
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                conv2d_104 (Conv2D)          (None, 74, 74, 125)       140750    
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                conv2d_105 (Conv2D)          (None, 74, 74, 125)       140750    
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_52 (MaxPooling (None, 37, 37, 125)       0         
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_52 (Batc (None, 37, 37, 125)       500       
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                conv2d_106 (Conv2D)          (None, 37, 37, 125)       140750    
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                conv2d_107 (Conv2D)          (None, 37, 37, 125)       140750    
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_53 (MaxPooling (None, 18, 18, 125)       0         
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_53 (Batc (None, 18, 18, 125)       500       
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                flatten_8 (Flatten)          (None, 40500)             0         
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                dense_32 (Dense)             (None, 99)                4009599   
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                dropout_24 (Dropout)         (None, 99)                0         
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                dense_33 (Dense)             (None, 99)                9900      
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                dropout_25 (Dropout)         (None, 99)                0         
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                dense_34 (Dense)             (None, 2)                 200       
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                Total params: 5,010,449
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                Trainable params: 5,009,449
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                Non-trainable params: 1,000
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                None
 27%|██▋       | 8/30 [38:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]2019-04-13 12:47:24.894224: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 27%|██▋       | 8/30 [39:52<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 27%|██▋       | 8/30 [42:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 26:05 - loss: 1.1175 - sparse_categorical_accuracy: 0.4258 - f1_score: 0.8722
 27%|██▋       | 8/30 [42:46<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [42:48<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 27%|██▋       | 8/30 [42:48<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 11:42 - loss: 1.7288 - sparse_categorical_accuracy: 0.5840 - f1_score: 0.8556
 27%|██▋       | 8/30 [42:48<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [42:49<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 27%|██▋       | 8/30 [42:49<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6:53 - loss: 4.0694 - sparse_categorical_accuracy: 0.5013 - f1_score: 0.8518 
 27%|██▋       | 8/30 [42:49<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [42:51<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 27%|██▋       | 8/30 [42:51<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 4:28 - loss: 3.6603 - sparse_categorical_accuracy: 0.5713 - f1_score: 0.8557
 27%|██▋       | 8/30 [42:51<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [42:53<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 27%|██▋       | 8/30 [42:53<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3:00 - loss: 3.2043 - sparse_categorical_accuracy: 0.5945 - f1_score: 0.8524
 27%|██▋       | 8/30 [42:53<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [42:54<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 27%|██▋       | 8/30 [42:54<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:01 - loss: 2.8421 - sparse_categorical_accuracy: 0.6126 - f1_score: 0.8510
 27%|██▋       | 8/30 [42:54<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [42:56<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 27%|██▋       | 8/30 [42:56<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:18 - loss: 2.6253 - sparse_categorical_accuracy: 0.6211 - f1_score: 0.8519
 27%|██▋       | 8/30 [42:56<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [42:58<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 27%|██▋       | 8/30 [42:58<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 46s - loss: 2.4173 - sparse_categorical_accuracy: 0.6309 - f1_score: 0.8499 
 27%|██▋       | 8/30 [42:58<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [42:59<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 27%|██▋       | 8/30 [42:59<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 20s - loss: 2.2245 - sparse_categorical_accuracy: 0.6441 - f1_score: 0.8502
 27%|██▋       | 8/30 [42:59<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [44:48<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 27%|██▋       | 8/30 [44:48<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - 296s 30s/step - loss: 2.1081 - sparse_categorical_accuracy: 0.6520 - f1_score: 0.8509 - val_loss: 4.4325 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 27%|██▋       | 8/30 [44:48<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                Epoch 2/2
 27%|██▋       | 8/30 [44:48<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 27%|██▋       | 8/30 [44:50<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 17s - loss: 0.8921 - sparse_categorical_accuracy: 0.7734 - f1_score: 0.8364
 27%|██▋       | 8/30 [44:50<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [44:51<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 27%|██▋       | 8/30 [44:51<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 14s - loss: 0.9997 - sparse_categorical_accuracy: 0.7520 - f1_score: 0.8506
 27%|██▋       | 8/30 [44:51<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [44:53<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 27%|██▋       | 8/30 [44:53<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 12s - loss: 0.9182 - sparse_categorical_accuracy: 0.7552 - f1_score: 0.8553
 27%|██▋       | 8/30 [44:53<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [44:55<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 27%|██▋       | 8/30 [44:55<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 11s - loss: 0.8471 - sparse_categorical_accuracy: 0.7646 - f1_score: 0.8570
 27%|██▋       | 8/30 [44:55<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [44:57<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 27%|██▋       | 8/30 [44:57<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 9s - loss: 0.7757 - sparse_categorical_accuracy: 0.7789 - f1_score: 0.8545 
 27%|██▋       | 8/30 [44:57<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [44:59<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 27%|██▋       | 8/30 [44:59<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 7s - loss: 0.7387 - sparse_categorical_accuracy: 0.7832 - f1_score: 0.8562
 27%|██▋       | 8/30 [44:59<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [45:00<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 27%|██▋       | 8/30 [45:00<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5s - loss: 0.7077 - sparse_categorical_accuracy: 0.7868 - f1_score: 0.8578
 27%|██▋       | 8/30 [45:00<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [45:02<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 27%|██▋       | 8/30 [45:02<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3s - loss: 0.6647 - sparse_categorical_accuracy: 0.7979 - f1_score: 0.8589
 27%|██▋       | 8/30 [45:02<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [45:04<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 27%|██▋       | 8/30 [45:04<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1s - loss: 0.6359 - sparse_categorical_accuracy: 0.8003 - f1_score: 0.8590
 27%|██▋       | 8/30 [45:04<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                
 27%|██▋       | 8/30 [45:07<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 27%|██▋       | 8/30 [45:07<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                 - 19s 2s/step - loss: 0.6073 - sparse_categorical_accuracy: 0.8059 - f1_score: 0.8596 - val_loss: 4.4325 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 27%|██▋       | 8/30 [45:07<2:01:01, 330.09s/it, best loss: 0.6578827500343323]                                                                                4.43246603012085
 27%|██▋       | 8/30 [45:50<2:01:01, 330.09s/it, best loss: 0.6578827500343323] 30%|███       | 9/30 [45:50<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                Layer (type)                 Output Shape              Param #   
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                conv2d_108 (Conv2D)          (None, 299, 299, 46)      1288      
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                conv2d_109 (Conv2D)          (None, 299, 299, 46)      19090     
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_54 (MaxPooling (None, 149, 149, 46)      0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_54 (Batc (None, 149, 149, 46)      184       
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                conv2d_110 (Conv2D)          (None, 149, 149, 46)      19090     
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                conv2d_111 (Conv2D)          (None, 149, 149, 46)      19090     
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_55 (MaxPooling (None, 74, 74, 46)        0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_55 (Batc (None, 74, 74, 46)        184       
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                conv2d_112 (Conv2D)          (None, 74, 74, 46)        19090     
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                conv2d_113 (Conv2D)          (None, 74, 74, 46)        19090     
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_56 (MaxPooling (None, 37, 37, 46)        0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_56 (Batc (None, 37, 37, 46)        184       
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                conv2d_114 (Conv2D)          (None, 37, 37, 46)        19090     
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                conv2d_115 (Conv2D)          (None, 37, 37, 46)        19090     
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                max_pooling2d_57 (MaxPooling (None, 18, 18, 46)        0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                batch_normalization_57 (Batc (None, 18, 18, 46)        184       
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                flatten_9 (Flatten)          (None, 14904)             0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dense_35 (Dense)             (None, 1)                 14905     
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dropout_26 (Dropout)         (None, 1)                 0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dense_36 (Dense)             (None, 1)                 2         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dropout_27 (Dropout)         (None, 1)                 0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dense_37 (Dense)             (None, 1)                 2         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dropout_28 (Dropout)         (None, 1)                 0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dense_38 (Dense)             (None, 1)                 2         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dropout_29 (Dropout)         (None, 1)                 0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dense_39 (Dense)             (None, 1)                 2         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dropout_30 (Dropout)         (None, 1)                 0         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                dense_40 (Dense)             (None, 2)                 4         
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                =================================================================
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                Total params: 150,571
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                Trainable params: 150,203
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                Non-trainable params: 368
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                _________________________________________________________________
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                None
 30%|███       | 9/30 [45:54<2:05:46, 359.35s/it, best loss: 0.6578827500343323]2019-04-13 12:54:32.497616: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                Epoch 1/2
 30%|███       | 9/30 [47:07<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 30%|███       | 9/30 [50:11<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 27:30 - loss: 0.6931 - sparse_categorical_accuracy: 0.7266 - f1_score: 0.0000e+00
 30%|███       | 9/30 [50:11<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [50:13<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 30%|███       | 9/30 [50:13<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 12:20 - loss: 0.6929 - sparse_categorical_accuracy: 0.7324 - f1_score: 0.4247    
 30%|███       | 9/30 [50:13<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [50:14<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 30%|███       | 9/30 [50:14<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 7:16 - loss: 0.6926 - sparse_categorical_accuracy: 0.7448 - f1_score: 0.5731 
 30%|███       | 9/30 [50:14<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [50:16<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 30%|███       | 9/30 [50:16<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 4:42 - loss: 0.6924 - sparse_categorical_accuracy: 0.7432 - f1_score: 0.6422
 30%|███       | 9/30 [50:16<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [50:18<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 30%|███       | 9/30 [50:18<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3:10 - loss: 0.6922 - sparse_categorical_accuracy: 0.7438 - f1_score: 0.6846
 30%|███       | 9/30 [50:18<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [50:19<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 30%|███       | 9/30 [50:19<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 2:08 - loss: 0.6919 - sparse_categorical_accuracy: 0.7422 - f1_score: 0.7117
 30%|███       | 9/30 [50:19<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [50:21<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 30%|███       | 9/30 [50:21<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1:23 - loss: 0.6917 - sparse_categorical_accuracy: 0.7439 - f1_score: 0.7328
 30%|███       | 9/30 [50:21<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [50:23<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 30%|███       | 9/30 [50:23<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 48s - loss: 0.6914 - sparse_categorical_accuracy: 0.7466 - f1_score: 0.7496 
 30%|███       | 9/30 [50:23<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [50:25<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 30%|███       | 9/30 [50:25<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 21s - loss: 0.6911 - sparse_categorical_accuracy: 0.7470 - f1_score: 0.7616
 30%|███       | 9/30 [50:25<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:21<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 30%|███       | 9/30 [52:21<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - 314s 31s/step - loss: 0.6909 - sparse_categorical_accuracy: 0.7484 - f1_score: 0.7719 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 30%|███       | 9/30 [52:21<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                Epoch 2/2
 30%|███       | 9/30 [52:21<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 1/10 [==>...........................]
 30%|███       | 9/30 [52:23<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 15s - loss: 0.6880 - sparse_categorical_accuracy: 0.7617 - f1_score: 0.8647
 30%|███       | 9/30 [52:23<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:25<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 2/10 [=====>........................]
 30%|███       | 9/30 [52:25<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 13s - loss: 0.6880 - sparse_categorical_accuracy: 0.7480 - f1_score: 0.8558
 30%|███       | 9/30 [52:25<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:26<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 3/10 [========>.....................]
 30%|███       | 9/30 [52:26<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 11s - loss: 0.6878 - sparse_categorical_accuracy: 0.7448 - f1_score: 0.8537
 30%|███       | 9/30 [52:26<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:28<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 4/10 [===========>..................]
 30%|███       | 9/30 [52:28<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 10s - loss: 0.6876 - sparse_categorical_accuracy: 0.7441 - f1_score: 0.8533
 30%|███       | 9/30 [52:28<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:30<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 5/10 [==============>...............]
 30%|███       | 9/30 [52:30<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 8s - loss: 0.6874 - sparse_categorical_accuracy: 0.7438 - f1_score: 0.8530 
 30%|███       | 9/30 [52:30<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:32<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 6/10 [=================>............]
 30%|███       | 9/30 [52:32<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 6s - loss: 0.6870 - sparse_categorical_accuracy: 0.7480 - f1_score: 0.8558
 30%|███       | 9/30 [52:32<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:33<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 7/10 [====================>.........]
 30%|███       | 9/30 [52:33<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 5s - loss: 0.6868 - sparse_categorical_accuracy: 0.7478 - f1_score: 0.8556
 30%|███       | 9/30 [52:33<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:35<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 8/10 [=======================>......]
 30%|███       | 9/30 [52:35<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 3s - loss: 0.6865 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8571
 30%|███       | 9/30 [52:35<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:37<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 9/10 [==========================>...]
 30%|███       | 9/30 [52:37<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - ETA: 1s - loss: 0.6863 - sparse_categorical_accuracy: 0.7487 - f1_score: 0.8562
 30%|███       | 9/30 [52:37<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                
 30%|███       | 9/30 [52:40<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                10/10 [==============================]
 30%|███       | 9/30 [52:40<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                 - 19s 2s/step - loss: 0.6861 - sparse_categorical_accuracy: 0.7461 - f1_score: 0.8545 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 30%|███       | 9/30 [52:40<2:05:46, 359.35s/it, best loss: 0.6578827500343323]                                                                                0.6843452453613281
 30%|███       | 9/30 [53:28<2:05:46, 359.35s/it, best loss: 0.6578827500343323] 33%|███▎      | 10/30 [53:28<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 Layer (type)                 Output Shape              Param #   
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 =================================================================
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_116 (Conv2D)          (None, 299, 299, 48)      1344      
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_117 (Conv2D)          (None, 299, 299, 48)      20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 max_pooling2d_58 (MaxPooling (None, 149, 149, 48)      0         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 batch_normalization_58 (Batc (None, 149, 149, 48)      192       
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_118 (Conv2D)          (None, 149, 149, 48)      20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_119 (Conv2D)          (None, 149, 149, 48)      20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 max_pooling2d_59 (MaxPooling (None, 74, 74, 48)        0         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 batch_normalization_59 (Batc (None, 74, 74, 48)        192       
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_120 (Conv2D)          (None, 74, 74, 48)        20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_121 (Conv2D)          (None, 74, 74, 48)        20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 max_pooling2d_60 (MaxPooling (None, 37, 37, 48)        0         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 batch_normalization_60 (Batc (None, 37, 37, 48)        192       
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_122 (Conv2D)          (None, 37, 37, 48)        20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_123 (Conv2D)          (None, 37, 37, 48)        20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 max_pooling2d_61 (MaxPooling (None, 18, 18, 48)        0         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 batch_normalization_61 (Batc (None, 18, 18, 48)        192       
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_124 (Conv2D)          (None, 18, 18, 48)        20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_125 (Conv2D)          (None, 18, 18, 48)        20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 max_pooling2d_62 (MaxPooling (None, 9, 9, 48)          0         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 batch_normalization_62 (Batc (None, 9, 9, 48)          192       
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_126 (Conv2D)          (None, 9, 9, 48)          20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 conv2d_127 (Conv2D)          (None, 9, 9, 48)          20784     
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 max_pooling2d_63 (MaxPooling (None, 4, 4, 48)          0         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 batch_normalization_63 (Batc (None, 4, 4, 48)          192       
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 flatten_10 (Flatten)         (None, 768)               0         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 dense_41 (Dense)             (None, 2)                 1538      
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 dropout_31 (Dropout)         (None, 2)                 0         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 dense_42 (Dense)             (None, 2)                 6         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 dropout_32 (Dropout)         (None, 2)                 0         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 dense_43 (Dense)             (None, 2)                 6         
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 =================================================================
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 Total params: 232,670
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 Trainable params: 232,094
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 Non-trainable params: 576
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 _________________________________________________________________
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 None
 33%|███▎      | 10/30 [53:33<2:09:44, 389.20s/it, best loss: 0.6578827500343323]2019-04-13 13:02:11.959081: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                 Epoch 1/2
 33%|███▎      | 10/30 [54:58<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  1/10 [==>...........................]
 33%|███▎      | 10/30 [58:19<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  - ETA: 30:07 - loss: 1.0980 - sparse_categorical_accuracy: 0.6484 - f1_score: 0.3615
 33%|███▎      | 10/30 [58:19<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 
 33%|███▎      | 10/30 [58:20<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  2/10 [=====>........................]
 33%|███▎      | 10/30 [58:20<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  - ETA: 13:30 - loss: 0.9310 - sparse_categorical_accuracy: 0.6484 - f1_score: 0.5990
 33%|███▎      | 10/30 [58:20<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 
 33%|███▎      | 10/30 [58:22<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  3/10 [========>.....................]
 33%|███▎      | 10/30 [58:22<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  - ETA: 7:56 - loss: 0.8625 - sparse_categorical_accuracy: 0.6641 - f1_score: 0.6875 
 33%|███▎      | 10/30 [58:22<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 
 33%|███▎      | 10/30 [58:24<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  4/10 [===========>..................]
 33%|███▎      | 10/30 [58:24<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  - ETA: 5:08 - loss: 0.8228 - sparse_categorical_accuracy: 0.6738 - f1_score: 0.7325
 33%|███▎      | 10/30 [58:24<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 
 33%|███▎      | 10/30 [58:25<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  5/10 [==============>...............]
 33%|███▎      | 10/30 [58:25<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  - ETA: 3:27 - loss: 0.7980 - sparse_categorical_accuracy: 0.6766 - f1_score: 0.7543
 33%|███▎      | 10/30 [58:25<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 
 33%|███▎      | 10/30 [58:27<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  6/10 [=================>............]
 33%|███▎      | 10/30 [58:27<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  - ETA: 2:19 - loss: 0.7812 - sparse_categorical_accuracy: 0.6836 - f1_score: 0.7731
 33%|███▎      | 10/30 [58:27<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 
 33%|███▎      | 10/30 [58:29<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  7/10 [====================>.........]
 33%|███▎      | 10/30 [58:29<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  - ETA: 1:30 - loss: 0.7688 - sparse_categorical_accuracy: 0.6903 - f1_score: 0.7851
 33%|███▎      | 10/30 [58:29<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 
 33%|███▎      | 10/30 [58:30<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  8/10 [=======================>......]
 33%|███▎      | 10/30 [58:30<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  - ETA: 53s - loss: 0.7584 - sparse_categorical_accuracy: 0.7007 - f1_score: 0.7954 
 33%|███▎      | 10/30 [58:30<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 
 33%|███▎      | 10/30 [58:32<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  9/10 [==========================>...]
 33%|███▎      | 10/30 [58:32<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                  - ETA: 23s - loss: 0.7509 - sparse_categorical_accuracy: 0.7066 - f1_score: 0.8023
 33%|███▎      | 10/30 [58:32<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                 
 33%|███▎      | 10/30 [1:00:37<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   10/10 [==============================]
 33%|███▎      | 10/30 [1:00:37<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - 340s 34s/step - loss: 0.7442 - sparse_categorical_accuracy: 0.7129 - f1_score: 0.8085 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 33%|███▎      | 10/30 [1:00:37<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   Epoch 2/2
 33%|███▎      | 10/30 [1:00:37<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    1/10 [==>...........................]
 33%|███▎      | 10/30 [1:00:39<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 15s - loss: 0.6841 - sparse_categorical_accuracy: 0.7539 - f1_score: 0.8494
 33%|███▎      | 10/30 [1:00:39<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   
 33%|███▎      | 10/30 [1:00:41<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    2/10 [=====>........................]
 33%|███▎      | 10/30 [1:00:41<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 13s - loss: 0.6868 - sparse_categorical_accuracy: 0.7461 - f1_score: 0.8507
 33%|███▎      | 10/30 [1:00:41<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   
 33%|███▎      | 10/30 [1:00:42<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    3/10 [========>.....................]
 33%|███▎      | 10/30 [1:00:42<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 11s - loss: 0.6850 - sparse_categorical_accuracy: 0.7591 - f1_score: 0.8587
 33%|███▎      | 10/30 [1:00:42<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   
 33%|███▎      | 10/30 [1:00:44<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    4/10 [===========>..................]
 33%|███▎      | 10/30 [1:00:44<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 9s - loss: 0.6863 - sparse_categorical_accuracy: 0.7529 - f1_score: 0.8545 
 33%|███▎      | 10/30 [1:00:44<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   
 33%|███▎      | 10/30 [1:00:46<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    5/10 [==============>...............]
 33%|███▎      | 10/30 [1:00:46<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 8s - loss: 0.6902 - sparse_categorical_accuracy: 0.7508 - f1_score: 0.8534
 33%|███▎      | 10/30 [1:00:46<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   
 33%|███▎      | 10/30 [1:00:47<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    6/10 [=================>............]
 33%|███▎      | 10/30 [1:00:47<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 6s - loss: 0.6892 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8545
 33%|███▎      | 10/30 [1:00:47<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   
 33%|███▎      | 10/30 [1:00:49<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    7/10 [====================>.........]
 33%|███▎      | 10/30 [1:00:49<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 4s - loss: 0.6881 - sparse_categorical_accuracy: 0.7489 - f1_score: 0.8534
 33%|███▎      | 10/30 [1:00:49<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   
 33%|███▎      | 10/30 [1:00:51<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    8/10 [=======================>......]
 33%|███▎      | 10/30 [1:00:51<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 3s - loss: 0.6872 - sparse_categorical_accuracy: 0.7505 - f1_score: 0.8539
 33%|███▎      | 10/30 [1:00:51<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   
 33%|███▎      | 10/30 [1:00:52<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    9/10 [==========================>...]
 33%|███▎      | 10/30 [1:00:52<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 1s - loss: 0.6864 - sparse_categorical_accuracy: 0.7504 - f1_score: 0.8545
 33%|███▎      | 10/30 [1:00:52<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   
 33%|███▎      | 10/30 [1:00:56<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   10/10 [==============================]
 33%|███▎      | 10/30 [1:00:56<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                    - 18s 2s/step - loss: 0.6861 - sparse_categorical_accuracy: 0.7520 - f1_score: 0.8560 - val_loss: 0.6845 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 33%|███▎      | 10/30 [1:00:56<2:09:44, 389.20s/it, best loss: 0.6578827500343323]                                                                                   0.6845457553863525
 33%|███▎      | 10/30 [1:01:51<2:09:44, 389.20s/it, best loss: 0.6578827500343323] 37%|███▋      | 11/30 [1:01:51<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   Layer (type)                 Output Shape              Param #   
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   =================================================================
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_128 (Conv2D)          (None, 299, 299, 45)      1260      
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_129 (Conv2D)          (None, 299, 299, 45)      18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_64 (MaxPooling (None, 149, 149, 45)      0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_64 (Batc (None, 149, 149, 45)      180       
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_130 (Conv2D)          (None, 149, 149, 45)      18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_131 (Conv2D)          (None, 149, 149, 45)      18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_65 (MaxPooling (None, 74, 74, 45)        0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_65 (Batc (None, 74, 74, 45)        180       
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_132 (Conv2D)          (None, 74, 74, 45)        18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_133 (Conv2D)          (None, 74, 74, 45)        18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_66 (MaxPooling (None, 37, 37, 45)        0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_66 (Batc (None, 37, 37, 45)        180       
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_134 (Conv2D)          (None, 37, 37, 45)        18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_135 (Conv2D)          (None, 37, 37, 45)        18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_67 (MaxPooling (None, 18, 18, 45)        0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_67 (Batc (None, 18, 18, 45)        180       
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_136 (Conv2D)          (None, 18, 18, 45)        18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_137 (Conv2D)          (None, 18, 18, 45)        18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_68 (MaxPooling (None, 9, 9, 45)          0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_68 (Batc (None, 9, 9, 45)          180       
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_138 (Conv2D)          (None, 9, 9, 45)          18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_139 (Conv2D)          (None, 9, 9, 45)          18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_69 (MaxPooling (None, 4, 4, 45)          0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_69 (Batc (None, 4, 4, 45)          180       
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_140 (Conv2D)          (None, 4, 4, 45)          18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   conv2d_141 (Conv2D)          (None, 4, 4, 45)          18270     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_70 (MaxPooling (None, 2, 2, 45)          0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_70 (Batc (None, 2, 2, 45)          180       
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   flatten_11 (Flatten)         (None, 180)               0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   dense_44 (Dense)             (None, 65)                11765     
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   dropout_33 (Dropout)         (None, 65)                0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   dense_45 (Dense)             (None, 65)                4290      
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   dropout_34 (Dropout)         (None, 65)                0         
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   dense_46 (Dense)             (None, 2)                 132       
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   =================================================================
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   Total params: 256,217
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   Trainable params: 255,587
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   Non-trainable params: 630
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   None
 37%|███▋      | 11/30 [1:01:55<2:14:00, 423.17s/it, best loss: 0.6578827500343323]2019-04-13 13:10:33.882229: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 37%|███▋      | 11/30 [1:03:29<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    1/10 [==>...........................]
 37%|███▋      | 11/30 [1:07:03<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 32:08 - loss: 1.4191 - sparse_categorical_accuracy: 0.4688 - f1_score: 0.8520
 37%|███▋      | 11/30 [1:07:03<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:07:05<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    2/10 [=====>........................]
 37%|███▋      | 11/30 [1:07:05<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 14:23 - loss: 1.3554 - sparse_categorical_accuracy: 0.4648 - f1_score: 0.8546
 37%|███▋      | 11/30 [1:07:05<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:07:07<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    3/10 [========>.....................]
 37%|███▋      | 11/30 [1:07:07<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 8:27 - loss: 1.2840 - sparse_categorical_accuracy: 0.4635 - f1_score: 0.8503 
 37%|███▋      | 11/30 [1:07:07<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:07:08<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    4/10 [===========>..................]
 37%|███▋      | 11/30 [1:07:08<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 5:28 - loss: 1.2388 - sparse_categorical_accuracy: 0.4678 - f1_score: 0.8545
 37%|███▋      | 11/30 [1:07:08<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:07:10<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    5/10 [==============>...............]
 37%|███▋      | 11/30 [1:07:10<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 3:41 - loss: 1.2008 - sparse_categorical_accuracy: 0.4711 - f1_score: 0.8550
 37%|███▋      | 11/30 [1:07:10<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:07:12<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    6/10 [=================>............]
 37%|███▋      | 11/30 [1:07:12<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 2:28 - loss: 1.1626 - sparse_categorical_accuracy: 0.4746 - f1_score: 0.8545
 37%|███▋      | 11/30 [1:07:12<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:07:13<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    7/10 [====================>.........]
 37%|███▋      | 11/30 [1:07:13<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 1:36 - loss: 1.1102 - sparse_categorical_accuracy: 0.4955 - f1_score: 0.8531
 37%|███▋      | 11/30 [1:07:13<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:07:15<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    8/10 [=======================>......]
 37%|███▋      | 11/30 [1:07:15<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 56s - loss: 1.0805 - sparse_categorical_accuracy: 0.5054 - f1_score: 0.8536 
 37%|███▋      | 11/30 [1:07:15<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:07:17<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    9/10 [==========================>...]
 37%|███▋      | 11/30 [1:07:17<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 25s - loss: 1.0466 - sparse_categorical_accuracy: 0.5169 - f1_score: 0.8514
 37%|███▋      | 11/30 [1:07:17<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:31<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   10/10 [==============================]
 37%|███▋      | 11/30 [1:09:31<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - 362s 36s/step - loss: 1.0190 - sparse_categorical_accuracy: 0.5285 - f1_score: 0.8539 - val_loss: 0.6136 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 37%|███▋      | 11/30 [1:09:31<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   Epoch 2/2
 37%|███▋      | 11/30 [1:09:31<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    1/10 [==>...........................]
 37%|███▋      | 11/30 [1:09:33<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 16s - loss: 0.7391 - sparse_categorical_accuracy: 0.6289 - f1_score: 0.8442
 37%|███▋      | 11/30 [1:09:33<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:34<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    2/10 [=====>........................]
 37%|███▋      | 11/30 [1:09:34<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 14s - loss: 0.7368 - sparse_categorical_accuracy: 0.6309 - f1_score: 0.8442
 37%|███▋      | 11/30 [1:09:34<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:36<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    3/10 [========>.....................]
 37%|███▋      | 11/30 [1:09:36<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 12s - loss: 0.7282 - sparse_categorical_accuracy: 0.6276 - f1_score: 0.8434
 37%|███▋      | 11/30 [1:09:36<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:38<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    4/10 [===========>..................]
 37%|███▋      | 11/30 [1:09:38<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 10s - loss: 0.7322 - sparse_categorical_accuracy: 0.6348 - f1_score: 0.8423
 37%|███▋      | 11/30 [1:09:38<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:40<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    5/10 [==============>...............]
 37%|███▋      | 11/30 [1:09:40<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 8s - loss: 0.7158 - sparse_categorical_accuracy: 0.6383 - f1_score: 0.8478 
 37%|███▋      | 11/30 [1:09:40<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:41<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    6/10 [=================>............]
 37%|███▋      | 11/30 [1:09:41<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 6s - loss: 0.7143 - sparse_categorical_accuracy: 0.6387 - f1_score: 0.8498
 37%|███▋      | 11/30 [1:09:41<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:43<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    7/10 [====================>.........]
 37%|███▋      | 11/30 [1:09:43<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 5s - loss: 0.6973 - sparse_categorical_accuracy: 0.6523 - f1_score: 0.8504
 37%|███▋      | 11/30 [1:09:43<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:45<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    8/10 [=======================>......]
 37%|███▋      | 11/30 [1:09:45<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 3s - loss: 0.6936 - sparse_categorical_accuracy: 0.6499 - f1_score: 0.8513
 37%|███▋      | 11/30 [1:09:45<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:46<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    9/10 [==========================>...]
 37%|███▋      | 11/30 [1:09:46<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 1s - loss: 0.6904 - sparse_categorical_accuracy: 0.6567 - f1_score: 0.8531
 37%|███▋      | 11/30 [1:09:46<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   
 37%|███▋      | 11/30 [1:09:49<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   10/10 [==============================]
 37%|███▋      | 11/30 [1:09:49<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                    - 18s 2s/step - loss: 0.6865 - sparse_categorical_accuracy: 0.6570 - f1_score: 0.8540 - val_loss: 1.4310 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 37%|███▋      | 11/30 [1:09:49<2:14:00, 423.17s/it, best loss: 0.6578827500343323]                                                                                   1.4309885501861572
 37%|███▋      | 11/30 [1:10:56<2:14:00, 423.17s/it, best loss: 0.6578827500343323] 40%|████      | 12/30 [1:10:56<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   Layer (type)                 Output Shape              Param #   
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   =================================================================
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_142 (Conv2D)          (None, 299, 299, 109)     3052      
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_143 (Conv2D)          (None, 299, 299, 109)     107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_71 (MaxPooling (None, 149, 149, 109)     0         
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_71 (Batc (None, 149, 149, 109)     436       
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_144 (Conv2D)          (None, 149, 149, 109)     107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_145 (Conv2D)          (None, 149, 149, 109)     107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_72 (MaxPooling (None, 74, 74, 109)       0         
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_72 (Batc (None, 74, 74, 109)       436       
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_146 (Conv2D)          (None, 74, 74, 109)       107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_147 (Conv2D)          (None, 74, 74, 109)       107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_73 (MaxPooling (None, 37, 37, 109)       0         
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_73 (Batc (None, 37, 37, 109)       436       
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_148 (Conv2D)          (None, 37, 37, 109)       107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_149 (Conv2D)          (None, 37, 37, 109)       107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_74 (MaxPooling (None, 18, 18, 109)       0         
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_74 (Batc (None, 18, 18, 109)       436       
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_150 (Conv2D)          (None, 18, 18, 109)       107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_151 (Conv2D)          (None, 18, 18, 109)       107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_75 (MaxPooling (None, 9, 9, 109)         0         
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_75 (Batc (None, 9, 9, 109)         436       
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_152 (Conv2D)          (None, 9, 9, 109)         107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_153 (Conv2D)          (None, 9, 9, 109)         107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_76 (MaxPooling (None, 4, 4, 109)         0         
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_76 (Batc (None, 4, 4, 109)         436       
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_154 (Conv2D)          (None, 4, 4, 109)         107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   conv2d_155 (Conv2D)          (None, 4, 4, 109)         107038    
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_77 (MaxPooling (None, 2, 2, 109)         0         
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_77 (Batc (None, 2, 2, 109)         436       
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   flatten_12 (Flatten)         (None, 436)               0         
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   dense_47 (Dense)             (None, 64)                27968     
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   dropout_35 (Dropout)         (None, 64)                0         
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   dense_48 (Dense)             (None, 2)                 130       
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   =================================================================
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   Total params: 1,425,696
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   Trainable params: 1,424,170
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   Non-trainable params: 1,526
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   None
 40%|████      | 12/30 [1:11:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323]2019-04-13 13:19:39.621187: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 40%|████      | 12/30 [1:12:49<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    1/10 [==>...........................]
 40%|████      | 12/30 [1:16:44<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 35:14 - loss: 1.3054 - sparse_categorical_accuracy: 0.4531 - f1_score: 0.8622
 40%|████      | 12/30 [1:16:44<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:16:46<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    2/10 [=====>........................]
 40%|████      | 12/30 [1:16:46<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 15:46 - loss: 1.0613 - sparse_categorical_accuracy: 0.5840 - f1_score: 0.8635
 40%|████      | 12/30 [1:16:46<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:16:47<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    3/10 [========>.....................]
 40%|████      | 12/30 [1:16:47<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 9:16 - loss: 0.9462 - sparse_categorical_accuracy: 0.6367 - f1_score: 0.8588 
 40%|████      | 12/30 [1:16:47<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:16:49<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    4/10 [===========>..................]
 40%|████      | 12/30 [1:16:49<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 6:00 - loss: 0.8697 - sparse_categorical_accuracy: 0.6553 - f1_score: 0.8571
 40%|████      | 12/30 [1:16:49<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:16:51<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    5/10 [==============>...............]
 40%|████      | 12/30 [1:16:51<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 4:02 - loss: 0.8209 - sparse_categorical_accuracy: 0.6742 - f1_score: 0.8601
 40%|████      | 12/30 [1:16:51<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:16:53<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    6/10 [=================>............]
 40%|████      | 12/30 [1:16:53<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 2:42 - loss: 0.7606 - sparse_categorical_accuracy: 0.6927 - f1_score: 0.8617
 40%|████      | 12/30 [1:16:53<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:16:55<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    7/10 [====================>.........]
 40%|████      | 12/30 [1:16:55<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 1:45 - loss: 0.7328 - sparse_categorical_accuracy: 0.6987 - f1_score: 0.8622
 40%|████      | 12/30 [1:16:55<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:16:56<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    8/10 [=======================>......]
 40%|████      | 12/30 [1:16:56<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 1:01 - loss: 0.7157 - sparse_categorical_accuracy: 0.7056 - f1_score: 0.8599
 40%|████      | 12/30 [1:16:56<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:16:58<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    9/10 [==========================>...]
 40%|████      | 12/30 [1:16:58<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 27s - loss: 0.7045 - sparse_categorical_accuracy: 0.7114 - f1_score: 0.8602 
 40%|████      | 12/30 [1:16:58<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:24<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   10/10 [==============================]
 40%|████      | 12/30 [1:19:24<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - 395s 40s/step - loss: 0.6740 - sparse_categorical_accuracy: 0.7223 - f1_score: 0.8591 - val_loss: 6.2639 - val_sparse_categorical_accuracy: 0.3667 - val_f1_score: 0.8406

 40%|████      | 12/30 [1:19:24<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   Epoch 2/2
 40%|████      | 12/30 [1:19:24<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    1/10 [==>...........................]
 40%|████      | 12/30 [1:19:26<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 16s - loss: 0.4519 - sparse_categorical_accuracy: 0.8008 - f1_score: 0.8597
 40%|████      | 12/30 [1:19:26<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:28<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    2/10 [=====>........................]
 40%|████      | 12/30 [1:19:28<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 14s - loss: 0.4309 - sparse_categorical_accuracy: 0.8027 - f1_score: 0.8520
 40%|████      | 12/30 [1:19:28<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:30<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    3/10 [========>.....................]
 40%|████      | 12/30 [1:19:30<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 12s - loss: 0.4200 - sparse_categorical_accuracy: 0.8112 - f1_score: 0.8485
 40%|████      | 12/30 [1:19:30<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:32<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    4/10 [===========>..................]
 40%|████      | 12/30 [1:19:32<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 10s - loss: 0.4302 - sparse_categorical_accuracy: 0.8066 - f1_score: 0.8507
 40%|████      | 12/30 [1:19:32<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:33<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    5/10 [==============>...............]
 40%|████      | 12/30 [1:19:33<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 8s - loss: 0.4108 - sparse_categorical_accuracy: 0.8148 - f1_score: 0.8489 
 40%|████      | 12/30 [1:19:33<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:35<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    6/10 [=================>............]
 40%|████      | 12/30 [1:19:35<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 7s - loss: 0.4311 - sparse_categorical_accuracy: 0.8040 - f1_score: 0.8523
 40%|████      | 12/30 [1:19:35<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:37<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    7/10 [====================>.........]
 40%|████      | 12/30 [1:19:37<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 5s - loss: 0.4186 - sparse_categorical_accuracy: 0.8108 - f1_score: 0.8504
 40%|████      | 12/30 [1:19:37<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:39<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    8/10 [=======================>......]
 40%|████      | 12/30 [1:19:39<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 3s - loss: 0.4138 - sparse_categorical_accuracy: 0.8125 - f1_score: 0.8513
 40%|████      | 12/30 [1:19:39<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:40<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    9/10 [==========================>...]
 40%|████      | 12/30 [1:19:40<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 1s - loss: 0.4031 - sparse_categorical_accuracy: 0.8181 - f1_score: 0.8508
 40%|████      | 12/30 [1:19:40<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   
 40%|████      | 12/30 [1:19:44<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   10/10 [==============================]
 40%|████      | 12/30 [1:19:44<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                    - 19s 2s/step - loss: 0.3855 - sparse_categorical_accuracy: 0.8297 - f1_score: 0.8509 - val_loss: 11.4025 - val_sparse_categorical_accuracy: 0.2833 - val_f1_score: 0.8406

 40%|████      | 12/30 [1:19:44<2:17:56, 459.83s/it, best loss: 0.6578827500343323]                                                                                   11.402528762817383
 40%|████      | 12/30 [1:21:01<2:17:56, 459.83s/it, best loss: 0.6578827500343323] 43%|████▎     | 13/30 [1:21:01<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   Layer (type)                 Output Shape              Param #   
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   =================================================================
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_156 (Conv2D)          (None, 299, 299, 2)       56        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_157 (Conv2D)          (None, 299, 299, 2)       38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_78 (MaxPooling (None, 149, 149, 2)       0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_78 (Batc (None, 149, 149, 2)       8         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_158 (Conv2D)          (None, 149, 149, 2)       38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_159 (Conv2D)          (None, 149, 149, 2)       38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_79 (MaxPooling (None, 74, 74, 2)         0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_79 (Batc (None, 74, 74, 2)         8         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_160 (Conv2D)          (None, 74, 74, 2)         38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_161 (Conv2D)          (None, 74, 74, 2)         38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_80 (MaxPooling (None, 37, 37, 2)         0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_80 (Batc (None, 37, 37, 2)         8         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_162 (Conv2D)          (None, 37, 37, 2)         38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_163 (Conv2D)          (None, 37, 37, 2)         38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_81 (MaxPooling (None, 18, 18, 2)         0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_81 (Batc (None, 18, 18, 2)         8         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_164 (Conv2D)          (None, 18, 18, 2)         38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_165 (Conv2D)          (None, 18, 18, 2)         38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_82 (MaxPooling (None, 9, 9, 2)           0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_82 (Batc (None, 9, 9, 2)           8         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_166 (Conv2D)          (None, 9, 9, 2)           38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_167 (Conv2D)          (None, 9, 9, 2)           38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_83 (MaxPooling (None, 4, 4, 2)           0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_83 (Batc (None, 4, 4, 2)           8         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_168 (Conv2D)          (None, 4, 4, 2)           38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_169 (Conv2D)          (None, 4, 4, 2)           38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_84 (MaxPooling (None, 2, 2, 2)           0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_84 (Batc (None, 2, 2, 2)           8         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_170 (Conv2D)          (None, 2, 2, 2)           38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   conv2d_171 (Conv2D)          (None, 2, 2, 2)           38        
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   max_pooling2d_85 (MaxPooling (None, 1, 1, 2)           0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   batch_normalization_85 (Batc (None, 1, 1, 2)           8         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   flatten_13 (Flatten)         (None, 2)                 0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   dense_49 (Dense)             (None, 73)                219       
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   dropout_36 (Dropout)         (None, 73)                0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   dense_50 (Dense)             (None, 73)                5402      
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   dropout_37 (Dropout)         (None, 73)                0         
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   dense_51 (Dense)             (None, 2)                 148       
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   =================================================================
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   Total params: 6,459
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   Trainable params: 6,427
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   Non-trainable params: 32
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   _________________________________________________________________
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   None
 43%|████▎     | 13/30 [1:21:05<2:22:35, 503.27s/it, best loss: 0.6578827500343323]2019-04-13 13:29:43.903980: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 43%|████▎     | 13/30 [1:23:09<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    1/10 [==>...........................]
 43%|████▎     | 13/30 [1:27:19<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 37:35 - loss: 0.8242 - sparse_categorical_accuracy: 0.3281 - f1_score: 0.8416
 43%|████▎     | 13/30 [1:27:19<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:27:21<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    2/10 [=====>........................]
 43%|████▎     | 13/30 [1:27:21<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 16:48 - loss: 0.8270 - sparse_categorical_accuracy: 0.3320 - f1_score: 0.8569
 43%|████▎     | 13/30 [1:27:21<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:27:22<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    3/10 [========>.....................]
 43%|████▎     | 13/30 [1:27:22<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 9:52 - loss: 0.8076 - sparse_categorical_accuracy: 0.3711 - f1_score: 0.8536 
 43%|████▎     | 13/30 [1:27:22<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:27:24<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    4/10 [===========>..................]
 43%|████▎     | 13/30 [1:27:24<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 6:22 - loss: 0.7894 - sparse_categorical_accuracy: 0.3818 - f1_score: 0.8570
 43%|████▎     | 13/30 [1:27:24<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:27:25<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    5/10 [==============>...............]
 43%|████▎     | 13/30 [1:27:25<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 4:16 - loss: 0.7852 - sparse_categorical_accuracy: 0.3937 - f1_score: 0.8550
 43%|████▎     | 13/30 [1:27:25<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:27:27<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    6/10 [=================>............]
 43%|████▎     | 13/30 [1:27:27<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 2:52 - loss: 0.7768 - sparse_categorical_accuracy: 0.4069 - f1_score: 0.8536
 43%|████▎     | 13/30 [1:27:27<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:27:28<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    7/10 [====================>.........]
 43%|████▎     | 13/30 [1:27:28<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 1:51 - loss: 0.7662 - sparse_categorical_accuracy: 0.4263 - f1_score: 0.8523
 43%|████▎     | 13/30 [1:27:28<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:27:30<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    8/10 [=======================>......]
 43%|████▎     | 13/30 [1:27:30<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 1:05 - loss: 0.7569 - sparse_categorical_accuracy: 0.4453 - f1_score: 0.8519
 43%|████▎     | 13/30 [1:27:30<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:27:31<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    9/10 [==========================>...]
 43%|████▎     | 13/30 [1:27:31<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 29s - loss: 0.7477 - sparse_categorical_accuracy: 0.4631 - f1_score: 0.8522 
 43%|████▎     | 13/30 [1:27:31<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:06<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   10/10 [==============================]
 43%|████▎     | 13/30 [1:30:06<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - 418s 42s/step - loss: 0.7411 - sparse_categorical_accuracy: 0.4766 - f1_score: 0.8522 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 43%|████▎     | 13/30 [1:30:06<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   Epoch 2/2
 43%|████▎     | 13/30 [1:30:06<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    1/10 [==>...........................]
 43%|████▎     | 13/30 [1:30:08<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 13s - loss: 0.6680 - sparse_categorical_accuracy: 0.6211 - f1_score: 0.8647
 43%|████▎     | 13/30 [1:30:08<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:09<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    2/10 [=====>........................]
 43%|████▎     | 13/30 [1:30:09<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 11s - loss: 0.6637 - sparse_categorical_accuracy: 0.6172 - f1_score: 0.8597
 43%|████▎     | 13/30 [1:30:09<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:10<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    3/10 [========>.....................]
 43%|████▎     | 13/30 [1:30:10<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 10s - loss: 0.6552 - sparse_categorical_accuracy: 0.6328 - f1_score: 0.8605
 43%|████▎     | 13/30 [1:30:10<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:12<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    4/10 [===========>..................]
 43%|████▎     | 13/30 [1:30:12<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 8s - loss: 0.6501 - sparse_categorical_accuracy: 0.6523 - f1_score: 0.8577 
 43%|████▎     | 13/30 [1:30:12<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:13<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    5/10 [==============>...............]
 43%|████▎     | 13/30 [1:30:13<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 7s - loss: 0.6453 - sparse_categorical_accuracy: 0.6617 - f1_score: 0.8591
 43%|████▎     | 13/30 [1:30:13<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:15<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    6/10 [=================>............]
 43%|████▎     | 13/30 [1:30:15<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 5s - loss: 0.6378 - sparse_categorical_accuracy: 0.6751 - f1_score: 0.8592
 43%|████▎     | 13/30 [1:30:15<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:16<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    7/10 [====================>.........]
 43%|████▎     | 13/30 [1:30:16<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 4s - loss: 0.6374 - sparse_categorical_accuracy: 0.6786 - f1_score: 0.8567
 43%|████▎     | 13/30 [1:30:16<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:18<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    8/10 [=======================>......]
 43%|████▎     | 13/30 [1:30:18<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 2s - loss: 0.6376 - sparse_categorical_accuracy: 0.6899 - f1_score: 0.8590
 43%|████▎     | 13/30 [1:30:18<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:20<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    9/10 [==========================>...]
 43%|████▎     | 13/30 [1:30:20<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - ETA: 1s - loss: 0.6405 - sparse_categorical_accuracy: 0.6888 - f1_score: 0.8565
 43%|████▎     | 13/30 [1:30:20<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   
 43%|████▎     | 13/30 [1:30:23<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   10/10 [==============================]
 43%|████▎     | 13/30 [1:30:23<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                    - 17s 2s/step - loss: 0.6424 - sparse_categorical_accuracy: 0.6906 - f1_score: 0.8552 - val_loss: 0.6456 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 43%|████▎     | 13/30 [1:30:23<2:22:35, 503.27s/it, best loss: 0.6578827500343323]                                                                                   0.6456168293952942
 43%|████▎     | 13/30 [1:31:51<2:22:35, 503.27s/it, best loss: 0.6578827500343323] 47%|████▋     | 14/30 [1:31:51<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   Layer (type)                 Output Shape              Param #   
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_172 (Conv2D)          (None, 299, 299, 103)     2884      
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_173 (Conv2D)          (None, 299, 299, 103)     95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_86 (MaxPooling (None, 149, 149, 103)     0         
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_86 (Batc (None, 149, 149, 103)     412       
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_174 (Conv2D)          (None, 149, 149, 103)     95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_175 (Conv2D)          (None, 149, 149, 103)     95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_87 (MaxPooling (None, 74, 74, 103)       0         
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_87 (Batc (None, 74, 74, 103)       412       
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_176 (Conv2D)          (None, 74, 74, 103)       95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_177 (Conv2D)          (None, 74, 74, 103)       95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_88 (MaxPooling (None, 37, 37, 103)       0         
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_88 (Batc (None, 37, 37, 103)       412       
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_178 (Conv2D)          (None, 37, 37, 103)       95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_179 (Conv2D)          (None, 37, 37, 103)       95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_89 (MaxPooling (None, 18, 18, 103)       0         
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_89 (Batc (None, 18, 18, 103)       412       
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_180 (Conv2D)          (None, 18, 18, 103)       95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_181 (Conv2D)          (None, 18, 18, 103)       95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_90 (MaxPooling (None, 9, 9, 103)         0         
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_90 (Batc (None, 9, 9, 103)         412       
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_182 (Conv2D)          (None, 9, 9, 103)         95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   conv2d_183 (Conv2D)          (None, 9, 9, 103)         95584     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_91 (MaxPooling (None, 4, 4, 103)         0         
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_91 (Batc (None, 4, 4, 103)         412       
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   flatten_14 (Flatten)         (None, 1648)              0         
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   dense_52 (Dense)             (None, 29)                47821     
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   dropout_38 (Dropout)         (None, 29)                0         
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   dense_53 (Dense)             (None, 2)                 60        
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   Total params: 1,104,661
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   Trainable params: 1,103,425
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   Non-trainable params: 1,236
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   None
 47%|████▋     | 14/30 [1:31:55<2:25:57, 547.32s/it, best loss: 0.6456168293952942]2019-04-13 13:40:33.993236: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 47%|████▋     | 14/30 [1:34:21<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 47%|████▋     | 14/30 [1:38:49<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 40:09 - loss: 1.3823 - sparse_categorical_accuracy: 0.5391 - f1_score: 0.8390
 47%|████▋     | 14/30 [1:38:49<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:38:50<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 47%|████▋     | 14/30 [1:38:50<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 17:58 - loss: 1.1063 - sparse_categorical_accuracy: 0.6172 - f1_score: 0.8481
 47%|████▋     | 14/30 [1:38:50<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:38:52<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 47%|████▋     | 14/30 [1:38:52<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 10:33 - loss: 0.9678 - sparse_categorical_accuracy: 0.6523 - f1_score: 0.8450
 47%|████▋     | 14/30 [1:38:52<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:38:54<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 47%|████▋     | 14/30 [1:38:54<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 6:49 - loss: 0.8972 - sparse_categorical_accuracy: 0.6553 - f1_score: 0.8487 
 47%|████▋     | 14/30 [1:38:54<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:38:56<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 47%|████▋     | 14/30 [1:38:56<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 4:34 - loss: 0.8283 - sparse_categorical_accuracy: 0.6750 - f1_score: 0.8468
 47%|████▋     | 14/30 [1:38:56<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:38:57<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 47%|████▋     | 14/30 [1:38:57<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3:04 - loss: 0.7828 - sparse_categorical_accuracy: 0.6868 - f1_score: 0.8493
 47%|████▋     | 14/30 [1:38:57<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:38:59<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 47%|████▋     | 14/30 [1:38:59<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1:59 - loss: 0.7660 - sparse_categorical_accuracy: 0.6897 - f1_score: 0.8494
 47%|████▋     | 14/30 [1:38:59<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:39:01<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 47%|████▋     | 14/30 [1:39:01<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1:09 - loss: 0.7411 - sparse_categorical_accuracy: 0.6948 - f1_score: 0.8510
 47%|████▋     | 14/30 [1:39:01<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:39:03<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 47%|████▋     | 14/30 [1:39:03<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 31s - loss: 0.7200 - sparse_categorical_accuracy: 0.7018 - f1_score: 0.8528 
 47%|████▋     | 14/30 [1:39:03<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:41:56<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 47%|████▋     | 14/30 [1:41:56<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - 456s 46s/step - loss: 0.7084 - sparse_categorical_accuracy: 0.7047 - f1_score: 0.8511 - val_loss: 3.4629 - val_sparse_categorical_accuracy: 0.7375 - val_f1_score: 0.8406

 47%|████▋     | 14/30 [1:41:56<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   Epoch 2/2
 47%|████▋     | 14/30 [1:41:56<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 47%|████▋     | 14/30 [1:41:58<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 15s - loss: 0.5087 - sparse_categorical_accuracy: 0.7422 - f1_score: 0.8647
 47%|████▋     | 14/30 [1:41:58<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:42:00<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 47%|████▋     | 14/30 [1:42:00<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 13s - loss: 0.5136 - sparse_categorical_accuracy: 0.7500 - f1_score: 0.8609
 47%|████▋     | 14/30 [1:42:00<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:42:02<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 47%|████▋     | 14/30 [1:42:02<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 12s - loss: 0.5172 - sparse_categorical_accuracy: 0.7565 - f1_score: 0.8630
 47%|████▋     | 14/30 [1:42:02<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:42:03<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 47%|████▋     | 14/30 [1:42:03<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 10s - loss: 0.5036 - sparse_categorical_accuracy: 0.7588 - f1_score: 0.8590
 47%|████▋     | 14/30 [1:42:03<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:42:05<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 47%|████▋     | 14/30 [1:42:05<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 8s - loss: 0.4981 - sparse_categorical_accuracy: 0.7578 - f1_score: 0.8571 
 47%|████▋     | 14/30 [1:42:05<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:42:07<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 47%|████▋     | 14/30 [1:42:07<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 6s - loss: 0.4994 - sparse_categorical_accuracy: 0.7591 - f1_score: 0.8584
 47%|████▋     | 14/30 [1:42:07<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:42:08<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 47%|████▋     | 14/30 [1:42:08<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 5s - loss: 0.4932 - sparse_categorical_accuracy: 0.7640 - f1_score: 0.8596
 47%|████▋     | 14/30 [1:42:08<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:42:10<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 47%|████▋     | 14/30 [1:42:10<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3s - loss: 0.4877 - sparse_categorical_accuracy: 0.7656 - f1_score: 0.8571
 47%|████▋     | 14/30 [1:42:10<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:42:12<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 47%|████▋     | 14/30 [1:42:12<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1s - loss: 0.4863 - sparse_categorical_accuracy: 0.7643 - f1_score: 0.8571
 47%|████▋     | 14/30 [1:42:12<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   
 47%|████▋     | 14/30 [1:42:15<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 47%|████▋     | 14/30 [1:42:15<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                    - 19s 2s/step - loss: 0.4805 - sparse_categorical_accuracy: 0.7668 - f1_score: 0.8573 - val_loss: 4.0705 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 47%|████▋     | 14/30 [1:42:15<2:25:57, 547.32s/it, best loss: 0.6456168293952942]                                                                                   4.07049560546875
 47%|████▋     | 14/30 [1:43:56<2:25:57, 547.32s/it, best loss: 0.6456168293952942] 50%|█████     | 15/30 [1:43:56<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   Layer (type)                 Output Shape              Param #   
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_184 (Conv2D)          (None, 299, 299, 97)      2716      
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_185 (Conv2D)          (None, 299, 299, 97)      84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_92 (MaxPooling (None, 149, 149, 97)      0         
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_92 (Batc (None, 149, 149, 97)      388       
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_186 (Conv2D)          (None, 149, 149, 97)      84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_187 (Conv2D)          (None, 149, 149, 97)      84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_93 (MaxPooling (None, 74, 74, 97)        0         
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_93 (Batc (None, 74, 74, 97)        388       
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_188 (Conv2D)          (None, 74, 74, 97)        84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_189 (Conv2D)          (None, 74, 74, 97)        84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_94 (MaxPooling (None, 37, 37, 97)        0         
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_94 (Batc (None, 37, 37, 97)        388       
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_190 (Conv2D)          (None, 37, 37, 97)        84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_191 (Conv2D)          (None, 37, 37, 97)        84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_95 (MaxPooling (None, 18, 18, 97)        0         
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_95 (Batc (None, 18, 18, 97)        388       
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_192 (Conv2D)          (None, 18, 18, 97)        84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_193 (Conv2D)          (None, 18, 18, 97)        84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_96 (MaxPooling (None, 9, 9, 97)          0         
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_96 (Batc (None, 9, 9, 97)          388       
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_194 (Conv2D)          (None, 9, 9, 97)          84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   conv2d_195 (Conv2D)          (None, 9, 9, 97)          84778     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_97 (MaxPooling (None, 4, 4, 97)          0         
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_97 (Batc (None, 4, 4, 97)          388       
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   flatten_15 (Flatten)         (None, 1552)              0         
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   dense_54 (Dense)             (None, 21)                32613     
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   dropout_39 (Dropout)         (None, 21)                0         
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   dense_55 (Dense)             (None, 21)                462       
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   dropout_40 (Dropout)         (None, 21)                0         
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   dense_56 (Dense)             (None, 2)                 44        
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   Total params: 970,721
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   Trainable params: 969,557
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   Non-trainable params: 1,164
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   None
 50%|█████     | 15/30 [1:44:00<2:30:08, 600.55s/it, best loss: 0.6456168293952942]2019-04-13 13:52:38.338725: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 50%|█████     | 15/30 [1:46:38<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 50%|█████     | 15/30 [1:51:26<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 43:06 - loss: 0.7540 - sparse_categorical_accuracy: 0.6250 - f1_score: 0.8673
 50%|█████     | 15/30 [1:51:26<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:51:27<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 50%|█████     | 15/30 [1:51:27<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 19:16 - loss: 0.6922 - sparse_categorical_accuracy: 0.6680 - f1_score: 0.8583
 50%|█████     | 15/30 [1:51:27<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:51:29<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 50%|█████     | 15/30 [1:51:29<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 11:18 - loss: 0.6437 - sparse_categorical_accuracy: 0.6953 - f1_score: 0.8554
 50%|█████     | 15/30 [1:51:29<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:51:31<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 50%|█████     | 15/30 [1:51:31<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 7:18 - loss: 0.6693 - sparse_categorical_accuracy: 0.6982 - f1_score: 0.8545 
 50%|█████     | 15/30 [1:51:31<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:51:32<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 50%|█████     | 15/30 [1:51:32<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 4:53 - loss: 0.6547 - sparse_categorical_accuracy: 0.7016 - f1_score: 0.8571
 50%|█████     | 15/30 [1:51:32<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:51:34<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 50%|█████     | 15/30 [1:51:34<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3:16 - loss: 0.6285 - sparse_categorical_accuracy: 0.7188 - f1_score: 0.8596
 50%|█████     | 15/30 [1:51:34<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:51:36<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 50%|█████     | 15/30 [1:51:36<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 2:07 - loss: 0.6118 - sparse_categorical_accuracy: 0.7249 - f1_score: 0.8589
 50%|█████     | 15/30 [1:51:36<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:51:37<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 50%|█████     | 15/30 [1:51:37<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1:14 - loss: 0.5932 - sparse_categorical_accuracy: 0.7290 - f1_score: 0.8596
 50%|█████     | 15/30 [1:51:37<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:51:39<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 50%|█████     | 15/30 [1:51:39<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 33s - loss: 0.5753 - sparse_categorical_accuracy: 0.7374 - f1_score: 0.8593 
 50%|█████     | 15/30 [1:51:39<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:37<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 50%|█████     | 15/30 [1:54:37<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - 479s 48s/step - loss: 0.5602 - sparse_categorical_accuracy: 0.7438 - f1_score: 0.8596 - val_loss: 1.9730 - val_sparse_categorical_accuracy: 0.6667 - val_f1_score: 0.8406

 50%|█████     | 15/30 [1:54:37<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   Epoch 2/2
 50%|█████     | 15/30 [1:54:37<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 50%|█████     | 15/30 [1:54:39<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 15s - loss: 0.3477 - sparse_categorical_accuracy: 0.8320 - f1_score: 0.8747
 50%|█████     | 15/30 [1:54:39<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:40<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 50%|█████     | 15/30 [1:54:40<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 13s - loss: 0.3716 - sparse_categorical_accuracy: 0.8359 - f1_score: 0.8608
 50%|█████     | 15/30 [1:54:40<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:42<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 50%|█████     | 15/30 [1:54:42<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 11s - loss: 0.3824 - sparse_categorical_accuracy: 0.8294 - f1_score: 0.8638
 50%|█████     | 15/30 [1:54:42<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:44<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 50%|█████     | 15/30 [1:54:44<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 9s - loss: 0.3762 - sparse_categorical_accuracy: 0.8301 - f1_score: 0.8646 
 50%|█████     | 15/30 [1:54:44<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:45<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 50%|█████     | 15/30 [1:54:45<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 8s - loss: 0.3739 - sparse_categorical_accuracy: 0.8289 - f1_score: 0.8652
 50%|█████     | 15/30 [1:54:45<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:47<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 50%|█████     | 15/30 [1:54:47<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 6s - loss: 0.3615 - sparse_categorical_accuracy: 0.8379 - f1_score: 0.8651
 50%|█████     | 15/30 [1:54:47<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:49<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 50%|█████     | 15/30 [1:54:49<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 4s - loss: 0.3478 - sparse_categorical_accuracy: 0.8421 - f1_score: 0.8654
 50%|█████     | 15/30 [1:54:49<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:50<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 50%|█████     | 15/30 [1:54:50<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3s - loss: 0.3402 - sparse_categorical_accuracy: 0.8462 - f1_score: 0.8650
 50%|█████     | 15/30 [1:54:50<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:52<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 50%|█████     | 15/30 [1:54:52<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1s - loss: 0.3498 - sparse_categorical_accuracy: 0.8411 - f1_score: 0.8618
 50%|█████     | 15/30 [1:54:52<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   
 50%|█████     | 15/30 [1:54:55<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 50%|█████     | 15/30 [1:54:55<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                    - 18s 2s/step - loss: 0.3391 - sparse_categorical_accuracy: 0.8453 - f1_score: 0.8629 - val_loss: 5.9354 - val_sparse_categorical_accuracy: 0.4250 - val_f1_score: 0.8406

 50%|█████     | 15/30 [1:54:55<2:30:08, 600.55s/it, best loss: 0.6456168293952942]                                                                                   5.93539571762085
 50%|█████     | 15/30 [1:56:43<2:30:08, 600.55s/it, best loss: 0.6456168293952942] 53%|█████▎    | 16/30 [1:56:43<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   Layer (type)                 Output Shape              Param #   
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_196 (Conv2D)          (None, 299, 299, 110)     3080      
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_197 (Conv2D)          (None, 299, 299, 110)     109010    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_98 (MaxPooling (None, 149, 149, 110)     0         
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_98 (Batc (None, 149, 149, 110)     440       
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_198 (Conv2D)          (None, 149, 149, 110)     109010    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_199 (Conv2D)          (None, 149, 149, 110)     109010    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_99 (MaxPooling (None, 74, 74, 110)       0         
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_99 (Batc (None, 74, 74, 110)       440       
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_200 (Conv2D)          (None, 74, 74, 110)       109010    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_201 (Conv2D)          (None, 74, 74, 110)       109010    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_100 (MaxPoolin (None, 37, 37, 110)       0         
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_100 (Bat (None, 37, 37, 110)       440       
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_202 (Conv2D)          (None, 37, 37, 110)       109010    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_203 (Conv2D)          (None, 37, 37, 110)       109010    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_101 (MaxPoolin (None, 18, 18, 110)       0         
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_101 (Bat (None, 18, 18, 110)       440       
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_204 (Conv2D)          (None, 18, 18, 110)       109010    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   conv2d_205 (Conv2D)          (None, 18, 18, 110)       109010    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_102 (MaxPoolin (None, 9, 9, 110)         0         
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_102 (Bat (None, 9, 9, 110)         440       
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   flatten_16 (Flatten)         (None, 8910)              0         
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   dense_57 (Dense)             (None, 51)                454461    
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   dropout_41 (Dropout)         (None, 51)                0         
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   dense_58 (Dense)             (None, 51)                2652      
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   dropout_42 (Dropout)         (None, 51)                0         
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   dense_59 (Dense)             (None, 2)                 104       
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   Total params: 1,443,587
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   Trainable params: 1,442,487
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   Non-trainable params: 1,100
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   None
 53%|█████▎    | 16/30 [1:56:48<2:31:50, 650.73s/it, best loss: 0.6456168293952942]2019-04-13 14:05:26.349768: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 53%|█████▎    | 16/30 [1:59:42<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 53%|█████▎    | 16/30 [2:04:42<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 44:56 - loss: 0.6615 - sparse_categorical_accuracy: 0.6523 - f1_score: 0.8364
 53%|█████▎    | 16/30 [2:04:42<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:04:43<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 53%|█████▎    | 16/30 [2:04:43<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 20:05 - loss: 0.8172 - sparse_categorical_accuracy: 0.6914 - f1_score: 0.8468
 53%|█████▎    | 16/30 [2:04:43<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:04:45<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 53%|█████▎    | 16/30 [2:04:45<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 11:47 - loss: 0.7109 - sparse_categorical_accuracy: 0.7161 - f1_score: 0.8502
 53%|█████▎    | 16/30 [2:04:45<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:04:47<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 53%|█████▎    | 16/30 [2:04:47<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 7:37 - loss: 0.6656 - sparse_categorical_accuracy: 0.7178 - f1_score: 0.8500 
 53%|█████▎    | 16/30 [2:04:47<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:04:49<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 53%|█████▎    | 16/30 [2:04:49<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 5:06 - loss: 0.6365 - sparse_categorical_accuracy: 0.7297 - f1_score: 0.8514
 53%|█████▎    | 16/30 [2:04:49<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:04:51<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 53%|█████▎    | 16/30 [2:04:51<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3:25 - loss: 0.6006 - sparse_categorical_accuracy: 0.7396 - f1_score: 0.8489
 53%|█████▎    | 16/30 [2:04:51<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:04:52<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 53%|█████▎    | 16/30 [2:04:52<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 2:13 - loss: 0.5825 - sparse_categorical_accuracy: 0.7455 - f1_score: 0.8519
 53%|█████▎    | 16/30 [2:04:52<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:04:54<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 53%|█████▎    | 16/30 [2:04:54<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1:18 - loss: 0.5520 - sparse_categorical_accuracy: 0.7593 - f1_score: 0.8541
 53%|█████▎    | 16/30 [2:04:54<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:04:56<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 53%|█████▎    | 16/30 [2:04:56<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 34s - loss: 0.5253 - sparse_categorical_accuracy: 0.7713 - f1_score: 0.8550 
 53%|█████▎    | 16/30 [2:04:56<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:02<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 53%|█████▎    | 16/30 [2:08:02<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - 499s 50s/step - loss: 0.5073 - sparse_categorical_accuracy: 0.7789 - f1_score: 0.8552 - val_loss: 1.3868 - val_sparse_categorical_accuracy: 0.6625 - val_f1_score: 0.8406

 53%|█████▎    | 16/30 [2:08:02<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   Epoch 2/2
 53%|█████▎    | 16/30 [2:08:02<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 53%|█████▎    | 16/30 [2:08:03<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 16s - loss: 0.3713 - sparse_categorical_accuracy: 0.8281 - f1_score: 0.8468
 53%|█████▎    | 16/30 [2:08:03<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:05<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 53%|█████▎    | 16/30 [2:08:05<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 14s - loss: 0.3087 - sparse_categorical_accuracy: 0.8730 - f1_score: 0.8583
 53%|█████▎    | 16/30 [2:08:05<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:07<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 53%|█████▎    | 16/30 [2:08:07<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 12s - loss: 0.2796 - sparse_categorical_accuracy: 0.8867 - f1_score: 0.8545
 53%|█████▎    | 16/30 [2:08:07<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:09<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 53%|█████▎    | 16/30 [2:08:09<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 10s - loss: 0.2647 - sparse_categorical_accuracy: 0.8955 - f1_score: 0.8506
 53%|█████▎    | 16/30 [2:08:09<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:10<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 53%|█████▎    | 16/30 [2:08:10<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 8s - loss: 0.2435 - sparse_categorical_accuracy: 0.9062 - f1_score: 0.8549 
 53%|█████▎    | 16/30 [2:08:10<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:12<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 53%|█████▎    | 16/30 [2:08:12<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 7s - loss: 0.2343 - sparse_categorical_accuracy: 0.9082 - f1_score: 0.8574
 53%|█████▎    | 16/30 [2:08:12<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:14<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 53%|█████▎    | 16/30 [2:08:14<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 5s - loss: 0.2266 - sparse_categorical_accuracy: 0.9107 - f1_score: 0.8592
 53%|█████▎    | 16/30 [2:08:14<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:16<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 53%|█████▎    | 16/30 [2:08:16<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3s - loss: 0.2169 - sparse_categorical_accuracy: 0.9146 - f1_score: 0.8580
 53%|█████▎    | 16/30 [2:08:16<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:18<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 53%|█████▎    | 16/30 [2:08:18<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1s - loss: 0.2109 - sparse_categorical_accuracy: 0.9188 - f1_score: 0.8564
 53%|█████▎    | 16/30 [2:08:18<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   
 53%|█████▎    | 16/30 [2:08:22<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 53%|█████▎    | 16/30 [2:08:22<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                    - 20s 2s/step - loss: 0.2156 - sparse_categorical_accuracy: 0.9168 - f1_score: 0.8562 - val_loss: 3.6589 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 53%|█████▎    | 16/30 [2:08:22<2:31:50, 650.73s/it, best loss: 0.6456168293952942]                                                                                   3.658870220184326
 53%|█████▎    | 16/30 [2:10:23<2:31:50, 650.73s/it, best loss: 0.6456168293952942] 57%|█████▋    | 17/30 [2:10:23<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   Layer (type)                 Output Shape              Param #   
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   conv2d_206 (Conv2D)          (None, 299, 299, 80)      2240      
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   conv2d_207 (Conv2D)          (None, 299, 299, 80)      57680     
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_103 (MaxPoolin (None, 149, 149, 80)      0         
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_103 (Bat (None, 149, 149, 80)      320       
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   conv2d_208 (Conv2D)          (None, 149, 149, 80)      57680     
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   conv2d_209 (Conv2D)          (None, 149, 149, 80)      57680     
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_104 (MaxPoolin (None, 74, 74, 80)        0         
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_104 (Bat (None, 74, 74, 80)        320       
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   conv2d_210 (Conv2D)          (None, 74, 74, 80)        57680     
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   conv2d_211 (Conv2D)          (None, 74, 74, 80)        57680     
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_105 (MaxPoolin (None, 37, 37, 80)        0         
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_105 (Bat (None, 37, 37, 80)        320       
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   conv2d_212 (Conv2D)          (None, 37, 37, 80)        57680     
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   conv2d_213 (Conv2D)          (None, 37, 37, 80)        57680     
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_106 (MaxPoolin (None, 18, 18, 80)        0         
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_106 (Bat (None, 18, 18, 80)        320       
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   flatten_17 (Flatten)         (None, 25920)             0         
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   dense_60 (Dense)             (None, 24)                622104    
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   dropout_43 (Dropout)         (None, 24)                0         
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   dense_61 (Dense)             (None, 24)                600       
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   dropout_44 (Dropout)         (None, 24)                0         
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   dense_62 (Dense)             (None, 2)                 50        
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   Total params: 1,030,034
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   Trainable params: 1,029,394
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   Non-trainable params: 640
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   None
 57%|█████▋    | 17/30 [2:10:28<2:31:57, 701.37s/it, best loss: 0.6456168293952942]2019-04-13 14:19:06.153100: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 57%|█████▋    | 17/30 [2:13:43<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 57%|█████▋    | 17/30 [2:18:54<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 46:39 - loss: 1.9380 - sparse_categorical_accuracy: 0.3164 - f1_score: 0.8390
 57%|█████▋    | 17/30 [2:18:54<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:18:56<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 57%|█████▋    | 17/30 [2:18:56<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 20:51 - loss: 1.6854 - sparse_categorical_accuracy: 0.4375 - f1_score: 0.8416
 57%|█████▋    | 17/30 [2:18:56<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:18:58<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 57%|█████▋    | 17/30 [2:18:58<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 12:14 - loss: 1.5029 - sparse_categorical_accuracy: 0.4948 - f1_score: 0.8493
 57%|█████▋    | 17/30 [2:18:58<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:19:00<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 57%|█████▋    | 17/30 [2:19:00<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 7:54 - loss: 1.4069 - sparse_categorical_accuracy: 0.5049 - f1_score: 0.8500 
 57%|█████▋    | 17/30 [2:19:00<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:19:02<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 57%|█████▋    | 17/30 [2:19:02<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 5:18 - loss: 1.3090 - sparse_categorical_accuracy: 0.5297 - f1_score: 0.8535
 57%|█████▋    | 17/30 [2:19:02<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:19:03<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 57%|█████▋    | 17/30 [2:19:03<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3:33 - loss: 1.2161 - sparse_categorical_accuracy: 0.5547 - f1_score: 0.8532
 57%|█████▋    | 17/30 [2:19:03<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:19:05<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 57%|█████▋    | 17/30 [2:19:05<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 2:17 - loss: 1.1430 - sparse_categorical_accuracy: 0.5792 - f1_score: 0.8552
 57%|█████▋    | 17/30 [2:19:05<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:19:07<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 57%|█████▋    | 17/30 [2:19:07<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1:20 - loss: 1.0905 - sparse_categorical_accuracy: 0.5947 - f1_score: 0.8548
 57%|█████▋    | 17/30 [2:19:07<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:19:09<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 57%|█████▋    | 17/30 [2:19:09<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 36s - loss: 1.0408 - sparse_categorical_accuracy: 0.6141 - f1_score: 0.8531 
 57%|█████▋    | 17/30 [2:19:09<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:33<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 57%|█████▋    | 17/30 [2:22:33<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - 529s 53s/step - loss: 1.0127 - sparse_categorical_accuracy: 0.6254 - f1_score: 0.8527 - val_loss: 2.8682 - val_sparse_categorical_accuracy: 0.7167 - val_f1_score: 0.8406

 57%|█████▋    | 17/30 [2:22:33<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   Epoch 2/2
 57%|█████▋    | 17/30 [2:22:33<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 57%|█████▋    | 17/30 [2:22:34<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 15s - loss: 0.6415 - sparse_categorical_accuracy: 0.7461 - f1_score: 0.8546
 57%|█████▋    | 17/30 [2:22:34<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:36<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 57%|█████▋    | 17/30 [2:22:36<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 14s - loss: 0.6998 - sparse_categorical_accuracy: 0.7305 - f1_score: 0.8609
 57%|█████▋    | 17/30 [2:22:36<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:38<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 57%|█████▋    | 17/30 [2:22:38<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 12s - loss: 0.6969 - sparse_categorical_accuracy: 0.7253 - f1_score: 0.8605
 57%|█████▋    | 17/30 [2:22:38<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:40<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 57%|█████▋    | 17/30 [2:22:40<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 10s - loss: 0.6803 - sparse_categorical_accuracy: 0.7227 - f1_score: 0.8577
 57%|█████▋    | 17/30 [2:22:40<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:41<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 57%|█████▋    | 17/30 [2:22:41<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 8s - loss: 0.6891 - sparse_categorical_accuracy: 0.7250 - f1_score: 0.8571 
 57%|█████▋    | 17/30 [2:22:41<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:43<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 57%|█████▋    | 17/30 [2:22:43<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 7s - loss: 0.6862 - sparse_categorical_accuracy: 0.7279 - f1_score: 0.8563
 57%|█████▋    | 17/30 [2:22:43<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:45<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 57%|█████▋    | 17/30 [2:22:45<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 5s - loss: 0.7066 - sparse_categorical_accuracy: 0.7294 - f1_score: 0.8578
 57%|█████▋    | 17/30 [2:22:45<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:47<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 57%|█████▋    | 17/30 [2:22:47<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3s - loss: 0.6927 - sparse_categorical_accuracy: 0.7329 - f1_score: 0.8561
 57%|█████▋    | 17/30 [2:22:47<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:48<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 57%|█████▋    | 17/30 [2:22:48<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1s - loss: 0.6841 - sparse_categorical_accuracy: 0.7352 - f1_score: 0.8560
 57%|█████▋    | 17/30 [2:22:48<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   
 57%|█████▋    | 17/30 [2:22:52<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 57%|█████▋    | 17/30 [2:22:52<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                    - 19s 2s/step - loss: 0.6732 - sparse_categorical_accuracy: 0.7375 - f1_score: 0.8556 - val_loss: 5.0888 - val_sparse_categorical_accuracy: 0.5375 - val_f1_score: 0.8406

 57%|█████▋    | 17/30 [2:22:52<2:31:57, 701.37s/it, best loss: 0.6456168293952942]                                                                                   5.088830947875977
 57%|█████▋    | 17/30 [2:25:04<2:31:57, 701.37s/it, best loss: 0.6456168293952942] 60%|██████    | 18/30 [2:25:04<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   Layer (type)                 Output Shape              Param #   
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_214 (Conv2D)          (None, 299, 299, 39)      1092      
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_215 (Conv2D)          (None, 299, 299, 39)      13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_107 (MaxPoolin (None, 149, 149, 39)      0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_107 (Bat (None, 149, 149, 39)      156       
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_216 (Conv2D)          (None, 149, 149, 39)      13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_217 (Conv2D)          (None, 149, 149, 39)      13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_108 (MaxPoolin (None, 74, 74, 39)        0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_108 (Bat (None, 74, 74, 39)        156       
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_218 (Conv2D)          (None, 74, 74, 39)        13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_219 (Conv2D)          (None, 74, 74, 39)        13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_109 (MaxPoolin (None, 37, 37, 39)        0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_109 (Bat (None, 37, 37, 39)        156       
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_220 (Conv2D)          (None, 37, 37, 39)        13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_221 (Conv2D)          (None, 37, 37, 39)        13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_110 (MaxPoolin (None, 18, 18, 39)        0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_110 (Bat (None, 18, 18, 39)        156       
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_222 (Conv2D)          (None, 18, 18, 39)        13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_223 (Conv2D)          (None, 18, 18, 39)        13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_111 (MaxPoolin (None, 9, 9, 39)          0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_111 (Bat (None, 9, 9, 39)          156       
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_224 (Conv2D)          (None, 9, 9, 39)          13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_225 (Conv2D)          (None, 9, 9, 39)          13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_112 (MaxPoolin (None, 4, 4, 39)          0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_112 (Bat (None, 4, 4, 39)          156       
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_226 (Conv2D)          (None, 4, 4, 39)          13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   conv2d_227 (Conv2D)          (None, 4, 4, 39)          13728     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   max_pooling2d_113 (MaxPoolin (None, 2, 2, 39)          0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   batch_normalization_113 (Bat (None, 2, 2, 39)          156       
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   flatten_18 (Flatten)         (None, 156)               0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   dense_63 (Dense)             (None, 70)                10990     
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   dropout_45 (Dropout)         (None, 70)                0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   dense_64 (Dense)             (None, 70)                4970      
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   dropout_46 (Dropout)         (None, 70)                0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   dense_65 (Dense)             (None, 70)                4970      
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   dropout_47 (Dropout)         (None, 70)                0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   dense_66 (Dense)             (None, 70)                4970      
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   dropout_48 (Dropout)         (None, 70)                0         
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   dense_67 (Dense)             (None, 2)                 142       
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   =================================================================
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   Total params: 206,690
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   Trainable params: 206,144
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   Non-trainable params: 546
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   _________________________________________________________________
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   None
 60%|██████    | 18/30 [2:25:09<2:31:01, 755.14s/it, best loss: 0.6456168293952942]2019-04-13 14:33:47.659489: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 60%|██████    | 18/30 [2:28:37<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 60%|██████    | 18/30 [2:34:17<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 51:01 - loss: 1.2908 - sparse_categorical_accuracy: 0.5742 - f1_score: 0.8597
 60%|██████    | 18/30 [2:34:17<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:34:19<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 60%|██████    | 18/30 [2:34:19<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 22:47 - loss: 1.3847 - sparse_categorical_accuracy: 0.5566 - f1_score: 0.8635
 60%|██████    | 18/30 [2:34:19<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:34:21<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 60%|██████    | 18/30 [2:34:21<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 13:21 - loss: 1.3805 - sparse_categorical_accuracy: 0.5560 - f1_score: 0.8622
 60%|██████    | 18/30 [2:34:21<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:34:23<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 60%|██████    | 18/30 [2:34:23<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 8:37 - loss: 1.3128 - sparse_categorical_accuracy: 0.5605 - f1_score: 0.8635 
 60%|██████    | 18/30 [2:34:23<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:34:24<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 60%|██████    | 18/30 [2:34:24<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 5:46 - loss: 1.2928 - sparse_categorical_accuracy: 0.5586 - f1_score: 0.8591
 60%|██████    | 18/30 [2:34:24<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:34:26<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 60%|██████    | 18/30 [2:34:26<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3:52 - loss: 1.2518 - sparse_categorical_accuracy: 0.5632 - f1_score: 0.8588
 60%|██████    | 18/30 [2:34:26<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:34:28<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 60%|██████    | 18/30 [2:34:28<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 2:30 - loss: 1.2237 - sparse_categorical_accuracy: 0.5647 - f1_score: 0.8593
 60%|██████    | 18/30 [2:34:28<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:34:29<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 60%|██████    | 18/30 [2:34:29<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1:27 - loss: 1.2001 - sparse_categorical_accuracy: 0.5684 - f1_score: 0.8600
 60%|██████    | 18/30 [2:34:29<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:34:31<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 60%|██████    | 18/30 [2:34:31<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 39s - loss: 1.1570 - sparse_categorical_accuracy: 0.5729 - f1_score: 0.8582 
 60%|██████    | 18/30 [2:34:31<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:10<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 60%|██████    | 18/30 [2:38:10<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - 573s 57s/step - loss: 1.1367 - sparse_categorical_accuracy: 0.5785 - f1_score: 0.8578 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 60%|██████    | 18/30 [2:38:10<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   Epoch 2/2
 60%|██████    | 18/30 [2:38:10<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    1/10 [==>...........................]
 60%|██████    | 18/30 [2:38:12<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 16s - loss: 0.8386 - sparse_categorical_accuracy: 0.6758 - f1_score: 0.8647
 60%|██████    | 18/30 [2:38:12<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:13<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    2/10 [=====>........................]
 60%|██████    | 18/30 [2:38:13<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 14s - loss: 0.8662 - sparse_categorical_accuracy: 0.6777 - f1_score: 0.8647
 60%|██████    | 18/30 [2:38:13<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:15<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    3/10 [========>.....................]
 60%|██████    | 18/30 [2:38:15<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 12s - loss: 0.8407 - sparse_categorical_accuracy: 0.6693 - f1_score: 0.8672
 60%|██████    | 18/30 [2:38:15<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:17<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    4/10 [===========>..................]
 60%|██████    | 18/30 [2:38:17<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 10s - loss: 0.8339 - sparse_categorical_accuracy: 0.6621 - f1_score: 0.8647
 60%|██████    | 18/30 [2:38:17<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:19<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    5/10 [==============>...............]
 60%|██████    | 18/30 [2:38:19<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 8s - loss: 0.8248 - sparse_categorical_accuracy: 0.6719 - f1_score: 0.8622 
 60%|██████    | 18/30 [2:38:19<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:20<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    6/10 [=================>............]
 60%|██████    | 18/30 [2:38:20<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 6s - loss: 0.8106 - sparse_categorical_accuracy: 0.6777 - f1_score: 0.8630
 60%|██████    | 18/30 [2:38:20<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:22<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    7/10 [====================>.........]
 60%|██████    | 18/30 [2:38:22<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 5s - loss: 0.8056 - sparse_categorical_accuracy: 0.6724 - f1_score: 0.8600
 60%|██████    | 18/30 [2:38:22<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:24<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    8/10 [=======================>......]
 60%|██████    | 18/30 [2:38:24<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 3s - loss: 0.8129 - sparse_categorical_accuracy: 0.6670 - f1_score: 0.8580
 60%|██████    | 18/30 [2:38:24<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:26<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    9/10 [==========================>...]
 60%|██████    | 18/30 [2:38:26<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - ETA: 1s - loss: 0.8034 - sparse_categorical_accuracy: 0.6706 - f1_score: 0.8556
 60%|██████    | 18/30 [2:38:26<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   
 60%|██████    | 18/30 [2:38:29<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   10/10 [==============================]
 60%|██████    | 18/30 [2:38:29<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                    - 19s 2s/step - loss: 0.8033 - sparse_categorical_accuracy: 0.6715 - f1_score: 0.8570 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 60%|██████    | 18/30 [2:38:29<2:31:01, 755.14s/it, best loss: 0.6456168293952942]                                                                                   0.6415665149688721
 60%|██████    | 18/30 [2:40:55<2:31:01, 755.14s/it, best loss: 0.6456168293952942] 63%|██████▎   | 19/30 [2:40:55<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   Layer (type)                 Output Shape              Param #   
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   =================================================================
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_228 (Conv2D)          (None, 299, 299, 85)      2380      
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_229 (Conv2D)          (None, 299, 299, 85)      65110     
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   max_pooling2d_114 (MaxPoolin (None, 149, 149, 85)      0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   batch_normalization_114 (Bat (None, 149, 149, 85)      340       
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_230 (Conv2D)          (None, 149, 149, 85)      65110     
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_231 (Conv2D)          (None, 149, 149, 85)      65110     
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   max_pooling2d_115 (MaxPoolin (None, 74, 74, 85)        0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   batch_normalization_115 (Bat (None, 74, 74, 85)        340       
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_232 (Conv2D)          (None, 74, 74, 85)        65110     
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_233 (Conv2D)          (None, 74, 74, 85)        65110     
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   max_pooling2d_116 (MaxPoolin (None, 37, 37, 85)        0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   batch_normalization_116 (Bat (None, 37, 37, 85)        340       
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_234 (Conv2D)          (None, 37, 37, 85)        65110     
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_235 (Conv2D)          (None, 37, 37, 85)        65110     
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   max_pooling2d_117 (MaxPoolin (None, 18, 18, 85)        0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   batch_normalization_117 (Bat (None, 18, 18, 85)        340       
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_236 (Conv2D)          (None, 18, 18, 85)        65110     
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   conv2d_237 (Conv2D)          (None, 18, 18, 85)        65110     
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   max_pooling2d_118 (MaxPoolin (None, 9, 9, 85)          0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   batch_normalization_118 (Bat (None, 9, 9, 85)          340       
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   flatten_19 (Flatten)         (None, 6885)              0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   dense_68 (Dense)             (None, 57)                392502    
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   dropout_49 (Dropout)         (None, 57)                0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   dense_69 (Dense)             (None, 57)                3306      
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   dropout_50 (Dropout)         (None, 57)                0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   dense_70 (Dense)             (None, 57)                3306      
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   dropout_51 (Dropout)         (None, 57)                0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   dense_71 (Dense)             (None, 57)                3306      
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   dropout_52 (Dropout)         (None, 57)                0         
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   dense_72 (Dense)             (None, 2)                 116       
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   =================================================================
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   Total params: 992,606
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   Trainable params: 991,756
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   Non-trainable params: 850
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   _________________________________________________________________
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   None
 63%|██████▎   | 19/30 [2:41:00<2:29:12, 813.89s/it, best loss: 0.6415665149688721]2019-04-13 14:49:38.441186: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.
                                                                                   Epoch 1/2
 63%|██████▎   | 19/30 [2:44:45<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    1/10 [==>...........................]
 63%|██████▎   | 19/30 [2:50:36<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 52:40 - loss: 2.4528 - sparse_categorical_accuracy: 0.5195 - f1_score: 0.8647
 63%|██████▎   | 19/30 [2:50:36<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:50:37<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    2/10 [=====>........................]
 63%|██████▎   | 19/30 [2:50:37<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 23:31 - loss: 2.2992 - sparse_categorical_accuracy: 0.5293 - f1_score: 0.8597
 63%|██████▎   | 19/30 [2:50:37<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:50:39<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    3/10 [========>.....................]
 63%|██████▎   | 19/30 [2:50:39<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 13:47 - loss: 2.1649 - sparse_categorical_accuracy: 0.5443 - f1_score: 0.8537
 63%|██████▎   | 19/30 [2:50:39<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:50:41<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    4/10 [===========>..................]
 63%|██████▎   | 19/30 [2:50:41<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 8:54 - loss: 2.0620 - sparse_categorical_accuracy: 0.5410 - f1_score: 0.8520 
 63%|██████▎   | 19/30 [2:50:41<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:50:42<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    5/10 [==============>...............]
 63%|██████▎   | 19/30 [2:50:42<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 5:57 - loss: 1.9675 - sparse_categorical_accuracy: 0.5477 - f1_score: 0.8509
 63%|██████▎   | 19/30 [2:50:42<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:50:44<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    6/10 [=================>............]
 63%|██████▎   | 19/30 [2:50:44<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 3:59 - loss: 1.8631 - sparse_categorical_accuracy: 0.5527 - f1_score: 0.8489
 63%|██████▎   | 19/30 [2:50:44<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:50:45<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    7/10 [====================>.........]
 63%|██████▎   | 19/30 [2:50:45<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 2:34 - loss: 1.7836 - sparse_categorical_accuracy: 0.5681 - f1_score: 0.8505
 63%|██████▎   | 19/30 [2:50:45<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:50:47<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    8/10 [=======================>......]
 63%|██████▎   | 19/30 [2:50:47<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 1:30 - loss: 1.7072 - sparse_categorical_accuracy: 0.5767 - f1_score: 0.8513
 63%|██████▎   | 19/30 [2:50:47<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:50:49<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    9/10 [==========================>...]
 63%|██████▎   | 19/30 [2:50:49<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 40s - loss: 1.6298 - sparse_categorical_accuracy: 0.5855 - f1_score: 0.8531 
 63%|██████▎   | 19/30 [2:50:49<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:38<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   10/10 [==============================]
 63%|██████▎   | 19/30 [2:54:38<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - 593s 59s/step - loss: 1.5644 - sparse_categorical_accuracy: 0.5914 - f1_score: 0.8542 - val_loss: 0.9203 - val_sparse_categorical_accuracy: 0.7167 - val_f1_score: 0.8406

 63%|██████▎   | 19/30 [2:54:38<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   Epoch 2/2
 63%|██████▎   | 19/30 [2:54:38<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    1/10 [==>...........................]
 63%|██████▎   | 19/30 [2:54:39<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 13s - loss: 0.8103 - sparse_categorical_accuracy: 0.6641 - f1_score: 0.8747
 63%|██████▎   | 19/30 [2:54:39<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:41<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    2/10 [=====>........................]
 63%|██████▎   | 19/30 [2:54:41<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 12s - loss: 0.9624 - sparse_categorical_accuracy: 0.6719 - f1_score: 0.8595
 63%|██████▎   | 19/30 [2:54:41<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:42<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    3/10 [========>.....................]
 63%|██████▎   | 19/30 [2:54:42<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 10s - loss: 0.9564 - sparse_categorical_accuracy: 0.6667 - f1_score: 0.8570
 63%|██████▎   | 19/30 [2:54:42<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:44<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    4/10 [===========>..................]
 63%|██████▎   | 19/30 [2:54:44<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 9s - loss: 0.9224 - sparse_categorical_accuracy: 0.6709 - f1_score: 0.8583 
 63%|██████▎   | 19/30 [2:54:44<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:45<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    5/10 [==============>...............]
 63%|██████▎   | 19/30 [2:54:45<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 7s - loss: 0.9056 - sparse_categorical_accuracy: 0.6750 - f1_score: 0.8576
 63%|██████▎   | 19/30 [2:54:45<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:47<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    6/10 [=================>............]
 63%|██████▎   | 19/30 [2:54:47<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 6s - loss: 0.9229 - sparse_categorical_accuracy: 0.6706 - f1_score: 0.8549
 63%|██████▎   | 19/30 [2:54:47<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:48<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    7/10 [====================>.........]
 63%|██████▎   | 19/30 [2:54:48<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 4s - loss: 0.9065 - sparse_categorical_accuracy: 0.6763 - f1_score: 0.8556
 63%|██████▎   | 19/30 [2:54:48<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:50<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    8/10 [=======================>......]
 63%|██████▎   | 19/30 [2:54:50<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 3s - loss: 0.8831 - sparse_categorical_accuracy: 0.6826 - f1_score: 0.8570
 63%|██████▎   | 19/30 [2:54:50<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:52<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    9/10 [==========================>...]
 63%|██████▎   | 19/30 [2:54:52<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - ETA: 1s - loss: 0.8825 - sparse_categorical_accuracy: 0.6836 - f1_score: 0.8559
 63%|██████▎   | 19/30 [2:54:52<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   
 63%|██████▎   | 19/30 [2:54:55<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   10/10 [==============================]
 63%|██████▎   | 19/30 [2:54:55<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                    - 17s 2s/step - loss: 0.8821 - sparse_categorical_accuracy: 0.6879 - f1_score: 0.8575 - val_loss: 2.5644 - val_sparse_categorical_accuracy: 0.7250 - val_f1_score: 0.8406

 63%|██████▎   | 19/30 [2:54:55<2:29:12, 813.89s/it, best loss: 0.6415665149688721]                                                                                   2.5643835067749023
 63%|██████▎   | 19/30 [2:57:27<2:29:12, 813.89s/it, best loss: 0.6415665149688721] 67%|██████▋   | 20/30 [2:57:27<2:24:34, 867.49s/it, best loss: 0.6415665149688721]
Traceback (most recent call last):
  File "hyperparameter-tuning.py", line 78, in <module>
    max_evals = MAX_EVALS, trials = bayes_trials)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/fmin.py", line 388, in fmin
    show_progressbar=show_progressbar,
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/base.py", line 639, in fmin
    show_progressbar=show_progressbar)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/fmin.py", line 407, in fmin
    rval.exhaust()
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/fmin.py", line 262, in exhaust
    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/fmin.py", line 211, in run
    self.rstate.randint(2 ** 31 - 1))
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/tpe.py", line 900, in suggest
    print_node_on_error=False)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/pyll/base.py", line 913, in rec_eval
    rval = scope._impls[node.name](*args, **kwargs)
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/hyperopt/tpe.py", line 465, in adaptive_parzen_normal
    assert prior_sigma > 0
AssertionError
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7f1627e9f080>>
Traceback (most recent call last):
  File "/home/dominique_c_a_paul/yes/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
